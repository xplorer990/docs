var __index = Promise.resolve({"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+","tags":false},"docs":[{"location":"","text":"","title":"Saltbox Documentation"},{"location":"#welcome-to-saltbox","text":"","title":"Welcome to Saltbox."},{"location":"#what-is-it","text":"<p>You can read more about what Saltbox is here.</p>","title":"What is it?"},{"location":"#how-do-i-install-it","text":"<p>Install instructions start here.</p>","title":"How do I install it?"},{"location":"#can-i-migrate-from-cloudbox-or-plexguide","text":"<p>There are notes on migration from Cloudbox and Plexguide.</p>","title":"Can I migrate from Cloudbox or PlexGuide?"},{"location":"#is-there-a-discord-server-for-support","text":"<p>Why yes there is.</p>","title":"Is there a Discord server for support?"},{"location":"#what-if-i-see-a-mistake-in-or-have-a-suggestion-about-the-docs","text":"<p>Please report any mistakes or provide suggestions on our discord or on the docs repo, would be much appreciated.</p> <p>Issues</p>","title":"What if I see a mistake in or have a suggestion about the docs?"},{"location":"advanced/","text":"<p>In this section you will find various guides for advanced use cases.</p>","title":"Index"},{"location":"advanced/feeder/","text":"<p>For setups with separate Feeder and Media boxes, you will have newly downloaded media that will not be instantly available on cloud storage (e.g. Google Drive) and, therefore, inaccessible to Mediabox (e.g. Plex) when Sonarr/Radarr sends a media scan request.</p> <p>To remedy this issue, you can use Saltbox's Feeder Mounter to mount your Feederbox's <code>/mnt/local</code> path, onto your Mediabox's <code>/mnt/feeder</code> location, so that you are able to play those newly downloaded media files even if they haven't been uploaded to the cloud.</p> <p>Note: Running the below commands will replace your <code>unionfs.service</code> or <code>mergerfs.service</code> file. If you have any custom paths in there (e.g. <code>/mnt/rclone</code>), make sure you back that up and add them back in once you mount/dismount the Feederbox.</p>","title":"Intro"},{"location":"advanced/feeder/#mount","text":"<p>The following steps will be done on the Mediabox.</p> <ol> <li>In rclone config, create an sftp remote to your Feederbox called <code>feeder</code> (asciicast).</li> </ol> <p>Note: If you don't already have one, add the <code>feederbox</code> [[subdomain|Adding a Subdomain]] and point it to your Feederbox's IP address. If you are using Cloudflare, make sure CDN/Proxy is not enabled for this subdomain.</p> <ol> <li>Edit the <code>mounts</code> section of <code>adv_settings.yml</code> and set <code>feeder</code> to \"yes\":</li> </ol> <pre><code>mounts:\n  remote: rclone_vfs\n  feeder: yes\n</code></pre> <ol> <li>Run the following command:</li> </ol> <pre><code>sb install mounts\n</code></pre> <ol> <li>Your docker containers will restart and media on Feederbox will be available to them.</li> </ol> <p>Note: You do not need to do anything to your apps (eg no need to edit Plex library paths etc).</p>","title":"Mount"},{"location":"advanced/user-crontab-examples/","text":"<p>Note that this is just some examples, not a list of things that any particular user should have in their crontab.</p> <p><code>crontab -e</code></p> <pre><code>@daily cd /opt/python-plexlibrary/plexlibrary.sh\n0 7 * * 7 sudo PATH='/usr/bin:/bin:/usr/local/bin' env ANSIBLE_CONFIG='/srv/git/saltbox/ansible.cfg' 'sb install backup' -v  &gt;&gt; '/home/seed/logs/saltbox_backup.log' 2&gt;&amp;1\n@daily sb update &amp;&amp; sb install saltbox\n* * * * * /opt/scripts/nzbget/cleanup.sh\n0 10 * * * /opt/scripts/plex/optimize.sh\n0 * * * * PATH='/usr/bin:/bin:/usr/local/bin' cd /opt/SonarrSync/ ; /usr/bin/python SonarrSync.py\n</code></pre> <p>Line 1: <code>python-plexlibrary</code> script to make Plex libraries. - [Runs midnight daily server time]</p> <p>Line 2: Saltbox backup. - [Runs every Sunday @ 7AM server time]</p> <p>Line 3: Update Saltbox and do auto-updates - [Runs daily]</p> <p>Line 4: cleanup script to remove left over junk in /downloads/nzbs/nzbget/completed/sonarr/* etc. - [Runs every minute] <code>Note: Scroll down for a couple ideas for this script.</code></p> <p>Line 5: Script to optimize the Plex database. - [Runs daily @ 10AM server time]  <code>Note: Scroll down for script.</code></p> <p>Line 6: Enormoz's SonarrSync (based on Sperryfreak's RadarrSync) - [Runs hourly]</p>","title":"User crontab examples"},{"location":"advanced/user-crontab-examples/#phos-cleanupsh","text":"<p>This script deletes  * everything under a size of 100M * every unwanted file immediately * everything but the wanted files after 10 hours * every empty folder</p> <pre><code>#!/bin/bash\n#####################################################\n# script by pho\n#####################################################\n\n# basic settings\nTARGET_FOLDER=\"/mnt/local/downloads/nzbs/{sabnzbd,nzbget}/completed/{radarr,sonarr,lidarr}/\" # find files in this folders\nFIND_SAMPLE_SIZE='100M' # files smaller then this are seen as samples and get deleted\n\n# advanced settings\nFIND=$(which find)\nFIND_BASE_CONDITION_WANTED='-type f -amin +600'\nFIND_BASE_CONDITION_UNWANTED='-type f'\nFIND_ADD_NAME='-o -iname'\nFIND_DEL_NAME='! -iname'\nFIND_ACTION='-not -path \"*_UNPACK_*\" -delete &gt; /dev/null 2&gt;&amp;1'\ncommand=\"${FIND} ${TARGET_FOLDER} -mindepth 1 ${FIND_BASE_CONDITION_WANTED} -size -${FIND_SAMPLE_SIZE} ${FIND_ACTION}\"\n#echo \"Executing ${command}\"\neval \"${command}\"\n\nWANTED_FILES=(\n    '*.mkv'\n    '*.mpg'\n    '*.mpeg'\n    '*.avi'\n    '*.mp4'\n    '*.mp3'\n    '*.flac'\n    '*.srt'\n    '*.idx'\n    '*.sub'\n)\nUNWANTED_FILES=(\n    '*.nfo'\n    '*.jpeg'\n    '*.jpg'\n    '*.gif'\n    '*.rar'\n    '*sample.*'\n    '*.sh'\n    '*.pdf'\n    '*.doc'\n    '*.docx'\n    '*.xls'\n    '*.xlsx'\n    '*.xml'\n    '*.html'\n    '*.htm'\n    '*.exe'\n    '*.nzb'\n)\n#Folder Setting\ncondition=\"-iname '${UNWANTED_FILES[0]}'\"\nfor ((i = 1; i &lt; ${#UNWANTED_FILES[@]}; i++))\ndo\n    condition=\"${condition} ${FIND_ADD_NAME} '${UNWANTED_FILES[i]}'\"\ndone\ncommand=\"${FIND} ${TARGET_FOLDER} -mindepth 1 ${FIND_BASE_CONDITION_UNWANTED} \\( ${condition} \\) ${FIND_ACTION}\"\n#echo \"Executing ${command}\"\neval \"${command}\"\n\nfor ((i = 0; i &lt; ${#WANTED_FILES[@]}-1; i++))\ndo\n    condition2=\"${condition2} ${FIND_DEL_NAME} '${WANTED_FILES[i]}'\"\ndone\ncommand=\"${FIND} ${TARGET_FOLDER} -mindepth 1 ${FIND_BASE_CONDITION_WANTED} \\( ${condition2} \\) ${FIND_ACTION}\"\n#echo \"Executing ${command}\"\neval \"${command}\"\n\ncommand=\"${FIND} ${TARGET_FOLDER} -mindepth 1 -type d -empty ${FIND_ACTION}\"\n#echo \"Executing ${command}\"\neval \"${command}\"\n</code></pre>","title":"pho's cleanup.sh"},{"location":"advanced/user-crontab-examples/#rxwatchers-cleanupsh","text":"<p>Note that this script is specific to its author's setup when it was written.  It probably won't work for you as-is.  You'll need to edit the paths to match your situation.</p> <pre><code>#!/bin/bash\nfind /mnt/local/downloads/nzbget/completed/sonarr/* -type d -mmin +60 -ls -exec rm -rf {} + 2&gt;/dev/null\nfind /mnt/local/downloads/nzbget/completed/radarr/* -type d -mmin +60 -ls -exec rm -rf {} + 2&gt;/dev/null\nfind /mnt/local/downloads/nzbget/completed/books/*  -type d -mmin +240 -ls -exec rm -rf {} + 2&gt;/dev/null\nfind /mnt/local/downloads/nzbget/completed/sonarr/* -type d -mmin +60 -ls -exec rm -rf {} + 2&gt;/dev/null\nfind /mnt/local/downloads/nzbget/completed/radarr4k/* -type d -mmin +60 -ls -exec rm -rf {} + 2&gt;/dev/null\nfind /mnt/local/downloads/nzbget/completed/anime/* -type d -mmin +60 -ls -exec rm -rf {} + 2&gt;/dev/null\n</code></pre>","title":"RXWatcher's cleanup.sh"},{"location":"advanced/user-crontab-examples/#rxwatchers-optimizesh","text":"<pre><code>#!/bin/sh\n# Get the contents of the Preferences file, keep only what we need,  push to a temp, then use it in the curl command\n\ncat \"/opt/plex/Library/Application Support/Plex Media Server/Preferences.xml\" |  \\\nsed -e 's;^.* PlexOnlineToken=\";;' | sed -e 's;\".*$;;' | tail -1 &gt; /tmp/plex.tmp\n\ncurl --request PUT http://plex:32400/library/optimize\\?async=1\\&amp;X-Plex-Token=`cat /tmp/plex.tmp`\n\nrm -f /tmp/plex.tmp\n</code></pre>","title":"RXWatcher's optimize.sh"},{"location":"advanced/your-own-containers/","text":"<p>When you install existing roles in saltbox, some things get handled behind the scenes for you.  Notably, this includes creating the subdomain[s] at cloudflare and creating the <code>/opt/APPNAME</code> directory tree.</p> <p>When you add a container manually as outlined on this page, neither of those things will be done for you, so prior to running the docker commands described below you will have to create the <code>APPNAME.domain.tld</code> subdomain at cloudflare [or wherever your DNS is] and create the required <code>/opt/APPNAME</code> directory tree.</p> <p>The examples below are <code>docker run</code> commands that you would execute in an SSH session on your server.</p> <p>If you want to create a role file that you can install like the built-in applications, the [Contribute page in the Community wiki] outlines the process.</p>","title":"Prerequisites:"},{"location":"advanced/your-own-containers/#format","text":"<pre>\ndocker run -d  \\\n  --name=APPNAME  \\\n  --restart=unless-stopped  \\\n  -e PGID=1000 -e PUID=1000  \\\n  -v /opt/APPNAME:/CONFIG  \\\n  -v /etc/localtime:/etc/localtime:ro  \\\n  --network=saltbox \\\n  --network-alias=APPNAME  \\\n  --label com.github.saltbox.saltbox_managed=true \\\n  --label traefik.enable=true \\\n  --label traefik.http.routers.APPNAME.entrypoints=websecure \\\n  --label traefik.http.routers.APPNAME.middlewares=secureHeaders@file \\\n  --label traefik.http.routers.APPNAME.rule=Host\\(\\`APPNAME.yourdomain.com\\`\\) \\\n  --label traefik.http.routers.APPNAME.service=APPNAME \\\n  --label traefik.http.routers.APPNAME.tls.certresolver=cfdns \\\n  --label traefik.http.routers.APPNAME.tls.options=securetls@file \\\n  --label traefik.http.services.APPNAME.loadbalancer.server.port=APPLICATION_PORT \\\n  docker/image\n</pre>","title":"Format"},{"location":"advanced/your-own-containers/#format-detailed","text":"<p>Note: containers will not always use <code>/config</code>, nor will they necessarily use everything shown here.  The required volume maps and environment variables will vary by the docker image being used.</p> <pre>\ndocker run -d \\\n    --name APPNAME \\\n    --restart=unless-stopped \\\n    -e PGID=1000 -e PUID=1000 \\\n    --network=saltbox \\\n    --network-alias=APPNAME \\\n    -p host_port1:container_misc_port1 \\\n    -p host_port2:container_misc_port2 \\\n    -v /opt/APPNAME/:/config \\\n    -v /mnt/:/mnt/ \\\n    --label com.github.saltbox.saltbox_managed=true \\\n    --label traefik.enable=true \\\n    --label traefik.http.routers.APPNAME.entrypoints=websecure \\\n    --label traefik.http.routers.APPNAME.middlewares=secureHeaders@file \\\n    --label traefik.http.routers.APPNAME.rule=Host\\(\\`APPNAME.yourdomain.com\\`\\) \\\n    --label traefik.http.routers.APPNAME.service=APPNAME \\\n    --label traefik.http.routers.APPNAME.tls.certresolver=cfdns \\\n    --label traefik.http.routers.APPNAME.tls.options=securetls@file \\\n    --label traefik.http.services.APPNAME.loadbalancer.server.port=APPLICATION_PORT \\\n    docker-hub-user/repo-name\n</pre>","title":"Format (detailed)"},{"location":"advanced/your-own-containers/#examples","text":"<p>Tautulli listens on port 8181</p> <pre>\ndocker run -d \\\n    --name tautulli \\\n    --restart=unless-stopped \\\n    -e PGID=1000 -e PUID=1000 \\\n    --network=saltbox \\\n    --network-alias=tautulli \\\n    -v /opt/tautulli/:/config \\\n    -v /opt/tautulli/transcode:/transcode \\\n    -v /mnt/:/mnt/ \\\n    -v /etc/localtime:/etc/localtime:ro \\\n    -v /opt/plex/Library/Application Support/Plex Media Server/Logs:/logs \\\n    -v /opt:/opt \\\n    --label com.github.saltbox.saltbox_managed=true \\\n    --label traefik.enable=true \\\n    --label traefik.http.routers.tautulli.entrypoints=websecure \\\n    --label traefik.http.routers.tautulli.middlewares=secureHeaders@file \\\n    --label traefik.http.routers.tautulli.rule=Host\\(\\`tautulli.yourdomain.com\\`\\) \\\n    --label traefik.http.routers.tautulli.service=tautulli \\\n    --label traefik.http.routers.tautulli.tls.certresolver=cfdns \\\n    --label traefik.http.routers.tautulli.tls.options=securetls@file \\\n    --label traefik.http.services.tautulli.loadbalancer.server.port=8181 \\\n    linuxserver/tautulli\n</pre> <p>Speedtest listens on port 80, doesn't have a config dir</p> <pre>\ndocker run -d  \\\n  --name=speedtest  \\\n  --restart=unless-stopped  \\\n  -e PGID=1000 -e PUID=1000  \\\n  -v /opt/speedtest:/var/www/html \\\n  --network=saltbox \\\n  --network-alias=speedtest  \\\n  --label com.github.saltbox.saltbox_managed=true \\\n  --label traefik.enable=true \\\n  --label traefik.http.routers.speedtest.entrypoints=websecure \\\n  --label traefik.http.routers.speedtest.middlewares=secureHeaders@file \\\n  --label traefik.http.routers.speedtest.rule=Host\\(\\`speedtest.yourdomain.com\\`\\) \\\n  --label traefik.http.routers.speedtest.service=speedtest \\\n  --label traefik.http.routers.speedtest.tls.certresolver=cfdns \\\n  --label traefik.http.routers.speedtest.tls.options=securetls@file \\\n  --label traefik.http.services.speedtest.loadbalancer.server.port=80 \\\n  satzisa/html5-speedtest\n</pre> <p>Plex-Patrol doesn't need to be behind the proxy, but you want it on the saltbox network and you want saltbox to take it down for backups.</p> <pre>\ndocker run -d  \\\n  --name=plex_patrol  \\\n  --restart=unless-stopped  \\\n  -e PGID=1000 -e PUID=1000  \\\n  -v /opt/plex_patrol:/config  \\\n  -v /opt/speedtest:/var/www/html \\\n  --network=saltbox \\\n  --network-alias=plex_patrol  \\\n  --label com.github.saltbox.saltbox_managed=true \\\n  --label traefik.enable=false \\\n  cloudb0x/plex_patrol:latest\n</pre> <p>Autoscan exposing an alternate port for perhaps a second instance, but only visisble on the host [not outside]</p> <pre>\ndocker run -d  \\\n  --name=autoscan  \\\n  --restart=unless-stopped  \\\n  -e PGID=1000 -e PUID=1000  \\\n  -p 127.0.0.1:3033:3030 \\\n  -v /etc/localtime:/etc/localtime:ro \\\n  -v /opt/autoscan:/config \\\n  -v /mnt:/mnt \\\n  --network=saltbox \\\n  --network-alias=autoscan  \\\n  --label com.github.saltbox.saltbox_managed=true \\\n  --label traefik.enable=false \\\n  cloudb0x/autoscan:master\n</pre>","title":"Examples"},{"location":"advanced/your-own-containers/#details","text":"","title":"Details"},{"location":"advanced/your-own-containers/#notes","text":"<ul> <li> <p>Replace all <code>&lt;tags&gt;</code> with your info.</p> </li> <li> <p>All <code>&lt;container_*&gt;</code> items are specified by the Docker container.</p> </li> <li> <p>Ideally, you want all <code>&lt;name&gt;</code> items to have the same name.</p> </li> <li> <p>Pick docker images that allow you to specify the PUID/PGID.</p> </li> <li> <p>You can break a command into multiple lines with a backslash (<code>\\</code>) at the end of all the lines except the last one.</p> </li> </ul>","title":"Notes"},{"location":"advanced/your-own-containers/#basics","text":"<ul> <li> <p><code>--name=&lt;name&gt;</code></p> </li> <li> <p><code>--restart=unless-stopped</code></p> </li> <li> <p>To have it startup automatically, unless the container was previously stopped.</p> </li> <li> <p><code>-v /etc/localtime:/etc/localtime:ro</code></p> </li> <li> <p>To set the docker container's timezone to your host timezone.</p> </li> <li> <p><code>-e PUID=&lt;your_user_ID&gt; -e PGID=&lt;your_group_ID&gt;</code></p> </li> <li> <p>Replace <code>&lt;user&gt;</code> and <code>&lt;group&gt;</code> to match yours (see here).</p> </li> <li> <p><code>--label com.github.saltbox.saltbox_managed=true</code></p> </li> <li> <p>Is used to determine whether the container is shut down or not during Saltbox backup and other tasks. If you want this container to not be shut down, leave the label out or set it to <code>false</code>.</p> </li> <li> <p>If you do decide leave this out or set this to <code>false</code>, it will probably be a good idea to store the config files at another location other than <code>/opt</code> as a running container could cause issues during Saltbox Backup.</p> </li> </ul>","title":"Basics"},{"location":"advanced/your-own-containers/#mount-paths","text":"<p>Mount paths are in the format of <code>path/on/host:path/within/container</code>. You may change the path on host (left side), but not the path set for the container, internally (right side).</p> <ul> <li> <p><code>-v /opt/&lt;name&gt;:&lt;container_config_path&gt;</code></p> <ul> <li> <p>This is where your config files will go</p> </li> <li> <p>You will need to:</p> </li> <li> <p>Create the folder: <code>mkdir /opt/&lt;name&gt;</code></p> </li> <li> <p>Set ownership: <code>sudo chown -R &lt;user&gt;:&lt;group&gt; /opt/&lt;name&gt;</code></p> <ul> <li>Replace <code>&lt;user&gt;</code> and <code>&lt;group&gt;</code> to match yours' (see here)</li> </ul> </li> <li> <p>Set permissions: <code>sudo chmod -R ugo+X /opt&lt;name&gt;</code></p> </li> </ul> </li> <li> <p><code>-v /mnt/local/downloads/&lt;name&gt;:/downloads/&lt;name&gt;</code></p> <ul> <li> <p>Only required if your Docker app needs a path for downloads.</p> </li> <li> <p>You will need to set <code>/downloads/&lt;name&gt;</code> as the downloads path in your app.</p> </li> <li> <p>This path will be accessible to Sonarr and Radarr.</p> </li> <li> <p>You will need to:</p> </li> <li> <p>Create the folder: <code>mkdir /mnt/local/downloads/&lt;name&gt;</code></p> </li> <li> <p>Set ownership: <code>sudo chown -R &lt;user&gt;:&lt;group&gt; /mnt/local/downloads/&lt;name&gt;</code></p> <ul> <li>Replace <code>&lt;user&gt;</code> and <code>&lt;group&gt;</code> to match yours' (see here)</li> </ul> </li> <li> <p>Set permissions: <code>sudo chmod -R ugo+X /mnt/local/downloads/&lt;name&gt;</code></p> </li> </ul> </li> </ul>","title":"Mount Paths"},{"location":"advanced/your-own-containers/#network","text":"<p>Note: These are important, but leave them out if your docker run command requires <code>--net=host</code>.</p> <ul> <li> <p><code>--network=saltbox</code></p> </li> <li> <p><code>--network-alias=&lt;name&gt;</code>   (aliases are shortcuts to communicate across dockers)</p> </li> </ul>","title":"Network"},{"location":"advanced/your-own-containers/#ports","text":"<p>Ports are in the format of <code>host_port:container_port</code>.</p> <ul> <li> <p>For the main, web admin/page port (e.g. 32400 in Plex):</p> <ul> <li> <p>You do not need to specify this port with <code>-p</code>. Since this port will not be accessible over the net or from the host. Instead, Nginx-Proxy will redirect the subdomain to it.</p> </li> <li> <p>If you do want the port accessible from the host (but not from the net), simply add <code>127.0.0.1:</code> to it and specify it via:</p> </li> </ul> <p><code>-p 127.0.0.1:&lt;host_port&gt;:&lt;container_webadmin_port&gt;</code></p> <p>If you expose ports to the host like this, make sure they don't conflict with another one on that host.</p> </li> <li> <p>For all other ports:</p> <ul> <li> <p><code>-p &lt;host_port&gt;:&lt;container_other_ports&gt;</code></p> </li> <li> <p>These are accessible from the net.</p> </li> </ul> </li> <li> <p>If this is a home install, you will probably need to forward the port to the cloudbox machine.</p> </li> </ul>","title":"Ports"},{"location":"advanced/your-own-containers/#traefik-proxy","text":"<pre><code>  --label traefik.enable=true\n  --label traefik.http.routers.&lt;name&gt;.entrypoints=websecure\n  --label traefik.http.routers.&lt;name&gt;.middlewares=secureHeaders@file\n  --label traefik.http.routers.&lt;name&gt;.rule=Host\\(\\`&lt;name&gt;.&lt;yourdomain&gt;\\`\\)\n  --label traefik.http.routers.&lt;name&gt;.service=&lt;name&gt;\n  --label traefik.http.routers.&lt;name&gt;.tls.certresolver=cfdns\n  --label traefik.http.routers.&lt;name&gt;.tls.options=securetls@file\n  --label traefik.http.services.&lt;name&gt;.loadbalancer.server.port=&lt;container_webpage_port&gt; # (1)\n</code></pre> <ol> <li>The port for the web admin page for the container.</li> </ol> <p>You'll need to add the subdomain manually at your DNS provider if you're not using wild-card DNS.</p>","title":"Traefik Proxy"},{"location":"apps/asshama/","text":"","title":"Absolute Series Scanner and HAMA role for anime."},{"location":"apps/asshama/#what-is-it","text":"<p>asshama will install the Absolute Series Scanner (ASS) and the HTTP Anidb Metadata Agent (HAMA).</p> <p>HAMA is a plex agent specifically for anime and its various challenges. It is recommended to use the HAMA agent with the Absolute Series Scanner (ASS). Hama agent features include: -</p> <ul> <li>Both Movies and Series Agent</li> <li>AniDB ID to TVDB/TMDB ID matching (with studio and episode mapping list) with ScudLee's xml mapping file</li> <li>Posters from TVDB (assign a poster to each anidb id in anidb to tvdb mapping file to avoid poster duplicates)</li> <li>TVDB episode screenshots</li> <li>Episode summary (in English only) courtesy of TVDB through ScudLee's XML episode mappings</li> <li>Uses studio from mapping file then AniDB (as often missing from AniDB)</li> <li>Search part entirely local through AniDB HTML API database file anime-titles.xml</li> <li>Separate language order selection for the series name and episode titles in Agent Settings (Supports Kanji characters in folders, filenames, titles)</li> <li>Warnings in html report files (no poster available, episode summary empty, TVDB id not in mapping file) to allow the community to update more easily the mapping XML or TVDB, list of missing episodes</li> <li>Collection mapping from ScudLee's movie collection ammended with AniDB RelatedAnime field</li> <li>Unique posters by using the anidbid rank in the mapping to rotate the posters</li> <li>when a serie is not found in AniDB, search TVDB and TMDB automatically</li> <li>Trakt scrobbling supports Hama guids</li> </ul>","title":"What is it?"},{"location":"apps/asshama/#project-information","text":"<ul> <li> Absolute Series Scanner (A.S.S.)</li> <li> HTTP Anidb Metadata Agent (HAMA)</li> </ul>","title":"Project Information"},{"location":"apps/asshama/#1-installation","text":"<pre><code>sb install asshama\n</code></pre>","title":"1. Installation"},{"location":"apps/asshama/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"apps/autoscan/","text":"","title":"Autoscan"},{"location":"apps/autoscan/#what-is-it","text":"<p>Autoscan replaces the default Plex, Emby, and Jellyfin behaviour for picking up file changes on the file system. Autoscan integrates with Sonarr, Radarr, Lidarr and Google Share Drives to fetch changes in near real-time without relying on the file system.</p> <p>Autoscan is a rewrite of the original Plex Autoscan written in the Go language. In addition, this rewrite introduces a more modular approach and should be easy to extend in the future.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"apps/autoscan/#1-installation","text":"<pre><code>sb install autoscan\n</code></pre>","title":"1. Installation"},{"location":"apps/autoscan/#2-setup","text":"<p>The Saltbox Community Autoscan role will attempt to partially configure your autoscan config file located at <code>/opt/autoscan/config.yml</code>. You should refer to the documentation and adjust this file as suits your own needs. The config generated is very minimal. If you wish to monitor sharedrive activity you should probably consider using a-train rather than soon to be shelved bernard trigger.</p>","title":"2. Setup"},{"location":"apps/autoscan/#3-a-train","text":"<p>Autoscan can monitor Google Drive changes via a trigger called \"Bernard\".  The code behind Bernard can sometimes get out of sync with the satate of Google Drive and miss thing.  \"A-Train\" is a rewrite of the Bernard concepts, and is currently available as a second docker image.  At some poin t it may be integrated into autoscan.</p> <p>To run A-Train in place of Bernard:</p> <p>You must be running the cloudb0x/autoscan:bernard-rs Docker image during the testing period, together with ghcr.io/m-rots/a-train:latest.</p> <p>To do this, edit <code>/srv/git/saltbox/inventories/host_vars/localhost.yml</code> and add the following line:</p> <pre><code>autoscan_docker_image_tag: \"bernard-rs\"\n</code></pre> <p>Create an a-train config file:</p> <pre><code>mkdir /opt/a-train\nnano  /opt/a-train/a-train.toml\n</code></pre> <p>Insert the following into <code>atrain.toml</code>:</p> <pre><code># a-train.toml\n[autoscan]\n# Replace the URL with your Autoscan URL.\nurl = \"http://autoscan:3030\"\n# If you have set a username and password\n# on autoscan enter them here\nusername = \"user\"\npassword = \"password\"\n\n[drive]\n# Path to the Service Account key file,\n# relative to the current working directory (`/data` on Docker).\naccount = \"./1001.json\"\n# One or more Shared Drive IDs\n# These are IDs, not names\ndrives = [\"driveid1\", \"driveid2\"]\n</code></pre> <p>Of course, you need to change the details noted in the comments.</p> <p>Edit your Autoscan config file: <code>/opt/autoscan/config.yml</code>; replace the <code>bernard</code> trigger section with the following:</p> <pre><code>  a-train:\n      priority: 5\n      rewrite: # Global rewrites\n        - from: ^/Media/\n          to: /mnt/unionfs/Media/\n</code></pre> <p>Run the autoscan tag to rebuild the container with the new image:</p> <pre><code>sb install cm-autoscan\n</code></pre> <p>Create and run the a-train container:</p> <pre><code>docker run -d \\\n    --name a-train \\\n    --restart unless-stopped \\\n    -e PUID=1000 \\\n    -e PGID=1001 \\\n    -v /opt/a-train:/data \\\n    --label com.github.saltbox.saltbox_managed=true \\\n    --network=saltbox \\\n    --network-alias=a-train \\\n    ghcr.io/m-rots/a-train\n</code></pre> <p>Further documentation:</p> <p>A-Train Docker page: https://github.com/users/m-rots/packages/container/package/a-train</p> <p>A-Train initial documentation: https://gist.github.com/m-rots/f345fd2cfc44585266b620feb9fbd612</p> <p>Updated Autoscan documentation: https://github.com/Cloudbox/autoscan/tree/bernard-rs#a-train</p> <ul> <li> Documentation</li> </ul>","title":"3. A-Train"},{"location":"apps/btrfsmaintenance/","text":"","title":"BTRFS Maintenance"},{"location":"apps/btrfsmaintenance/#what-is-it","text":"<p>BTRFS Maintenance is a set of scripts supplementing the btrfs filesystem and aims to automate a few maintenance tasks. This means the scrub, balance, trim or defragmentation.</p> <p>Each of the tasks can be turned on/off and configured independently. The default config values were selected to fit the default installation profile with btrfs on the root filesystem.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"apps/btrfsmaintenance/#1-installation","text":"<pre><code>sb install btrfsmaintenance\n</code></pre>","title":"1. Installation"},{"location":"apps/btrfsmaintenance/#2-setup","text":"<ul> <li> Documentation</li> </ul>","title":"2. Setup"},{"location":"apps/cloudplow/","text":"","title":"Cloudplow"},{"location":"apps/cloudplow/#what-is-it","text":"<p>Cloudplow (CP) is a script created by l3uddz that has one main component as relates to Saltbox: it's an uploader to Rclone remote. Files are moved off local storage. With support for multiple uploaders (i.e. remote/folder pairings).</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"apps/cloudplow/#remote-uploader-function","text":"<p>As setup for Saltbox, Cloudplow uploads all the content in <code>/mnt/local/Media/</code> (see Paths) to your cloud storage provider (e.g. Google Drive), after the folder reaches a <code>200</code> GB size threshold, when checked every <code>30</code> minutes.</p> <p>Note: The size threshold and the check interval can be changed via steps mentioned on this page.</p>  Google Drive Daily Upload Limit (click to expand)  Google Drive has a max upload limit of about 750GB per day. When this limit is reached, Google Drive will put you in a 24 hour soft ban. When Cloudplow detects this (with the phrase `Failed to copy: googleapi: Error 403: User rate limit exceeded`), uploading will be suspended for 25 hours (i.e. a 25 hour ban sleep), and upon waking up, it will resume its checking and uploading tasks. This feature is enabled by default. This method is better than running Rclone task with a bwlimit, becasuse you can just upload in bursts when the uploading resumes.  _Note: The keywords or phrases that are used to monitor the ban, and the duration of the sleep time, can be changed at any time by editing the `config.json` file._  Cloudplow can also use service accounts to upload and work around this limitation.","title":"Remote Uploader Function"},{"location":"apps/cloudplow/#config","text":"","title":"Config"},{"location":"apps/cloudplow/#default-configjson-file","text":"<p>See Example Cloudplow configs.</p>","title":"Default config.json file"},{"location":"apps/cloudplow/#location","text":"<pre><code>/opt/cloudplow/config.json\n</code></pre> <p>Note: Config changes require a restart: <code>sudo systemctl restart cloudplow</code>.</p>","title":"Location"},{"location":"apps/cloudplow/#editing","text":"<p>Edit in your favorite code editor  (with json highlighting) or even a unix editor like nano.</p> <pre><code>nano /opt/cloudplow/config.json\n</code></pre> <p>Note: The cloudplow config file is a JSON file.  JSON files have a particular format and syntax.  If you are unfamiliar with JSON formatting and syntax, don't edit this file until you have gained that familiarity.  Here's a random YouTube video that will give you a ten-minute overview.</p>","title":"Editing"},{"location":"apps/cloudplow/#modify-upload-threshold-and-interval","text":"<pre><code>    \"uploader\": {\n        \"google\": {\n            \"check_interval\": 30,\n            \"exclude_open_files\": false,\n            \"max_size_gb\": 200,\n            \"opened_excludes\": [\n                \"/downloads/\"\n            ],\n            \"size_excludes\": [\n                \"downloads/*\"\n            ]\n        }\n</code></pre> <p><code>\"check_interval\":</code> How often (in minutes) Cloudplow checks the size of <code>/mnt/local/Media</code>.</p> <p><code>\"max_size_gb\":</code> Max size (in GB) Cloudplow allows <code>/mnt/local/Media</code> to get before starting an upload task.</p> <ul> <li> <p>Note: <code>max_size_gb</code> is rounded up, so it is advised to have it minimum <code>2GB</code> or else it would attempt upload at each interval. Explanation below.</p> <ul> <li> <p><code>1GB</code> is basically anything in there.</p> </li> <li> <p><code>2GB</code> is at least 1GB of data.</p> </li> </ul> </li> </ul>","title":"Modify Upload Threshold and Interval"},{"location":"apps/cloudplow/#plex-integration","text":"<p>Cloudplow can throttle Rclone uploads during active, playing Plex streams (paused streams are ignored).</p> <pre><code>  \"plex\": {\n      \"enabled\": false,\n      \"url\": \"https://plex.domain.com\",\n      \"token\": \"YOUR_TOKEN_HERE\",\n      \"poll_interval\": 60,\n      \"max_streams_before_throttle\": 1,\n      \"rclone\": {\n          \"throttle_speeds\": {\n              \"0\": \"1000M\",\n              \"1\": \"50M\",\n              \"2\": \"40M\",\n              \"3\": \"30M\",\n              \"4\": \"20M\",\n              \"5\": \"10M\"\n          },\n          \"url\": \"http://localhost:7949\"\n      }\n  }\n</code></pre> <p><code>enabled</code> - Change <code>false</code> to <code>true</code> to enable.</p> <p><code>url</code> - Your Plex URL.</p> <p><code>token</code> - Your Plex Access Token.</p> <p><code>poll_interval</code> - How often (in seconds) Plex is checked for active streams.</p> <p><code>max_streams_before_throttle</code> - How many playing streams are allowed before enabling throttling.</p> <p><code>rclone</code></p> <ul> <li> <p><code>url</code> - Leave as default.</p> </li> <li> <p><code>throttle_speeds</code> - Categorized option to configure upload speeds for various stream counts (where <code>5</code> represents 5 or more streams). <code>M</code> is MB/s.</p> <ul> <li>Format:</li> </ul> <pre><code>\"STREAM COUNT\": \"THROTTLED UPLOAD SPEED\",\n</code></pre> </li> </ul>","title":"Plex Integration"},{"location":"apps/cloudplow/#restart","text":"<p>Restart Cloudplow to apply the changes to the config.</p> <pre><code>sudo systemctl restart cloudplow\n</code></pre>","title":"Restart"},{"location":"apps/cloudplow/#cli","text":"<p>You can run a manual Cloudplow task from anywhere by just using the <code>cloudplow</code> command.</p>","title":"CLI"},{"location":"apps/cloudplow/#manual-upload","text":"<p>To start uploading right away, regardless of what the folder size is:</p> <pre><code>cloudplow upload\n</code></pre>","title":"Manual Upload"},{"location":"apps/emby/","text":"","title":"Emby"},{"location":"apps/emby/#what-is-it","text":"<p>Emby is a media server designed to organize, play, and stream audio and video to a variety of devices</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"apps/emby/#1-introduction","text":"<p></p>","title":"1. Introduction"},{"location":"apps/emby/#2-url","text":"<ul> <li>To access Emby, visit https://emby.yourdomain.com</li> </ul>","title":"2. URL"},{"location":"apps/emby/#3-initial-setup","text":"","title":"3. Initial Setup"},{"location":"apps/emby/#i-domain","text":"<ul> <li> <p>See Adding a Subdomain on how to add the subdomain <code>emby</code> to your DNS provider.</p> </li> <li> <p>Note: You can skip this step if you are using Cloudflare with Saltbox.</p> </li> </ul>","title":"i. Domain"},{"location":"apps/emby/#ii-install","text":"<ul> <li> <p>Run the following command:</p> <pre><code>sb install emby\n</code></pre> </li> </ul>","title":"ii. Install"},{"location":"apps/emby/#4-setup-wizard","text":"<ol> <li> <p>Visit https://emby.yourdomain.com.</p> </li> <li> <p>Select your preferred display language. Click Next.</p> </li> </ol> <p>)</p> <ol> <li> <p>Type the following and click Next:</p> <ul> <li> <p>Username: The username you wwant to use to log into Emby</p> </li> <li> <p>New Password: A strong password you'll use to log into Emby</p> </li> <li> <p>New Password Confirm: That same password again</p> </li> <li> <p>Emby connect username or email address: your Emby Connect username (important)</p> </li> </ul> </li> </ol> <p></p> <ol> <li>Confirm the message by clicking Got It.</li> </ol> <p></p> <ol> <li>Confirm the link in your email.</li> </ol> <p></p> <p></p> <ol> <li>Skip the adding of the libraries. Click Next.</li> </ol> <p></p> <ol> <li>Select your Preferred Metadata Language and Country (<code>English</code> and <code>United States</code> are recommended) and click Next.</li> </ol> <p></p> <ol> <li>Uncheck Enable automatic port mapping. Click Next.</li> </ol> <p></p> <ol> <li>Check to accept the terms. Click Next.</li> </ol> <p></p> <ol> <li>Click Finish.</li> </ol> <p></p> <ol> <li>You will now be taken to the Dashboard view.</li> </ol>","title":"4. Setup Wizard"},{"location":"apps/emby/#5-settings","text":"","title":"5. Settings"},{"location":"apps/emby/#i-transcoding","text":"<ol> <li> <p>Go to Settings.</p> </li> <li> <p>Go to Transcoding.</p> </li> </ol> <p></p> <ol> <li>Under Enable hardware acceleration when available, select Advanced.</li> </ol> <p></p> <ol> <li>Under Transcoding temporary path, type in or choose <code>/transcode</code>.</li> </ol> <p></p> <ol> <li>Click Save.</li> </ol>","title":"i. Transcoding"},{"location":"apps/emby/#iii-libraries","text":"<p>In this section, we will add two libraries: one for Movies and one for TV Shows.</p>","title":"iii. Libraries"},{"location":"apps/emby/#add-movie-library","text":"<ol> <li> <p>Go to Settings.</p> </li> <li> <p>Go to Library.</p> </li> </ol> <p></p> <ol> <li> <p>Click + New Library.</p> </li> <li> <p>Under Content type, select Movies.</p> </li> </ol> <p></p> <p></p> <ol> <li> <p>Click + next to Folders.</p> </li> <li> <p>Type in or choose <code>/mnt/unionfs/Media/Movies</code>. Click OK.</p> </li> </ol> <p>Note: These paths are for the standard library setup. If you have customized it, use those paths instead.</p> <p></p> <ol> <li>Click OK once more.</li> </ol>","title":"Add Movie Library"},{"location":"apps/emby/#add-tv-shows-library","text":"<ol> <li> <p>Go to Settings.</p> </li> <li> <p>Go to Library.</p> </li> </ol> <p></p> <ol> <li> <p>Click + New Library.</p> </li> <li> <p>Under Content type, select TV shows.</p> </li> </ol> <p></p> <p></p> <ol> <li> <p>Click + next to Folders.</p> </li> <li> <p>Type in or choose <code>/mnt/unionfs/Media/TV</code>. Click OK.</p> </li> </ol> <p>Note: These paths are for the standard library setup. If you have customized it, use those paths instead.</p> <p></p> <ol> <li>Click OK once more.</li> </ol>","title":"Add TV Shows Library"},{"location":"apps/emby/#6-api-key","text":"<p>Instructions below will guide you through creating an API Key for a specific app.</p> <ol> <li> <p>Click the Settings icon.</p> </li> <li> <p>Under Advanced, click API Keys.</p> </li> </ol> <p></p> <ol> <li>Click + New API Key.</li> </ol> <p></p> <ol> <li> <p>Fill in an App name (e.g. Ombi) and click OK.</p> </li> <li> <p>You have now have created an Api Key for your app.</p> </li> </ol> <p></p>","title":"6. API Key"},{"location":"apps/jackett/","text":"","title":"Jackett"},{"location":"apps/jackett/#what-is-it","text":"<p>Jackett (based on the original work of Matthew Little aka zone117x) is a web-based app that acts like a proxy server, directing search queries from download clients (e.g. Sonarr) to torrent tracker sites and sending the results back. Download clients can also use Jackett to fetch RSS feeds from tracker sites. Finally, it can be used as a meta search tool to find torrents, right from within the app.</p>    Details         Project home  Docs  Github:  Docker     <p>Note: If you don't use torrents, you may just skip this page.</p>","title":"What is it?"},{"location":"apps/jackett/#1-url","text":"<ul> <li>To access Jackett, visit http://jackett.yourdomain.com</li> </ul>","title":"1. URL"},{"location":"apps/jackett/#2-settings","text":"<p></p>","title":"2. Settings"},{"location":"apps/jackett/#disabling-auto-update","text":"<p>Under \"Jackett Configuration\":</p> <ol> <li> <p>Check \"Disable auto update\".</p> </li> <li> <p>Check \"External access\".</p> </li> <li> <p>Click \"Apply server settings\".</p> </li> <li> <p>The page will now reload.</p> </li> </ol>","title":"Disabling Auto Update"},{"location":"apps/jackett/#3-adding-indexers-to-sonarrradarr","text":"<p>Under \"Configured Indexers\":</p> <ol> <li> <p>Click \"Add Indexer\" to add your favorite indexers (i.e. torrent trackers).</p> </li> <li> <p>When adding indexers into Sonarr/Radarr, you will need:</p> <ol> <li> <p>Indexer's Torznab Feed</p> <ul> <li> <p>Copy this by clicking on \"Copy Torznab Feed\" button next to the Indexer.</p> </li> <li> <p>You will need to replace...</p> </li> <li> <p><code>https</code> with <code>http</code></p> </li> <li> <p><code>jackett.yourdomain.com</code> with <code>jackett:9117</code></p> </li> </ul> </li> <li> <p>Jacket API Key</p> </li> </ol> </li> </ol>","title":"3. Adding Indexers to Sonarr/Radarr"},{"location":"apps/jellyfin/","text":"","title":"Jellyfin"},{"location":"apps/jellyfin/#what-is-it","text":"<p>Jellyfin is the volunteer-built media solution that puts you in control of your media. Stream to any device from your own server, with no strings attached. Your media, your server, your way.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"apps/jellyfin/#1-installation","text":"<pre><code>sb install jellyfin\n</code></pre>","title":"1. Installation"},{"location":"apps/jellyfin/#2-url","text":"<ul> <li>To access Jellyfin, visit <code>https://jellyfin._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"apps/jellyfin/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"apps/lidarr/","text":"","title":"Lidarr"},{"location":"apps/lidarr/#what-is-it","text":"<p>Lidarr is basically Sonarr for music. It functions as a music collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds from Bittorrent trackers and Usenet Indexers, looking for new tracks from your favorite artists and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"apps/lidarr/#url","text":"<ul> <li>To access Lidarr, visit https://lidarr.yourdomain.com</li> </ul>","title":"URL"},{"location":"apps/lidarr/#settings","text":"","title":"Settings"},{"location":"apps/lidarr/#general","text":"<ol> <li> <p>Go to \"Settings\" -&gt; \"General\".</p> </li> <li> <p>Set \"Advanced Settings\": <code>Shown</code></p> </li> </ol>","title":"General"},{"location":"apps/lidarr/#host","text":"<ul> <li> <p>\"Bind Address: <code>*</code></p> </li> <li> <p>\"Port Number\": <code>8686</code></p> </li> <li> <p>\"URL Base\": blank</p> </li> <li> <p>\"Enable SSL\": <code>No</code> (SSL is handled by Traefik)</p> </li> <li> <p>\"Open browser on start\": <code>No</code></p> </li> </ul>","title":"Host"},{"location":"apps/lidarr/#proxy-settings","text":"<ul> <li>\"Use Proxy\": <code>No</code></li> </ul>","title":"Proxy Settings"},{"location":"apps/lidarr/#logging","text":"<ul> <li>\"Log Level\": <code>Debug</code></li> </ul>","title":"Logging"},{"location":"apps/lidarr/#analytics","text":"<ul> <li>\"Send Anonymous Usage Data\": <code>No</code> (your preference)</li> </ul>","title":"Analytics"},{"location":"apps/lidarr/#updates","text":"<ul> <li> <p>\"Branch\": <code>develop</code></p> </li> <li> <p>\"Automatic\": <code>Off</code></p> </li> </ul>","title":"Updates"},{"location":"apps/lidarr/#save","text":"<ul> <li>Click \"Save\".</li> </ul>","title":"Save"},{"location":"apps/lidarr/#media-management","text":"<ol> <li> <p>Click \"Settings\" -&gt; \"Media Management\".</p> </li> <li> <p>Enable \"Rename Tracks\".</p> </li> <li> <p>Enable \"Replace Illegal Characters\".</p> </li> <li> <p>Set your preferred naming format (you can use the ones mentioned below).</p> </li> </ol>  Plex's Naming Preference         Example:        `01 - Shine On You Crazy Diamond (Parts I-V).m4a`        Standard Track Format:        `{track:00} - {Track Title}`        Artist Folder Format:        `{Artist Name}`        Album Folder Format:        `{Artist Name} - {Album Title}`        Ref: https://support.plex.tv/articles/categories/media-preparation/naming-and-organizing-music-media/    <ol> <li> <p>Disable \"Analyse audio files\".</p> </li> <li> <p>Click \"Save\".</p> </li> </ol>","title":"Media Management"},{"location":"apps/lidarr/#download-client","text":"<ol> <li> <p>Click \"Settings\" -&gt; \"Download Client\".</p> </li> <li> <p>\"Completed Download Handling\": <code>Enabled</code> Selected (your preference)</p> </li> <li> <p>\"Failed Download Handling\": <code>Redownload</code> Selected.</p> </li> </ol>","title":"Download Client"},{"location":"apps/lidarr/#nzbget","text":"<ol> <li> <p>Add a new \"NZBGet\" download client.</p> </li> <li> <p>Add the following:</p> </li> <li> <p>Name: NZBGet</p> </li> <li> <p>Enable: <code>Yes</code></p> </li> <li> <p>Host: <code>nzbget</code></p> </li> <li> <p>Port: <code>6789</code></p> </li> <li> <p>Username:  Your NZBGet Username</p> </li> <li> <p>Password:  Your NZBGet Password</p> </li> <li> <p>Category: <code>lidarr</code></p> </li> <li> <p>Use SSL: <code>No</code></p> </li> <li> <p>Add Paused: <code>No</code></p> </li> <li> <p>Your settings will now look like this:</p> <p></p> </li> <li> <p>Click \"Save\" to add NZBGet.</p> </li> </ol>","title":"NZBGet"},{"location":"apps/lidarr/#rutorrent","text":"<ol> <li> <p>Add a new \"rTorrent\" download client.</p> </li> <li> <p>Add the following:</p> </li> <li> <p>Name: ruTorrent</p> </li> <li> <p>Enable: <code>Yes</code></p> </li> <li> <p>Host: <code>rutorrent</code></p> </li> <li> <p>Port: <code>80</code></p> </li> <li> <p>URL Path: <code>RPC2</code></p> </li> <li> <p>Use SSL: <code>No</code></p> </li> <li> <p>Username: Your ruTorrent Username</p> </li> <li> <p>Password: Your ruTorrent Password</p> </li> <li> <p>Category: <code>lidarr</code></p> </li> <li> <p>Directory: Leave Blank</p> </li> <li> <p>Your settings will look like this:</p> </li> </ol> <p></p> <ol> <li>Click \"Save\" to add ruTorrent.</li> </ol>","title":"ruTorrent"},{"location":"apps/lidarr/#indexers","text":"<ol> <li> <p>Go to \"Settings\" -&gt; \"Indexers\".</p> </li> <li> <p>Set \"Advanced Settings\": <code>Shown</code></p> </li> <li> <p>Add in your your favorite indexers.</p> </li> </ol>","title":"Indexers"},{"location":"apps/lidarr/#nzbhydra2","text":"<ol> <li> <p>Click \"Settings\" -&gt; \"Indexers\".</p> </li> <li> <p>Click Add Indexer (<code>+</code>).</p> </li> <li> <p>Select \"Newznab\".</p> </li> <li> <p>Add the following:</p> </li> <li> <p>Name: NZBHydra2</p> </li> <li> <p>Enable RSS Sync: Your Preference</p> </li> <li> <p>Enable Search: Your Preference</p> </li> <li> <p>URL: <code>http://nzbhydra2:5076</code></p> </li> <li> <p>API Path: <code>/api</code></p> </li> <li> <p>API Key: Your NZBHydra2 API Key</p> </li> <li> <p>Additional Parameters: Leave Blank</p> </li> <li> <p>Your settings will look like this:</p> <p></p> </li> <li> <p>Click \"Save\" to add NZBHydra2.</p> </li> </ol> <p>Note: The \"Test\" will keep failing until you add an indexer in NZBHydra2.</p>","title":"NZBHydra2"},{"location":"apps/lidarr/#jackett","text":"<p>Note: Each Indexer will need to be added separately.</p> <ol> <li> <p>Click \"Settings\" -&gt; \"Indexers\".</p> </li> <li> <p>Click Add Indexer (<code>+</code>)</p> </li> <li> <p>Select \"Torznab\".</p> </li> <li> <p>Add the following:</p> </li> <li> <p>Name: Indexer's Name</p> </li> <li> <p>Enable RSS Sync: Your Preference</p> </li> <li> <p>Enable Search: Your Preference</p> </li> <li> <p>URL: Indexer's Torznab Feed</p> </li> <li> <p>API Path: <code>/api</code></p> </li> <li> <p>API Key: Your Jackett API Key</p> </li> <li> <p>Additional Parameters: Leave Blank</p> </li> <li> <p>Your settings will look like this:</p> <p></p> </li> <li> <p>Click \"Save\" to add the indexer.</p> </li> </ol>","title":"Jackett"},{"location":"apps/lidarr/#connect","text":"","title":"Connect"},{"location":"apps/lidarr/#torrent-cleanup","text":"<p>Torrent Cleanup Script is a custom script that will cleanup torrents from ruTorrent that were auto-extracted, but still being seeded. So if the script detects that <code>.rar</code> files are in the folder that Lidarr just imported from, it will delete the imported video file(s), leaving just the <code>.rar</code> files for seeding.</p> <ol> <li> <p>Click \"Settings\" -&gt; \"Connect\".</p> </li> <li> <p>Add a new \"Custom Script\".</p> </li> <li> <p>Add the following:</p> </li> <li> <p>Name: Torrent Cleanup</p> </li> <li> <p>On Grab: <code>No</code></p> </li> <li> <p>On Download: <code>Yes</code></p> </li> <li> <p>On Upgrade:  <code>Yes</code></p> </li> <li> <p>On Rename:<code>No</code></p> </li> <li> <p>Path: <code>/scripts/torrents/TorrentCleanup.py</code></p> </li> <li> <p>The settings will look like this:</p> </li> </ol> <p></p> <ol> <li>Click \"Save\" to add the Torrent Cleanup script.</li> </ol>","title":"Torrent Cleanup"},{"location":"apps/lidarr/#plex-autoscan","text":"<p>Plex Autoscan no longers work with music libraries as of version 1.18, so this feature will not work. 1. Click \"Settings\" -&gt; \"Connect\".</p> <ol> <li> <p>Add a new \"Webhook\".</p> </li> <li> <p>Add the following:</p> </li> <li> <p>Name: Plex Autoscan</p> </li> <li> <p>On Grab: <code>No</code></p> </li> <li> <p>On Download: <code>Yes</code></p> </li> <li> <p>On Upgrade:  <code>Yes</code></p> </li> <li> <p>On Rename: <code>Yes</code></p> </li> <li> <p>URL: Your Plex Autoscan URL</p> </li> <li> <p>Method:<code>POST</code></p> </li> <li> <p>Username: Leave Blank</p> </li> <li> <p>Password: Leave Blank</p> </li> <li> <p>The settings will look like this:</p> <p></p> </li> <li> <p>Click \"Save\" to add Plex Autoscan.</p> </li> </ol>","title":"Plex Autoscan"},{"location":"apps/lidarr/#music-path","text":"<ol> <li> <p>When you are ready to add your first artist to Lidarr, click the \"Path\" drop-down and select \"Add a different path\".</p> </li> <li> <p>Click the blue \"Browse\" button, navigate to <code>/mnt/unionfs/Media/Music</code>, scroll to the bottom, and select \"OK\".</p> </li> <li> <p>Click the green \"check\" button to add the path.</p> </li> <li> <p>All artist added now will have that path set.</p> </li> </ol>","title":"Music Path"},{"location":"apps/lidarr/#api-key","text":"<p>This is used during the setup of Organizr.</p> <ul> <li>Go to \"Settings\" -&gt; \"General\" -&gt; \"Security\" -&gt; \"API Key\".</li> </ul>","title":"API Key"},{"location":"apps/nzbget/","text":"","title":"Nzbget"},{"location":"apps/nzbget/#what-is-it","text":"<p>NZBGet (by Andrey Prygunkov aka hugbug) is a very efficient, cross-platform usenet downloader.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"apps/nzbget/#1-accessing-nzbget","text":"<ul> <li>To access NZBGet, visit https://nzbget.yourdomain.com</li> </ul>","title":"1. Accessing NZBGet"},{"location":"apps/nzbget/#2-settings","text":"","title":"2. Settings"},{"location":"apps/nzbget/#paths","text":"<ul> <li>Download paths have already been specified, no need to change those.</li> </ul>","title":"Paths"},{"location":"apps/nzbget/#news-servers","text":"<ul> <li>Add your news servers.</li> </ul>","title":"News-Servers"},{"location":"apps/nzbget/#security","text":"<ul> <li>Login settings are preset out of the box (<code>user</code> / <code>passwd</code> as set in accounts.yml).</li> </ul>","title":"Security"},{"location":"apps/nzbget/#download-queue","text":"<ul> <li> <p>Disk Space</p> <ul> <li>By default, minimum disk space is set at 100000 (i.e. 100GB). When space goes lower than this, NZBGet will pause the queue. If you have a smaller hard drive, you will need to lower this setting.</li> </ul> </li> </ul>","title":"Download Queue"},{"location":"apps/nzbget/#connection","text":"<ul> <li> <p>DailyQuota</p> <ul> <li>Recommend you set this to <code>750000</code> (i.e. 750GB), to coincide with the Google Drive daily upload limit.</li> </ul> </li> </ul>","title":"Connection"},{"location":"apps/nzbget/#3-extensions","text":"<ul> <li> <p>Location on server: <code>/opt/scripts/nzb</code>.</p> </li> <li> <p>Location within NZBGet: <code>/scripts/nzb</code>.</p> </li> </ul>","title":"3. Extensions"},{"location":"apps/nzbhydra2/","text":"<p>THIS PAGE HAS NOT BEEN FULLY UPDATED FOR SALTBOX</p>","title":"Nzbhydra2"},{"location":"apps/nzbhydra2/#what-is-it","text":"<p>NZBHydra2, by TheOtherP, is a meta search tool for NZB indexers. It provides easy access to a number of NZB indexers. You can search all your indexers from one place and use it as indexer source for tools like Sonarr or CouchPotato.</p>    Details         Project home  Docs  Github:  Docker     <p>Three Ways to setup NZB indexers with Sonarr/Radarr/Lidarr:</p> <ol> <li> <p>Skip this page and add all your NZB Indexers directly into Sonarr/Radarr/Lidarr. Benefit from the seeing indexer sources during manual lookups in Sonarr/Radarr/Lidarr. This method is also useful when diagnosing issues with indexers during failed searches;</p> </li> <li> <p>Add all your NZB Indexers directly into Sonarr/Radarr/Lidarr, but also add them in NZBHydra2, so it could be used a tool for manual downloads; or</p> </li> <li> <p>Add all your NZB indexers in NZBHydra2 and then just add the one NZBHydra2 \"indexer\" into Sonarr/Radarr/Lidarr. This is the most popular choice among users.</p> </li> </ol>  <p>To Setup NZBHydra2, follow the steps below.</p>","title":"What is it?"},{"location":"apps/nzbhydra2/#2-url","text":"<ul> <li>URL to access NZBHydra2, visit https://nzbhydra2.yourdomain.com.</li> </ul>","title":"2. URL"},{"location":"apps/nzbhydra2/#3-setup","text":"<p>Enter setup by clicking on \"Config\" at the top.</p>","title":"3. Setup"},{"location":"apps/nzbhydra2/#main","text":"<ul> <li>Under 'Security', click the icon next to the 'API key *' field to generate an API key. Click 'Save'.</li> </ul>","title":"Main"},{"location":"apps/nzbhydra2/#authorization","text":"<ul> <li>Login settings are preset out of the box (<code>user</code> / <code>passwd</code> as set in accounts.yml).</li> </ul>","title":"Authorization"},{"location":"apps/nzbhydra2/#indexers","text":"<ul> <li>Add your indexers. Click \"Save\".</li> </ul>","title":"Indexers"},{"location":"apps/nzbhydra2/#downloaders","text":"<ul> <li>NZBGet settings are preset out of the box.</li> </ul>","title":"Downloaders"},{"location":"apps/nzbhydra2/#4-api-key","text":"<p>To find the NZBHydra2 API Key, go to \"Config\" --&gt; \"Main\". This will be used later in Sonarr and Radarr.</p>","title":"4. API Key"},{"location":"apps/organizr/","text":"","title":"Organizr"},{"location":"apps/organizr/#what-is-it","text":"<p>Organizr (by CauseFX) is a web-based, HTPC server organizer, that allows you to manage various tools and programs within tabs. Also supports user management, allowing for non admin users or guests to access certain web-pages via Organizr, even if it is behind HTTP authentication. This guide is to help you get Organizr setup and running by no means is this a complete guide to Organizr as you'll see the depth of it is pretty vast and there are plenty of customizations available to you at every turn.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"apps/organizr/#2-url","text":"<ul> <li>To access Organizr, visit https://organizr.yourdomain.com</li> </ul>","title":"2. URL"},{"location":"apps/organizr/#3-initial-setup","text":"<ol> <li> <p>The first time you go to the Organizr page, you will be presented with <code>Install Type</code>, <code>Admin Info</code>, <code>Security</code>, <code>Database</code> and <code>Verify</code> sections. In the <code>Install Type</code> section select <code>Personal</code></p> <p></p> </li> <li> <p>In the <code>Admin Info</code> section enter your details such as the preferred password to log in and personal email. Note: it is suggested to enter your <code>plex username and password</code></p> <p></p> </li> <li> <p>In the <code>Security</code> section enter your fill in the <code>Hash Key</code> and <code>Registration Password</code> any type of password will do but if you want a secure one then follow these steps;</p> </li> <li>First for the <code>Hash Key</code> you can head over to Base64 Encode and convert a string to Base64. Keep in mind the <code>Hash Key</code> can be anywhere between 3 to 30 which mean you can enter string up to 21 characters in Base64</li> <li>For the password just use any strong password you prefer, if you want a strong one then Password Generator, there is no limit on the password section go crazy ;)</li> <li>The API key should be auto-generated so no need to worry about this if the API key is throwing an error such as shorter than it suppose to be or longer it's most likely due to the web browser auto-fill, make sure it's disabled or just use another browser that doesn't have auto-fill or you don't use much e.g Internet Explorer \ud83d\udc40.  You should have something like this:</li> </ol> <p></p> <ol> <li>In the <code>Database</code> section enter your preferred database name (there is 30 character limit), then after that for the \"Database Location\" set it as <code>/config/www</code> then click test path it should be a success.  You should have something like this:</li> </ol> <p></p> <ol> <li>In the <code>Verify</code> section you will just need to confirm everything but feel free to take note of your API key and save it somewhere safe. After clicking finish you will be taken to a log in the page just enter the <code>username</code> and <code>password</code> you have inserted in the <code>Admin info</code> section.  You should have something like this:</li> </ol> <p></p>","title":"3. Initial Setup"},{"location":"apps/organizr/#4-settings","text":"<ol> <li> <p>You will now be taken to the main Organizr Page and asked to login with the credentials you created in the previous steps.</p> <p></p> </li> </ol>","title":"4. Settings"},{"location":"apps/organizr/#tabs","text":"<ol> <li> <p>Click \"Settings\" on the left menu, to be taken to the \"Organizr Settings\" page.</p> <p> </p> </li> <li> <p>Things to note on this page, the Homepage is disabled by default and note the \"Type\" is set to \"Internal\".  Your normal Apps with Cloudbox will all need to have a Type: \"iFrame\" unless you have a particular app you wish to open in another window which is also a Type option.  Go ahead and click \"+ on the right\". You will be prompted for information regarding the tab.</p> <p></p> </li> <li> <p>Before hitting the Edit Tab button in the bottom right, please hit the \"Test Tab\" button, sometimes the Tab will check for you if iFrame is possible.  This will test if the information you inputted can be open in an iFrame.  Which is the secret sauce in Organizr's tabbed browsing.</p> <p></p> </li> <li> <p>You will need to create multiple tabs with the information below. These are merely a suggestion and examples to get you up and going.  Any changes made, won't be reflected until Organizr is reloaded. You can also drag and drop to change the order of the apps (don't forget to reload)</p>    Tab Name Tab URL Icon URL Category Group Type Active     Portainer https://portainer.yourdomain.ltd images/organizr.png (default) Unsorted Admin iFrame Y   Sonarr https://sonarr.yourdomain.ltd images/sonarr.png Unsorted Admin iFrame Y   Radarr https://radarr.yourdomain.ltd images/radarr.png Unsorted Admin iFrame Y   NZBGet https://nzbget.yourdomain.ltd images/nzbget.png Unsorted Admin iFrame Y   Rutorrent https://rutorrent.yourdomain.ltd images/rutorrent.png Unsorted Admin iFrame Y   NZBHydra2 https://nzbhydra2.yourdomain.ltd images/hydra.png Unsorted Admin iFrame Y   Jackett https://jackett.yourdomain.ltd images/jackett.png Unsorted Admin iFrame Y   Plex https://plex.yourdomain.ltd images/plex.png Unsorted User iFrame Y   Tautulli https://tautulli.yourdomain.ltd images/tautulli.png Unsorted User iFrame Y   Ombi https://ombi.yourdomain.ltd images/ombi.png Unsorted User iFrame Y    <p></p> </li> <li> <p>Note: If Sonarr or Radarr are lagging a lot, you may set it to a specific page in each. (e.g. Sonarr: https://sonarr.yourdomain.com/calendar ; Radarr: https://radarr.yourdomain.com/activity/history)</p> </li> </ol>","title":"Tabs"},{"location":"apps/organizr/#homepage-make-you-have-homepage-active-in-tabs-section","text":"<ol> <li> <p>Click \"Homepage Items\" under the Tab Editor section, to be taken to the \"Homepage Items\" page.</p> <p></p> </li> <li> <p>Click the Plex icon at the top.</p> <ul> <li> <p>You'll have to Enable it and verify the Minimum Authentication</p> </li> <li> <p>Click on the Connection Tab and set \"Plex URL\": <code>http://plex:32400</code></p> </li> <li> <p>Currently there is no \"GET PLEX TOKEN\" button like there was in v1 of Organizr so you will need to follow <code>https://github.com/Cloudbox/Cloudbox/wiki/Plex-Access-Token</code> in order to get your Plex access Token.</p> </li> <li> <p>Set your preferred options on the remaining tabs.</p> </li> <li> <p>Click \"SAVE\".</p> </li> </ul> <p></p> </li> <li> <p>Click the Sonarr icon at the top.</p> <ul> <li> <p>Enable it.</p> </li> <li> <p>On the Connections Tab, Set \"Sonarr URL\": <code>http://sonarr:8989</code></p> </li> <li> <p>Set \"Sonarr API Key\": [[Your Sonarr API Key|Install: Sonarr#9-retrieving-the-api-key]]</p> </li> <li> <p>Go over any other Miscellaneous Options on the next Tab and set your preferences.</p> </li> <li> <p>Click \"SAVE\".</p> </li> </ul> <p></p> </li> <li> <p>Click the Radarr icon at the top.</p> <ul> <li> <p>Enable it.</p> </li> <li> <p>Set \"Radarr URL\": <code>http://radarr:7878</code></p> </li> <li> <p>Set \"Radarr API Key\": [[Your Radarr API Key|Install: Radarr#9-retrieving-the-api-key]]</p> </li> <li> <p>Go over any other Miscellaneous Options on the next Tab and set your preferences.</p> </li> <li> <p>Click \"SAVE\".</p> </li> </ul> <p></p> </li> <li> <p>Click the NZBGet icon at the top.</p> <ul> <li> <p>Enable it.</p> </li> <li> <p>Set \"NZBGet URL\": <code>http://nzbget:6789</code></p> </li> <li> <p>For \"Username\" / \"Password\": fill in your NZBGet login (see [[NZBGet|Install: NZBGet#2-setup]])</p> </li> <li> <p>Click \"SAVE\".</p> </li> </ul> <p></p> </li> </ol>","title":"Homepage (Make you have Homepage ACTIVE in Tabs section)"},{"location":"apps/organizr/#homepage-order","text":"<ol> <li> <p>This is where you organize the apps and other items and how they will appear on your Homepage.  There's no right or wrong order so simply move things around and find out what works for you.</p> <p></p> </li> </ol> <p>Any additional question please reach out to the Organizr team, either via their Discord Server or their subreddit</p>","title":"Homepage Order"},{"location":"apps/overseerr/","text":"","title":"Overseerr"},{"location":"apps/overseerr/#what-is-it","text":"<p>Overseerr is a request management and media discovery tool built to work with your existing Plex ecosystem.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"apps/overseerr/#1-url","text":"<ul> <li>To access Overseerr, visit https://overseerr.yourdomain.com</li> </ul>","title":"1. URL"},{"location":"apps/overseerr/#2-settings","text":"<p>This setup needs to take place AFTER you've set up Plex, Radarr, and Sonarr, since it involves connections to all three of those.</p> <p>You will need your API Keys from both Radarr and Sonarr.</p> <ol> <li>Click \"Sign In\" and sign into your Plex account.</li> </ol> <p></p> <ol> <li>Click the \"refresh\" icon, then select your Plex server from the dropdown.  Click \"Save Changes\" to retrieve the libraries from Plex.</li> </ol> <p></p> <ol> <li>Scroll down and flip the switch on the libraries you want to expose for requests and discovery.  Click \"Continue\".</li> </ol> <p></p> <ol> <li>Click \"Add Radarr Server\".</li> </ol> <p></p> <ol> <li>On this screen:<ol> <li>Check \"Default server\"</li> <li>Enter a name</li> <li>Enter <code>radarr</code> as the hostname</li> <li>Enter your Radarr API Key</li> <li>Click \"Test\" to connect to Radarr and retrieve Quality Profiles, etc.</li> </ol> </li> </ol> <p></p> <ol> <li>Select a Quality, Root Folder, and Minimum Availability, then click \"Add Server\".  This will return you to the screen from the previous step. Click \"Add Sonarr Server\"</li> </ol> <p></p> <ol> <li>On this screen:<ol> <li>Check \"Default server\"</li> <li>Enter a name</li> <li>Enter <code>sonarr</code> as the hostname</li> <li>Enter your Sonarr API Key</li> <li>Scroll down and click \"Test\" to connect to Sonarr and retrieve Quality Profiles, etc.</li> </ol> </li> </ol> <p></p> <ol> <li>Select a Quality, Root Folder, and Minimum Availability for standard and Anime series.  Click  \"Add Server\".</li> </ol> <p></p> <ol> <li>Click \"Finish Setup\"</li> </ol> <p></p> <ol> <li>Click \"Settings\" over on the left.</li> </ol> <p></p> <ol> <li>Click \"Users\" on the left, then \"Import Users From Plex\"</li> </ol> <p></p> <ol> <li>Setup is complete.</li> </ol> <p></p>","title":"2. Settings"},{"location":"apps/petio/","text":"","title":"Petio"},{"location":"apps/petio/#what-is-it","text":"<p>Petio is a third party companion app available to Plex server owners to allow their users to request, review and discover content. The app is built to appear instantly familiar and intuitive to even the most tech-agnostic users. Petio will help you manage requests from your users, connect to other third party apps such as Sonarr and Radarr, notify users when content is available and track request progress. Petio also allows users to discover media both on and off your server, quickly and easily find related content and review to leave their opinion for other users.</p> <p>Petio is an ongoing, forever free, always evolving project currently in alpha prototype stage and now available!</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"apps/petio/#1-installation","text":"<pre><code>sb install petio\n</code></pre>","title":"1. Installation"},{"location":"apps/petio/#2-url","text":"<ul> <li>To access Petio, visit <code>https://petio._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"apps/petio/#3-setup","text":"<ul> <li> <p>Click Login With Plex and follow the steps to log in.</p> </li> <li> <p>After you log in with Plex you will need to specify your Petio specific admin credentials, by default it uses your Plex username and email but you still need to specify your own password.</p> </li> <li> <p>After setting up your credentials, you need to pick your Plex server.</p> </li> <li> <p>Leave MongoDB settings as default.</p> </li> <li> <p>Once the last step is finished, you will be presented with a login screen. Use your Plex username and the password you set up on Step 2. You can now get started with configuring Radarr, Sonarr and start requesting!</p> </li> <li> <p>See the Petio documentation for more information.</p> </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"apps/plex-autoscan/","text":"","title":"Plex Autoscan"},{"location":"apps/plex-autoscan/#what-is-it","text":"<p>Plex Autoscan (by l3uddz) is a script that assists Plex with the adding media files, that were imported by Sonarr / Radarr, by only scanning the folder that has been imported (vs the entire section library folder), thereby preventing Google API bans.</p> <p>Plex Autoscan comes configured out of the box (as related to Saltbox). However, there a few things that need to be set by you.</p>    Details         Project home  Docs  Github:  Docker","title":"What is it?"},{"location":"apps/plex-autoscan/#do-a-one-time-manual-scan-in-plex","text":"<ul> <li> <p>For Plex Autoscan to work, at least one item needs to exist in each library before new items can show up.</p> </li> <li> <p>If you already have media, simply add it to the library and do a manual scan within Plex, for each library you have, to build the DB.</p> </li> <li> <p>If you currently don\u2019t have any media, continue on with the setup, and when you have acquired some media, you will then perform a do a manual scan within Plex, for each library, to build the DB.</p> </li> <li> <p>For more info, see this.</p> </li> </ul>","title":"Do a One-Time, Manual Scan in Plex"},{"location":"apps/plex-autoscan/#add-your-plex-access-token-into-plex-autoscan-config","text":"<p>You can skip this step if you entered in your Plex credentials in accounts.yml during setup.</p> <p>Note: For Mediabox / Feederbox setups, the following will be done on the Mediabox.</p> <ol> <li> <p>Get your Plex Autoscan Token here.</p> </li> <li> <p>On the server's shell, run the following command:</p> <p><pre><code>nano /opt/plex_autoscan/config/config.json\n</code></pre>    3. Add the Plex Access Token to <code>\"PLEX_TOKEN\":</code> so that it now appears as:</p> <pre><code>\"PLEX_TOKEN\": \"xxxxxxxxxxxxxx\",\n</code></pre> <p>Note: Make sure it is within the quotes (<code>\"</code>) and there is a comma (<code>,</code>) after it.</p> </li> <li> <p>Ctrl + X Y Enter to save.</p> </li> </ol>","title":"Add Your Plex Access Token into Plex Autoscan Config"},{"location":"apps/plex-autoscan/#obtaining-the-plex-autoscan-url","text":"<p>Note: For Mediabox / Feederbox setup, the following will be done on the Mediabox.</p> <p>The Plex Autoscan URL is needed during the setup of Sonarr, Radarr, and Lidarr.</p> <p>To get your Plex Autoscan URL, run the following command:</p> <pre><code>/opt/scripts/plex_autoscan/plex_autoscan_url.sh\n</code></pre> <p>This will be in the format of:</p> <p><pre><code>http://subdomain.domain.com:plex_autoscan_port/plex_autoscan_pass\n</code></pre> or <pre><code>http://server_ip_address:plex_autoscan_port/plex_autoscan_pass\n</code></pre></p> <p>Example: <pre><code>http://plex.domain.com:3468/aiG7Uwie9iodTTlaisahcieNaeVonu6I\n</code></pre></p> <p>Note 1: The url will not use <code>plex.domain.com</code> if the IP address it points to does not match the server's IP address (e.g. Cloudflare CDN enabled).</p> <p>Note 2: If the url is <code>plex.domain.com</code>, but you decide to enable Cloudflare proxy for the <code>plex</code> subdomain later, you will need to generate another Plex Autoscan URL and add that into Sonarr/Radarr/Lidarr instead, as the scan request will need to go to you server's actual IP and not a Cloudflare one.</p> <p>Note 3: For Mediabox setups, make sure that the port is open in the firewall and/or router.</p> <p>Note 4: The PAS URL is not meant to be accessed via a browser by default (i.e. going there will give you a <code>401 Unauthorized</code> error). However, you can enable a web UI for manual scan requests, see here.</p>","title":"Obtaining the Plex Autoscan URL"},{"location":"apps/plex-autoscan/#4-upload-control-file-to-google-drive","text":"<p>If you used the scripted rclone setup; these control files were created for you.</p> <p>The following step is important so that Plex Autoscan can remove missing/replaced media files out of Plex (i.e. empty trash). Without it, Plex will be left with \"unavailable\" media that can't play (i.e. media posters with trash icons on them).</p> <p>For more details on what the control file is, see here.</p> <p>To upload the mounted.bin control file, run the following command:</p> <pre><code>rclone touch google:/mounted.bin\n</code></pre> <p>Note 1: If your Rclone remote config has a different name for Google Drive, replace <code>google:</code> with yours.</p> <p>Note 2: Above command requires Rclone version 1.39+</p> <p>Note 3: If you use different mount paths for your libraries in Plex this change must also be reflected in <code>/opt/plex_autoscan/config/config.json</code> in <code>SERVER_PATH_MAPPINGS</code>:</p> <p>Example:</p> <pre><code>  \"SERVER_PATH_MAPPINGS\": {\n    \"/mnt/unionfs/Media/Movies/\": [\n      \"/movies/\",\n      \"/mnt/unionfs/Media/Movies/\",\n      \"My Drive/Media/Movies/\"\n    ],\n</code></pre>","title":"4. Upload Control File to Google Drive"},{"location":"apps/plex-autoscan/#enabling-google-drive-monitoring-in-plex-autoscan","text":"<p>See the Plex-autoscan Extras page</p>","title":"Enabling Google Drive Monitoring in Plex Autoscan"},{"location":"apps/plex-autoscan/#invoking-a-manual-scan-in-plex-autoscan","text":"<p>See the Plex-autoscan Extras page</p>","title":"Invoking a manual scan in Plex Autoscan"},{"location":"apps/plex-autoscan/#plex-autoscan-is-installed-in-a-virtual-environment","text":"<p>To make this transparent to the user, saltbox installs a wrapper script that accounts for this.  This means that you can run Plex Autoscan manually like this:</p> <pre><code>plex_autoscan COMMAND\n</code></pre> <p>For example, if some documentation says you should run:</p> <pre><code>python scan.py sections\n</code></pre> <p>In saltbox you'd run:</p> <pre><code>plex_autoscan sections\n</code></pre> <p>If this doesn't work for you, update saltbox and rerun the plex-autoscan role:</p> <pre><code>sb update\nsb install plex-autoscan\n</code></pre>","title":"Plex Autoscan is installed in a Virtual Environment"},{"location":"apps/plex/","text":"","title":"Plex"},{"location":"apps/plex/#what-is-it","text":"<p>Plex is a media server.</p>    Details         Project home   Docs  Github  Docker","title":"What is it?"},{"location":"apps/plex/#url","text":"<ol> <li> <p>To access Plex, visit https://plex.yourdomain.com</p> </li> <li> <p>Login with your Plex account</p> <p></p> </li> </ol>","title":"URL"},{"location":"apps/plex/#setup-wizard","text":"<ol> <li> <p>First time you log in, you will be presented with a welcome screen. Click \"GOT IT!\" to continue.</p> <p></p> </li> <li> <p>Next screen will show you your server, with a randomly generated name. Give it a friendly name and click \"NEXT\".</p> <p></p> </li> <li> <p>On the next screen, click \"NEXT\" (we will add Libraries later).</p> <p></p> </li> <li> <p>Click \"DONE\".</p> <p></p> </li> </ol>  <p>Settings</p> LibraryNetworkTranscoderDLNAScheduled Tasks   <ol> <li> <p>Click the Settings icon (top right) \u2192 \"Server\" (top) \u2192 \"Library\" (left).</p> </li> <li> <p>Set the following:</p> <ul> <li> <p>\"Empty trash automatically after every scan\": <code>disabled</code></p> <ul> <li>Plex Autoscan will take care of this.</li> </ul> </li> <li> <p>\"Allow media deletion\": <code>enabled</code></p> </li> <li> <p>\"Generate video preview thumbnails\": <code>never</code></p> </li> <li> <p>\"Generate chapter thumbnails\": <code>never</code></p>  <p>The reasoning behind disabling these thumbnails is related to Google Drive API usage, data transfer, and disk space.  Accessing large portions of a given video file to generate thumbnails may generate large numbers of Google Drive API calls, and large amounts of data transfer.  Either of these things may result in your account suffering one of the various types of 24-hour bans Google hands out, which may prevent your server from playing media at all.  Also, storing these images will greatly inflate the size of <code>/opt/plex</code>, which can affect the speed of backups, your ability to download, and anything else related to disk space usage.  These are generally considered Bad Things, so the recommendation is to avoid the possibility by turning these options off.</p>  </li> </ul> </li> <li> <p>Click \"SAVE CHANGES\".</p> <p></p> </li> </ol>   <ol> <li> <p>Click the Settings icon (top right) \u2192 \"Server\" (top) \u2192 \"Network\" (left).</p> </li> <li> <p>Set the following:</p> <ul> <li> <p>\"Secure Connections\": <code>Preferred</code>.</p> </li> <li> <p>\"Enable local network discovery (GDM)\": <code>disabled</code>.</p> </li> <li> <p>\"Remote streams allowed per user\": your preference.</p> </li> <li> <p>\"Custom server access URLs\": <code>http://plex.yourdomain.com:80/,https://plex.yourdomain.com:443/</code> (pre-filled)</p> <ul> <li>NOTE: Enter your domain as you have it configured in accounts.yml, not literally \"yourdomain.com\".</li> </ul> </li> </ul> </li> <li> <p>Click \"SAVE CHANGES\".</p> <p></p> </li> </ol>   <ol> <li> <p>Click the Settings icon (top right) \u2192 \"Server\" (top) \u2192 \"Transcoder\" (left).</p> </li> <li> <p>Set the following:</p> <ul> <li> <p>\"Transcoder temporary directory\": <code>/transcode</code></p> </li> <li> <p>\"Transcoder default throttle buffer\": <code>150</code></p> </li> <li> <p>\"Use hardware acceleration when available\": <code>enabled</code></p> </li> <li> <p>\"Maximum simultaneous video transcode\": <code>unlimited</code></p> </li> </ul> </li> <li> <p>Click \"SAVE CHANGES\".</p> <p></p> </li> </ol>   <ol> <li> <p>Click the Settings icon (top right) \u2192 \"Server\" (top) \u2192 \"DLNA\" (left).</p> </li> <li> <p>Set the following:</p> <ul> <li> <p>\"Enable the DLNA server\": <code>disabled</code></p> </li> <li> <p>\"DLNA server timeline reporting\": <code>disabled</code></p> </li> </ul> </li> <li> <p>Click \"SAVE CHANGES\".</p> <p></p> </li> </ol>   <ol> <li> <p>Click the Settings icon (top right) \u2192 \"Server\" (top) \u2192 \"Scheduled Tasks\" (left).</p> </li> <li> <p>Set the following:</p> <ul> <li> <p>\"Update all libraries during maintenance\": <code>disabled</code></p> </li> <li> <p>\"Upgrade media analysis during maintenance\": <code>disabled</code></p> </li> <li> <p>\"Perform extensive media analysis during maintenance\": <code>disabled</code></p> </li> </ul> </li> <li> <p>Click \"SAVE CHANGES\".</p> <p></p> </li> </ol>","title":"Setup Wizard"},{"location":"apps/plex/#add-media-libraries","text":"<p>In this section, we will add two libraries: one for Movies and one for TV.</p> <p>Note: If you would like to have custom Plex libraries (more than just a Movies and TV one), see Customizing Plex Libraries.</p>  <p>Libraries</p> Add the Movie LibraryAdd the TV Library   <ol> <li> <p>In the main Plex screen (Home icon on the top left), click \"+\" next to \"LIBRARIES\".</p> <p></p> </li> <li> <p>In the \"Add Library\" window, select \"Movies\" and click \"NEXT\".</p> <p></p> </li> <li> <p>Click \"BROWSE FOR MEDIA FOLDER\".</p> <p></p> </li> <li> <p>Navigate to <code>/mnt/unionfs/Media/Movies</code>, and then click the \"ADD\" button.</p> <p></p> </li> <li> <p>You will now see <code>/mnt/unionfs/Media/Movies</code> in the text box (don't click \"ADD LIBRARY\" yet).</p> <p></p> </li> <li> <p>Click \"Advanced\" on the left.</p> </li> <li> <p>Set the following:</p> <ul> <li> <p>\"Enable Cinema Trailers\": <code>disabled</code> (optional)</p> </li> <li> <p>\"Enable video preview thumbnails\": <code>disabled</code></p> </li> <li> <p>\"Find trailers and extras automatically (Plex Pass required)\": <code>disabled</code> (optional)</p> </li> </ul> </li> <li> <p>Click \"ADD LIBRARY\".</p> <p></p> </li> </ol>   <ol> <li> <p>In the main Plex screen (Home icon on the top left), click \"+\" next to \"LIBRARIES\".</p> <p></p> </li> <li> <p>In the \"Add Library\" window, select \"TV Shows\" and click \"NEXT\".</p> <p></p> </li> <li> <p>Click \"BROWSE FOR MEDIA FOLDER\".</p> <p></p> </li> <li> <p>Navigate to <code>/mnt/unionfs/Media/TV</code>, and then click the \"ADD\" button.</p> <p></p> </li> <li> <p>You will now see <code>/mnt/unionfs/Media/TV</code> in the text box (don't click \"ADD LIBRARY\" yet).</p> <p></p> </li> <li> <p>Click \"Advanced\" on the left.</p> </li> <li> <p>Set the following:</p> <ul> <li> <p>\"Enable video preview thumbnails\": <code>disabled</code></p> </li> <li> <p>\"Find trailers and extras automatically (Plex Pass required)\": <code>disabled</code> (optional)</p> </li> </ul> </li> <li> <p>Click \"ADD LIBRARY\".</p> <p></p> </li> </ol>","title":"Add Media Libraries"},{"location":"apps/plex/#scan-media-libraries","text":"<p>As mentioned in the Introduction page, Plex Autoscan will automatically scan the media files into Plex as they are downloaded, but this will require the Plex database to not be completely empty. So for every new library that is added, a one-time, manual scan is required.</p> <p>To do so:</p> <ol> <li> <p>Click the 3 dots next to a Plex library.</p> </li> <li> <p>Select \"Scan Library Files\".</p> </li> </ol> <p></p> <ol> <li>Repeat steps 1-2 for each library.</li> </ol>","title":"Scan Media libraries"},{"location":"apps/plex/#webtools","text":"<p>Webtools for Plex comes preinstalled. If you wish to setup Webtools and install 3rd party add-ons, you can go to https://plex-webtools.yourdomain.com and log in with your Plex account.</p>","title":"Webtools"},{"location":"apps/portainer/","text":"<p>THIS PAGE HAS NOT BEEN FULLY UPDATED FOR SALTBOX</p>","title":"Portainer"},{"location":"apps/portainer/#what-is-it","text":"<p>Portainer is an open-source lightweight management UI which allows you to easily manage your Docker containers, images, networks and volumes.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"apps/portainer/#2-url","text":"<p>To access Portainer, visit  https://portainer.yourdomain.com</p>","title":"2. URL"},{"location":"apps/portainer/#3-initial-setup","text":"<ol> <li> <p>The first time you go to the Portainer page, you will be presented with the message \"Please create the initial administrator user.\". Fill in your preferred admin username and password. Click <code>Create User</code>.</p> <p></p> </li> <li> <p>On this first visit when you set up the admin user, you will be logged in automagically. On future visits, you will be asked to log in with your username and password.</p> <p></p> </li> <li> <p>On the \"Connect Portainer to the Docker environment you want to manage.\" screen, select <code>Local: Manage the local Docker environment</code> and click <code>Connect</code>.</p> <p>Note: Don't be confused by \"local\" in this context.  It is referring to the relationship between the Docker instance you're managing [on your Cloudbox] and this instance of Portainer [also on your Cloudbox].  These things are local to each other on your Cloudbox server, wherever that is.  They may be remote from you, but they are local to each other.  Pay no mind to what looks like a warning at the bottom.  Cloudbox has already taken care of that.</p> <p></p> </li> <li> <p>Portainer is now setup.</p> </li> </ol>","title":"3. Initial Setup"},{"location":"apps/prowlarr/","text":"","title":"Prowlarr"},{"location":"apps/prowlarr/#what-is-it","text":"<p>Prowlarr is an indexer manager/proxy built on the popular arr .net/reactjs base stack to integrate with your various PVR apps. Prowlarr supports management of both Torrent Trackers and Usenet Indexers. It integrates seamlessly with Lidarr, Mylar3, Radarr, Readarr, and Sonarr offering complete management of your indexers with no per app Indexer setup required (we do it all).</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"apps/prowlarr/#1-installation","text":"<pre><code>sb install prowlarr\n</code></pre>","title":"1. Installation"},{"location":"apps/prowlarr/#2-url","text":"<ul> <li>To access Prowlarr, visit <code>https://prowlarr._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"apps/prowlarr/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"apps/radarr/","text":"","title":"Radarr"},{"location":"apps/radarr/#what-is-it","text":"<p>Radarr is a movie collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new movies and will interface with clients and indexers to grab, sort, and rename them. It can also be configured to automatically upgrade the quality of existing files in the library when a better quality format becomes available.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"apps/radarr/#url","text":"<ul> <li>To access Radarr, visit https://radarr.yourdomain.com</li> </ul>","title":"URL"},{"location":"apps/radarr/#settings","text":"<p>Click on \"Settings\" in the sidebar.  Click \"Show Advanced\" at the top of the Settings pane.</p> <p>Make changes in the following sections:</p>  <p>Settings</p> Media ManagementIndexersDownload ClientsqBittorrentConnectGeneral   <p>These settings control management of media files.</p> Movie NamingFoldersImportingFile ManagementPermissionsSave   <ul> <li> <p>\"Rename Movies\": <code>Yes</code></p> </li> <li> <p>\"Replace Illegal Characters\": <code>Yes</code></p> </li> <li> <p>Colon Replacement Format: <code>Delete</code></p> </li> </ul> <p>Note: You could use <code>Replace with Space Dash</code> but only if your file naming format is not using spaces (e.g. using dots) to separate words.</p> <ul> <li>Set your preferred naming format; here are some examples.</li> </ul> <p> Plex's Naming Preference  Example:  <pre><code>/Guardians of the Galaxy (2014)/Guardians of the Galaxy (2014).mkv\n</code></pre> <p>Standard Movie Format:  <pre><code>{Movie Title} ({Release Year})\n</code></pre></p> <p>Movie Folder Format:  <pre><code>{Movie Title} ({Release Year})\n</code></pre></p> <p>Reference: https://support.plex.tv/articles/200381023-naming-movie-files/ </p> <p> Radarr's Wiki Example  Example:   <pre><code>The Movie Title (2010) - [ULTIMATE EXTENDED EDITION][BLURAY-1080P PROPER][DTS 5.1][X264]-EVOLVE.mkv\n</code></pre> <p>Standard Movie Format:  <pre><code>{Movie Title} ({Release Year}) - {[EDITION TAGS]}{[QUALITY FULL]}{[MEDIAINFO AUDIOCODEC}{ MEDIAINFO AUDIOCHANNELS]}{[MEDIAINFO VIDEOCODEC]}{-RELEASE GROUP}\n</code></pre></p> <p>Reference: https://github.com/Radarr/Radarr/wiki/Sorting-and-Renaming </p> <p> TRaSH' naming guide  Example:   <pre><code>The Movie Title (2010) Ultimate Extended Edition [imdb-tt0066921][Surround Sound x264][Bluray-1080p Proper][3D][HDR][10bit][x264][DTS 5.1]-EVOLVE.mkv\n</code></pre> <p>Standard Movie Format:  <pre><code>{Movie CleanTitle} {(Release Year)} {Edition Tags} [imdb-{ImdbId}]{[Custom Formats]}{[Quality Full]}{[MediaInfo 3D]}{[MediaInfo VideoDynamicRange]}[{Mediainfo VideoBitDepth}bit][{Mediainfo VideoCodec}]{[Mediainfo AudioCodec}{ Mediainfo AudioChannels}]{-Release Group}\n</code></pre></p> <p>Reference: https://trash-guides.info/Radarr/Radarr-recommended-naming-scheme/ </p>   <ul> <li> <p>\"Create empty movie folders\": <code>No</code></p> </li> <li> <p>\"Automatically Rename Folders\": <code>No</code></p> </li> <li> <p>\"Movie Paths Default to Static\": <code>No</code></p> </li> </ul>   <ul> <li> <p>\"Skip Free Space Check\": <code>No</code></p> </li> <li> <p>\"Use Hardlinks instead of Copy\": <code>Yes</code></p> </li> <li> <p>\"Import Extra Files\": <code>Yes</code> (can be your preference)</p> </li> <li> <p>\"Extra File Extensions\": <code>srt, sub, idx</code></p> </li> </ul>   <ul> <li> <p>\"Ignore Deleted Movies\": <code>No</code> (can be your preference)</p> </li> <li> <p>\"Download Propers\": <code>No</code> (can be your preference)</p> </li> <li> <p>\"Analyse video files\": <code>No</code></p> </li> <li> <p>\"Change File Date\": <code>None</code></p> </li> <li> <p>\"Recycle Bin\": blank (Rclone deletes are sent to Gdrive trash folder, anyway)</p> </li> </ul>   <ul> <li>Set Permissions: <code>No</code></li> </ul>   <ul> <li>Click \"Save\".</li> </ul>      <p>These settings control indexers and related behavior.</p> NZBHydra2Jackett   <ol> <li> <p>Click Add Indexer (<code>+</code>).</p> </li> <li> <p>Select \"Newznab\".</p> </li> <li> <p>Add the following:</p> <p>Name: NZBHydra2</p> <p>Enable RSS Sync: Your Preference</p> <p>Enable Search: Your Preference</p> <p>URL: <code>http://nzbhydra2:5076</code></p> <p>API Key: Your NZBHydra2 API Key</p> <p>Additional Parameters: Leave Blank</p> </li> <li> <p>Your settings will look like this:</p> <p></p> </li> <li> <p>Click \"Save\" to add NZBHydra2.</p> </li> </ol> <p>Note: The \"Test\" will keep failing until you add an indexer in NZBHydra2.</p>   <p>Note: Each Indexer you have defined in Jackett will need to be added separately.</p> <ol> <li> <p>Click Add Indexer (<code>+</code>)</p> </li> <li> <p>Select \"Torznab\".</p> </li> <li> <p>Add the following:</p> <p>Name: Indexer Name</p> <p>Enable RSS Sync: Your Preference</p> <p>Enable Search: Your Preference</p> <p>URL: Indexer's Torznab Feed</p> <p>API Key: Your Jackett API Key</p> <p>Additional Parameters: Leave Blank</p> </li> <li> <p>Your settings will look like this:</p> <p></p> </li> <li> <p>Click \"Save\" to add the indexer.</p> </li> </ol>      <p>These settings control downloading behavior and clients.</p> Completed Download HandlingFailed Download HandlingNZBGetruTorrent   <ul> <li> <p>\"Enable\": <code>Yes</code></p> </li> <li> <p>\"Remove\": <code>Yes</code> (can be your preference)</p> </li> </ul>   <ul> <li> <p>\"Redownload\": <code>Yes</code></p> </li> <li> <p>\"Remove\": <code>Yes</code></p> </li> </ul>   <ol> <li> <p>Click Add (<code>+</code>)</p> </li> <li> <p>Add a new \"NZBGet\" download client.</p> </li> <li> <p>Add the following:</p> <p>Name: NZBGet</p> <p>Enable: <code>Yes</code></p> <p>Host: <code>nzbget</code></p> <p>Port: <code>6789</code></p> <p>Username:  Your NZBGet Username</p> <p>Password:  Your NZBGet Password</p> <p>Category: <code>radarr</code></p> <p>Use SSL: <code>No</code></p> <p>Add Paused: <code>No</code></p> </li> <li> <p>Your settings will look like this:</p> <p></p> </li> <li> <p>Click \"Save\" to add NZBGet.</p> </li> </ol>   <ol> <li> <p>Click Add (<code>+</code>)</p> </li> <li> <p>Add a new \"rTorrent\" download client.</p> </li> <li> <p>Add the following:</p> <p>Name: ruTorrent</p> <p>Enable: <code>Yes</code></p> <p>Host: <code>rutorrent</code></p> <p>Port: <code>80</code></p> <p>URL Path: <code>RPC2</code></p> <p>Use SSL: <code>No</code></p> <p>Username: Your ruTorrent Username</p> <p>Password: Your ruTorrent Password</p> <p>Category: <code>radarr</code></p> <p>Directory: Leave Blank</p> </li> <li> <p>Your settings will now look like this:</p> <p></p> </li> <li> <p>Click \"Save\" to add ruTorrent.</p> </li> </ol>      <ol> <li> <p>Click Add ('+')</p> </li> <li> <p>Add a new \"qBittorrent\" download client.</p> </li> <li> <p>Add the following:</p> </li> </ol> <p>Name: qBittorrent</p> <p>Enable: 'Yes'</p> <p>Host: 'qBittorrent'</p> <p>Port: '8080'</p> <pre><code>    Username: [Your qBittorrent Username](../community/apps/qbittorrent.md)\n\n    Password: [Your qBittorrent Password](../community/apps/qbittorrent.md)\n</code></pre> <p>Category: 'radarr'</p> <ol> <li>Your settings will now look like this:</li> </ol> <p></p> <ol> <li>Click \"Save\" to add qBittorrent qb</li> </ol>   <p>These settings control connections to other applications or systems.</p> Torrent CleanupPlex Autoscan   <p>Torrent Cleanup Script is a custom script that will cleanup torrents from ruTorrent that were auto-extracted, but still being seeded. So if the script detects that <code>.rar</code> files are in the folder that Radarr just imported from, it will delete the imported video file(s), leaving just the <code>.rar</code> files for seeding.</p> <ol> <li> <p>Click \"Settings\" -&gt; \"Connect\".</p> </li> <li> <p>Add a new \"Custom Script\".</p> </li> <li> <p>Add the following:</p> <p>Name: Torrent Cleanup</p> <p>On Grab: <code>No</code></p> <p>On Download: <code>Yes</code></p> <p>On Upgrade:  <code>Yes</code></p> <p>On Rename:<code>No</code></p> <p>Path: <code>/scripts/torrents/TorrentCleanup.py</code></p> </li> <li> <p>The settings will look like this:</p> <p></p> </li> <li> <p>Click \"Save\" to add the Torrent Cleanup script.</p> </li> </ol>   <ol> <li> <p>Click \"Settings\" -&gt; \"Connect\".</p> </li> <li> <p>Add a new \"Webhook\".</p> </li> <li> <p>Add the following:</p> <p>Name: Plex Autoscan</p> <p>On Grab: <code>No</code></p> <p>On Download: <code>Yes</code></p> <p>On Upgrade:  <code>Yes</code></p> <p>On Rename: <code>Yes</code></p> <p>Filter Movie Tags: Leave Blank</p> <p>URL: Your Plex Autoscan URL</p> <p>Method:<code>POST</code></p> <p>Username: Leave Blank</p> <p>Password: Leave Blank</p> </li> <li> <p>The settings will look like this:</p> <p></p> </li> <li> <p>Click \"Save\" to add Plex Autoscan.</p> </li> </ol>      <p>These settings control general aspects of Radarr.</p> Start-UpProxy SettingsLoggingAnalyticsUpdatesSave   <ul> <li> <p>\"Bind Address: <code>*</code></p> </li> <li> <p>\"Port Number\": <code>7878</code></p> </li> <li> <p>\"URL Base\": blank</p> </li> <li> <p>\"Enable SSL\": <code>No</code> (SSL is handled by Traefik)</p> </li> </ul>   <ul> <li>\"Use Proxy\": <code>No</code></li> </ul>   <ul> <li>\"Log Level\": <code>Debug</code></li> </ul>   <ul> <li>\"Enable\": <code>No</code> (your preference)</li> </ul>   <ul> <li> <p>\"Branch\": <code>nightly</code> or <code>develop</code></p> </li> <li> <p>\"Automatic\": <code>Off</code></p> </li> </ul>   <ul> <li>Click \"Save\".</li> </ul>","title":"Settings"},{"location":"apps/radarr/#movies-path","text":"<ol> <li> <p>When you are ready to add your first movie to Radarr, click the \"Path\" drop-down and select \"Add a different path\".</p> </li> <li> <p>Click the blue \"Browse\" button, navigate to <code>/mnt/unionfs/Media/Movies</code>, scroll to the bottom, and select \"OK\".</p> </li> <li> <p>Click the green \"check\" button to add the path.</p> </li> <li> <p>All movies added now will have that path set.</p> </li> </ol>","title":"Movies Path"},{"location":"apps/radarr/#api-key","text":"<p>This is used during the setup of Overseerr and Organizr.</p> <ul> <li>Go to \"Settings\" -&gt; \"General\" -&gt; \"Security\" -&gt; \"API Key\".</li> </ul>","title":"API Key"},{"location":"apps/rutorrent/","text":"<p>THIS PAGE HAS NOT BEEN FULLY UPDATED FOR SALTBOX</p>","title":"Rutorrent"},{"location":"apps/rutorrent/#what-is-it","text":"<p>ruTorrent (by Novik) is a front-end for the popular, lightweight, and extensible BitTorrent client rtorrent (by Jari Sundell aka rakshasa).</p> <p>Note: public trackers are disabled by default in the standard install.  Refer to the FAQ for instructions on re-enabling them.</p>    Details          Project home  Docs  Github: ruTorrent  Github: rTorrent  Docker","title":"What is it?"},{"location":"apps/rutorrent/#1-url","text":"<ul> <li>To access ruTorrent, visit https://rutorrent.yourdomain.com</li> </ul>","title":"1. URL"},{"location":"apps/rutorrent/#2-basics","text":"","title":"2. Basics"},{"location":"apps/rutorrent/#setup","text":"<p>The setup for Sonarr, Radarr, and Lidarr are done on their respective wiki pages.</p>","title":"Setup"},{"location":"apps/rutorrent/#3-enable-autounpack","text":"<p>AutoUnpack is a plugin that will automatically unrar/unzip torrent data.</p> <p>This will allow Sonarr/Radarr/Lidarr to import the media files that would otherwise be ignored. After Sonarr and Radarr import the media files, Torrent Cleanup Script will then delete the extracted media files and ruTorrent will continue to seed the torrents (until they are either removed manually or automatically via ruTorrent's Ratio Group rules).</p> <p>To enable AutoUnpack:</p> <ol> <li> <p>Open \"Settings\" by clicking the gear icon  at the top</p> </li> <li> <p>Go to \"Unpack\" on the left.</p> </li> <li> <p>Check \"Enable autounpacking if torrents label matches filter\" and add the following:</p> </li> </ol> <pre><code>/.*(radarr|sonarr|lidarr).*/i\n</code></pre> <ol> <li> <p>Leave the other fields blank.</p> </li> <li> <p>Your settings will now look like this:</p> </li> </ol> <p></p> <ol> <li>Click \"OK\".</li> </ol>","title":"3. Enable AutoUnpack"},{"location":"apps/rutorrent/#3-custom-plugins-and-themes","text":"<p>You can have custom plugins and themes imported during Docker container rebuild. Just place them in the following paths:</p> <pre><code>/opt/rutorrent/plugins/\n</code></pre> <pre><code>/opt/rutorrent/themes/\n</code></pre> <p>And then restart the Docker container:</p> <pre><code>docker restart rutorrent\n</code></pre>","title":"3. Custom Plugins and Themes"},{"location":"apps/sabnzbd/","text":"<p>THIS PAGE HAS NOT BEEN FULLY UPDATED FOR SALTBOX</p>","title":"Sabnzbd"},{"location":"apps/sabnzbd/#what-is-it","text":"<p>SABnzbd is an Open Source Binary Newsreader written in Python.</p> <p>It's totally free, easy to use, and works practically everywhere. SABnzbd makes Usenet as simple and streamlined as possible by automating everything we can. All you have to do is add an .nzb. SABnzbd takes over from there, where it will be automatically downloaded, verified, repaired, extracted and filed away with zero human interaction. SABnzbd offers an easy setup wizard and has self-analysis tools to verify your setup.</p>    Details         Project home   Docs  Github:  Docker     <ul> <li>Install tag: <code>--tags sabnzbd</code></li> </ul>","title":"What is it?"},{"location":"apps/sabnzbd/#1-url","text":"<ul> <li>To access sabnzbd, visit https://sabnzbd.yourdomain.com</li> </ul>","title":"1. URL"},{"location":"apps/sabnzbd/#2-basics","text":"<ul> <li>Go through the setup wizard.  YOu will need to enter server details:</li> </ul> <p></p> <ul> <li>When you get to the end of the wizard, click \"Go To SABnzbd\"</li> </ul> <p></p> <ul> <li>Go to SABnzbd Config</li> </ul> <p></p> <ul> <li>You will need to add in categories for <code>sonarr</code>, <code>radarr</code>, and <code>lidarr</code>.</li> </ul> <p>Set a relative directory name for each category.</p> <p>You will need a category for each instance of <code>sonarr</code>/<code>radarr</code>/<code>lidarr</code> [for example, if you have a <code>radarr</code> and <code>radarr4k</code> you will need a category for each]</p> <p>SABnzbd requires the server to be filled in to set categories up.</p> <p>This needs to be done BEFORE adding sabnzbd as a downloader to any of those apps.</p> <p></p> <ul> <li> <p>Direct unpack is disabled by default. Configure this as you prefer.</p> </li> <li> <p>Make note of the API Key in the \"General\" section</p> </li> </ul> <p></p> <ul> <li>When creating the connection in the arrs, use API Key rather than user/pass.</li> </ul> <p></p> <p>Note that the category matches between Radarr and Sab.  The specific category doesn't matter; just that they match.</p>","title":"2. Basics"},{"location":"apps/sonarr/","text":"","title":"Sonarr"},{"location":"apps/sonarr/#what-is-it","text":"<p>Sonarr is a PVR for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new episodes of your favorite shows and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"apps/sonarr/#url","text":"<ul> <li>To access Sonarr, visit https://sonarr.yourdomain.com</li> </ul>","title":"URL"},{"location":"apps/sonarr/#settings","text":"<p>Click on \"Settings\" in the sidebar.  Click \"Show Advanced\" at the top of the Settings pane.</p> <p>Make changes in the following sections:</p>  <p>Settings</p> Media ManagementIndexersDownload ClientsConnectGeneral   <p>These settings control management of media files.</p> Episode NamingFoldersImportingFile ManagementPermissionsSave   <ul> <li> <p>\"Rename Episodes\": <code>Yes</code></p> </li> <li> <p>\"Replace Illegal Characters\": <code>Yes</code></p> </li> <li> <p>Set your preferred naming format; here are some examples:</p> <p> Plex's Naming Preference <p>Example:  <pre><code>/Gotham/Season 01/Gotham - s01e01 - Pilot.mkv\n</code></pre></p> <p>Standard Episode Format:  <pre><code>{Series Title} - s{season:00}e{episode:00} - {Episode Title}\n</code></pre></p> <p>Anime Episode Format:  <pre><code>{Series Title} - s{season:00}e{episode:00} - {Episode Title}\n</code></pre></p> <p>Daily Episode Format:  <pre><code>{Series Title} - {Air-Date} - {Episode Title}\n</code></pre></p> <p>Season Folder Format:  <pre><code>Season {season:00}\n</code></pre></p> <p>Multi-Episode Style:  <pre><code>Prefixed Range\n</code></pre></p> <p>Reference: https://support.plex.tv/articles/200220687-naming-series-season-based-tv-shows/   </p> <p> TRaSH' naming guide  <p>Example:   <pre><code>Single Episode:\n\nThe Series Title! (2010) - S01E01 - Episode Title 1 [AMZN WEBDL-1080p Proper][HDR][10bit][x264][DTS 5.1]-RlsGrp\n\nMulti Episode:\n\nThe Series Title! (2010) - S01E01-E02-E03 - Episode Title [AMZN WEBDL-1080p Proper][HDR][10bit][x264][DTS 5.1]-RlsGrp\n</code></pre></p> <p>Standard Episode Format:  <pre><code>{Series TitleYear} - S{season:00}E{episode:00} - {Episode CleanTitle} [{Preferred Words }{Quality Full}]{[MediaInfo VideoDynamicRange]}[{MediaInfo VideoBitDepth}bit]{[MediaInfo VideoCodec]}{[Mediainfo AudioCodec}{ Mediainfo AudioChannels]}{MediaInfo AudioLanguages}{-Release Group}\n</code></pre></p> <p>for more examples and discussion see the reference: https://trash-guides.info/Sonarr/Sonarr-recommended-naming-scheme/ </p>     <ul> <li> <p>\"Create empty series folders\": <code>No</code></p> </li> <li> <p>\"Delete empty folders\": <code>No</code></p> </li> </ul>   <ul> <li> <p>\"Skip Free Space Check\": <code>No</code></p> </li> <li> <p>\"Use Hardlinks instead of Copy\": <code>Yes</code></p> </li> <li> <p>\"Import Extra Files\": <code>Yes</code> (can be your preference)</p> </li> <li> <p>\"Extra File Extensions\": <code>srt, sub, idx</code></p> </li> </ul>   <ul> <li> <p>\"Ignore Deleted Episodes\": <code>No</code> (can be your preference)</p> </li> <li> <p>\"Download Propers\": <code>No</code> (can be your preference)</p> </li> <li> <p>\"Analyse video files\": <code>No</code></p> </li> <li> <p>\"Change File Date\": <code>None</code></p> </li> <li> <p>\"Recycle Bin\": blank (Rclone deletes are sent to Gdrive trash folder, anyway)</p> </li> </ul>   <ul> <li>Set Permissions: <code>No</code></li> </ul>   <ul> <li>Click \"Save\".</li> </ul>      <p>These settings control indexers and related behavior.</p> NZBHydra2Jackett   <ol> <li> <p>Click Add Indexer (<code>+</code>).</p> </li> <li> <p>Select \"Newznab\".</p> </li> <li> <p>Add the following:</p> <p>Name: NZBHydra2</p> <p>Enable RSS Sync: Your Preference</p> <p>Enable Search: Your Preference</p> <p>URL: <code>http://nzbhydra2:5076</code></p> <p>API Key: Your NZBHydra2 API Key</p> <p>Additional Parameters: Leave Blank</p> </li> <li> <p>Your settings will look like this:</p> <p></p> </li> <li> <p>Click \"Save\" to add NZBHydra2.</p> </li> </ol> <p>Note: The \"Test\" will keep failing until you add an indexer in NZBHydra2.</p>   <p>Note: Each Indexer you have defined in Jackett will need to be added separately.</p> <ol> <li> <p>Click Add Indexer (<code>+</code>)</p> </li> <li> <p>Select \"Torznab\".</p> </li> <li> <p>Add the following:</p> <p>Name: Indexer Name</p> <p>Enable RSS Sync: Your Preference</p> <p>Enable Search: Your Preference</p> <p>URL: Indexer's Torznab Feed</p> <p>API Key: Your Jackett API Key</p> <p>Additional Parameters: Leave Blank</p> </li> <li> <p>Your settings will look like this:</p> <p></p> </li> <li> <p>Click \"Save\" to add the indexer.</p> </li> </ol>      <p>These settings control downloading behavior and clients.</p> Completed Download HandlingFailed Download HandlingNZBGetruTorrent   <ul> <li> <p>\"Enable\": <code>Yes</code></p> </li> <li> <p>\"Remove\": <code>Yes</code> (can be your preference)</p> </li> </ul>   <ul> <li> <p>\"Redownload\": <code>Yes</code></p> </li> <li> <p>\"Remove\": <code>Yes</code></p> </li> </ul>   <ol> <li> <p>Click Add (<code>+</code>)</p> </li> <li> <p>Add a new \"NZBGet\" download client.</p> </li> <li> <p>Add the following:</p> <p>Name: NZBGet</p> <p>Enable: <code>Yes</code></p> <p>Host: <code>nzbget</code></p> <p>Port: <code>6789</code></p> <p>Username:  Your NZBGet Username</p> <p>Password:  Your NZBGet Password</p> <p>Category: <code>sonarr</code></p> <p>Use SSL: <code>No</code></p> <p>Add Paused: <code>No</code></p> </li> <li> <p>Your settings will look like this:</p> <p></p> </li> <li> <p>Click \"Save\" to add NZBGet.</p> </li> </ol>   <ol> <li> <p>Click Add (<code>+</code>)</p> </li> <li> <p>Add a new \"rTorrent\" download client.</p> </li> <li> <p>Add the following:</p> <p>Name: ruTorrent</p> <p>Enable: <code>Yes</code></p> <p>Host: <code>rutorrent</code></p> <p>Port: <code>80</code></p> <p>URL Path: <code>RPC2</code></p> <p>Use SSL: <code>No</code></p> <p>Username: Your ruTorrent Username</p> <p>Password: Your ruTorrent Password</p> <p>Category: <code>sonarr</code></p> <p>Directory: Leave Blank</p> </li> <li> <p>Your settings will now look like this:</p> <p></p> </li> <li> <p>Click \"Save\" to add ruTorrent.</p> </li> </ol>      <p>These settings control connections to other applications or systems.</p> Torrent CleanupPlex Autoscan   <p>Torrent Cleanup Script is a custom script that will cleanup torrents from ruTorrent that were auto-extracted, but still being seeded. So if the script detects that <code>.rar</code> files are in the folder that Sonarr just imported from, it will delete the imported video file(s), leaving just the <code>.rar</code> files for seeding.</p> <ol> <li> <p>Click \"Settings\" -&gt; \"Connect\".</p> </li> <li> <p>Add a new \"Custom Script\".</p> </li> <li> <p>Add the following:</p> <p>Name: Torrent Cleanup</p> <p>On Grab: <code>No</code></p> <p>On Download: <code>Yes</code></p> <p>On Upgrade:  <code>Yes</code></p> <p>On Rename:<code>No</code></p> <p>Path: <code>/scripts/torrents/TorrentCleanup.py</code></p> </li> <li> <p>The settings will look like this:</p> <p></p> </li> <li> <p>Click \"Save\" to add the Torrent Cleanup script.</p> </li> </ol>   <ol> <li> <p>Click \"Settings\" -&gt; \"Connect\".</p> </li> <li> <p>Add a new \"Webhook\".</p> </li> <li> <p>Add the following:</p> <p>Name: Plex Autoscan</p> <p>On Grab: <code>No</code></p> <p>On Download: <code>Yes</code></p> <p>On Upgrade:  <code>Yes</code></p> <p>On Rename: <code>Yes</code></p> <p>Filter Movie Tags: Leave Blank</p> <p>URL: Your Plex Autoscan URL</p> <p>Method:<code>POST</code></p> <p>Username: Leave Blank</p> <p>Password: Leave Blank</p> </li> <li> <p>The settings will look like this:</p> <p></p> </li> <li> <p>Click \"Save\" to add Plex Autoscan.</p> </li> </ol>      <p>These settings control general aspects of Sonarr.</p> Start-UpProxy SettingsLoggingAnalyticsUpdatesSave   <ul> <li> <p>\"Bind Address: <code>*</code></p> </li> <li> <p>\"Port Number\": <code>8989</code></p> </li> <li> <p>\"URL Base\": blank</p> </li> <li> <p>\"Enable SSL\": <code>No</code> (SSL is handled by Traefik)</p> </li> </ul>   <ul> <li>\"Use Proxy\": <code>No</code></li> </ul>   <ul> <li>\"Log Level\": <code>Debug</code></li> </ul>   <ul> <li>\"Enable\": <code>No</code> (your preference)</li> </ul>   <ul> <li> <p>\"Branch\": <code>main</code></p> </li> <li> <p>\"Automatic\": <code>Off</code></p> </li> </ul>   <ul> <li>Click \"Save\".</li> </ul>","title":"Settings"},{"location":"apps/sonarr/#tv-path","text":"<ol> <li> <p>When you are ready to add your first show to Sonarr, click the \"Path\" drop-down and select \"Add a different path\".</p> </li> <li> <p>Click the blue \"Browse\" button, navigate to <code>/mnt/unionfs/Media/TV</code>, scroll to the bottom, and select \"OK\".</p> </li> <li> <p>Click the green \"check\" button to add the path.</p> </li> <li> <p>All TV shows added now will have that path set.</p> </li> </ol>","title":"TV Path"},{"location":"apps/sonarr/#api-key","text":"<p>This is used during the setup of Overseer and Organizr.</p> <ul> <li>Go to \"Settings\" -&gt; \"General\" -&gt; \"Security\" -&gt; \"API Key\".</li> </ul>","title":"API Key"},{"location":"apps/sstv/","text":"<p>THIS PAGE HAS NOT BEEN FULLY UPDATED FOR SALTBOX</p>","title":"SSTV"},{"location":"apps/tautulli/","text":"","title":"Tautulli"},{"location":"apps/tautulli/#what-is-it","text":"<p>Tautulli (Tautulli), by JonnyWong16, is a web-based application runs alongside the Plex Media Server to monitor activity and track various statistics (eg most watched media).</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"apps/tautulli/#2-url","text":"<p>To access Tautulli, visit https://tautulli.yourdomain.com</p>","title":"2. URL"},{"location":"apps/tautulli/#3-setup-wizard","text":"<ol> <li> <p>First time you go to the Tautulli site, you will be presented with the \"Tautulli Setup Wizard\". Click <code>Next</code>.</p> <p></p> </li> <li> <p>On the \"Plex Authentication\" page, sign in with your Plex username and password, and click <code>Authenticate</code>. When you see the \"Authentication successful.\" message, click <code>Next</code>.</p> <p></p> </li> <li> <p>On the \"Plex Media Server\" page, set the following:</p> <ul> <li>\"Plex IP or Hostname\": <code>plex</code></li> <li>\"Port Number\": <code>32400</code></li> <li>\"Use SSL\": disabled</li> <li>\"Remote Server\": disabled</li> </ul> <p>Click <code>Verify</code>. When you see the \"Server found!\" message, click <code>Next</code>.</p> <p></p> </li> <li> <p>On the \"Activity Logging\" page, select your preferences (default is OK) and click <code>Next</code>.</p> <p></p> </li> <li> <p>On the \"Notifications\" page, simply click <code>Next</code>.</p> <p></p> </li> <li> <p>On the \"Database Import\" page, click <code>Finish</code> to complete the setup.</p> <p></p> </li> </ol>","title":"3. Setup Wizard"},{"location":"apps/tautulli/#4-settings","text":"<ol> <li> <p>Once the Tautulli page comes up, go to \"Settings\".</p> <p></p> </li> <li> <p>Click \"Web Interface\" on the left. Fill in \"HTTP Username\" and \"HTTP Password (this will be the login for your Tautulli site), but don't click <code>Save</code> yet.</p> <p></p> </li> <li> <p>Click \"Plex Media Server\" on the left. Click \"Show Advanced\" at the top. Under \"Logs Folder\", type in <code>/logs</code>. Now you can click <code>Save</code>. Also verify 'Use SSL' and 'Remote Server` are unchecked.</p> <p></p> </li> <li> <p>On the \"Restart\" popup window, click <code>Restart</code>.</p> <p></p> </li> </ol>","title":"4. Settings"},{"location":"apps/transfer/","text":"","title":"transfer.sh"},{"location":"apps/transfer/#what-is-it","text":"<p>transfer.sh is an easy and fast file sharing from the command-line or web gui app.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"apps/transfer/#1-installation","text":"<pre><code>sb install transfer\n</code></pre>","title":"1. Installation"},{"location":"apps/transfer/#2-url","text":"<ul> <li>To access transfer.sh, visit <code>https://transfer._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"apps/transfer/#3-setup","text":"<ul> <li> <p>The pre-configured username/password are taken from your Saltbox <code>accounts.yml</code> file located in <code>/srv/git/saltbox/accounts.yml</code>.</p> </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"community/","text":"Role Tags     bazarr cm-bazarr   bazarrx cm-bazarrx   deluge cm-deluge   delugex cm-delugex   hetzner_nfs cm-hetzner_nfs_server, cm-hetzner_nfs_server_uninstall, cm-hetzner_nfs_client_mount, cm-hetzner_nfs_client_unmount   qBittorrent cm-qbittorrent   qBittorrentx cm-qbittorrentx   readarr cm-readarr   readarrx cm-readarrx   settings cm-settings   tautullix cm-tautullix","title":"Community - All Apps Index"},{"location":"community/basics/","text":"<p>The Saltbox Community repository is installed with Saltbox as part of a standard install. The Saltbox Community application installers are provided and maintained by the community but subject to approval. The applications are not part of a standard Saltbox install, but they are tested and confirmed to be compatible with the Saltbox ecosystem.</p> <p>Community Guides are written by the community to help others make the most of their system.</p>","title":"Basics"},{"location":"community/basics/#update","text":"<p>To update Saltbox Community run a standard saltbox update and both community and Saltbox will be updated</p> <pre><code>sb update\n</code></pre> <p>To force update Saltbox Community settings.yml file run:</p> <pre><code>sb install cm-settings\n</code></pre>","title":"Update"},{"location":"community/basics/#how-to-install-community-apps","text":"<p>For most apps it is as simple as running the <code>sb install</code> command in a shell with a <code>cm-</code> prefix followed by the name of the role.</p> <pre><code>sb install cm-rolename\n</code></pre> <p>For example, to install a jellyfin server you would run the jellyfin role:-</p> <p><pre><code>sb install cm-jellyfin\n</code></pre> Before running any role you should first carefully read through the docs to see if there are any additional steps or pre configuration settings required.</p> <p>A list of all roles available to Saltbox can be called from the terminal via:-</p> <pre><code>sb list\n</code></pre>  <p>Tip</p> <p>Where possible the configured username/password are taken from your Saltbox <code>accounts.yml</code> file located in <code>/srv/git/saltbox/accounts.yml</code> and used to create a default user an password for logging in.</p>","title":"How to Install Community Apps"},{"location":"community/basics/#contributing-to-community-apps","text":"<p>Note: If you just want to install a container into the Saltbox system without creating a role, see this article.</p> <p>That work will also help you determine what you will need to do in a Community role, so starting there would not be wasted effort.</p> <p>If you want to create a Community role to allow others to install your role, keep reading.</p>","title":"Contributing to Community Apps"},{"location":"community/basics/#editing-an-existing-role","text":"<p>If you want to make a change to an existing role [for example, changing the docker image it uses], you don't have [or want to] to create a new role. You make changes like this for either core or community roles using the inventory system</p>","title":"Editing an existing role:"},{"location":"community/basics/#preparatory-work","text":"<p>Start by making your own fork of the community repo by clicking on the \"Fork\" button up and to the right.</p> <p>This will take you to your own copy of the community repo.</p> <p>On your development machine [which should probably be a machine running saltbox, as it makes things easier with regard to testing]:</p> <p>clone your community fork:</p> <pre><code>git clone https://github.com/YOURNAMEHERE/Community.git community\n</code></pre> <p>go into that local community dir:</p> <pre><code>cd community\n</code></pre> <p>make sure your local repo is up-to-date:</p> <pre><code>git pull\n</code></pre> <p>create your feature branch:</p> <pre><code>git checkout -b my-cool-role\n</code></pre>","title":"Preparatory work:"},{"location":"community/basics/#creating-a-role","text":"<p>Now you're ready to start work on your new role.</p> <p>A good starting point is to find a role that is similar to the one you want to add and use it as a starting point. For example, if your container requires mariadb and you want to create a database during setup, bookstack does that.</p> <p>copy the \"starting point\" role to your role:</p> <pre><code>cp -R roles/bookstack roles/my-cool-role\n</code></pre> <p>[of course, substitute whatever role you're using as your prototype for \"bookstack\"]</p> <p>Next step is to create the role. At a minimum, you will need to modify:</p> <pre><code>roles\n\u2514\u2500\u2500 my-cool-role\n \u00a0\u00a0 \u251c\u2500\u2500 defaults\n \u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 main.yml\n \u00a0\u00a0 \u2514\u2500\u2500 tasks\n \u00a0\u00a0     \u2514\u2500\u2500 main.yml\ncommunity.yml\n</code></pre> <p>There may be other things required; there may be templates or sub-tasks or what have you. Those three files are the absolute bare minimum that would need to be created to add a new role.</p> <p>What are those things?</p> <pre><code>roles/my-cool-role/defaults/main.yml\n</code></pre> <p>This file contains various details for your role; the docker image, the name, subdomain, that sort of thing. The stuff in there should be self-explanatory or understandable with comparisons to existing roles; if it's not, then with all respect you probably shouldn't be creating a role right now.</p> <pre><code>roles/my-cool-role/tasks/main.yml\n</code></pre> <p>This file drives the install of your role. The stuff in there should be self-explanatory or understandable with comparisons to existing roles; if it's not, then again, with all respect you probably shouldn't be creating a role right now.</p> <p>There is a wiki article on adding new containers here; this may be of some use.</p> <p>Don't forget the header in both these files:</p> <pre><code>#########################################################################\n# Title:            Community: my-cool-role                             #\n# Author(s):        some-guy, salty                                     #\n# URL:              https://github.com/saltyorg/Community               #\n# --                                                                    #\n#########################################################################\n#                   GNU General Public License v3.0                     #\n#########################################################################\n---\n</code></pre> <p>Be sure you edit this to reflect your role, name, and such depending on what's there in your prototype</p> <p><pre><code>community.yml\n</code></pre> This file drives the ansible install system by providing the valid tags that you can use with:</p> <pre><code>sb install cm-TAG\n</code></pre> <p>Again, it's a simple file, and it should be quite apparent what needs to be added for a new role.</p>","title":"Creating a role:"},{"location":"community/basics/#other-files-you-may-need-to-edit","text":"<pre><code>defaults\n\u2514\u2500\u2500 settings.yml.default\n</code></pre> <p>This file provides the prototype settings file; if your role requires some new settings, add them to this file.  When the community repo is updated, your new settings will be added to the user's current settings file and they will be prompted to review it. </p> <pre><code>templates\n\u2514\u2500\u2500 my-cool-role.j2\n</code></pre> <p>Perhaps you need to create a config file, or a service file, or the like.  Create templates for them here and fill them in at install time.  THere are lots of examples in the existing roles.</p>","title":"Other files you may need to edit:"},{"location":"community/basics/#testing","text":"<p>Warning</p> <p>BE SURE TO TEST YOUR ROLE.</p>  <p>You want to make sure that your role works, so be sure you run it several times. Run it on fresh installs, reinstalls, enlist someone else to run it for you. The point of doing this is to add something to community for others to use; if you don't verify that it works, why are you doing it?</p>","title":"Testing:"},{"location":"community/basics/#creating-the-pull-request","text":"<p>Now it's complete, and tested, and you want it to be added to community for other users to enjoy.</p> <p>First, commit your changes to your fork.</p>  <p>Warning</p> <p>BE SURE YOU DO NOT COMMIT FILES CONTAINING SECRETS LIKE API KEYS OR TOKENS.</p>  <p>This will involve adding the files you changed or added and doing a git commit and git push.</p> <p>This is standard git stuff, and again, with all respect, if you don't know these git basics you probably shouldn't be creating a role right now.</p> <p>Back at github.com, create a pull request against the \"master\" branch of the community repo.</p> <p>You do this by switching to your feature branch in your repo and clicking \"Pull request\" at the top where it says something like: \"This branch is 2 commits ahead of Community:master.\"</p> <p>This is a request for the Saltbox team to \"pull\" your changes into their repo.</p> <p>If there are special instructions or details that your role needs, add them to the pull request comments. If needed, create a doc page [which will be its own pull request] for the role.</p>  <p>Warning</p> <p>BE SURE YOU DO NOT COMMIT FILES CONTAINING SECRETS LIKE API KEYS OR TOKENS.</p>  <p>Your pull request will be reviewed eventually, and may generate comments or change requests.</p> <p>You can address those change requests by making further commits to your feature branch; they will automatically be added to this pull request.</p> <p>Eventually, if deemed a good or just reasonable fit, your pull request will be accepted and it will appear in the source community repo.</p>","title":"Creating the Pull Request:"},{"location":"community/settings/","text":"<p>The configuration file for Saltbox Community settings is called settings.yml and is located at <code>/opt/community/settings.yml</code></p> <p>settings.yml</p> <pre><code>---\nalternatrrx:  # (1)\n  roles:\n    - 1080webdl\n    - 1080remux\nbazarrx:  # (2)\n  roles:\n    - 1080webdl\n    - 1080remux\ndelugevpn:  # (3)\n  vpn_endpoint: netherlands.ovpn\n  vpn_pass: your_vpn_password\n  vpn_prov: pia\n  vpn_user: your_vpn_username\n  vpn_client: wireguard # 'wireguard' or 'openvpn'\ndelugex:  # (4)\n  roles:\n    - 1080webdl\n    - 1080remux\ngoplaxt:  # (5)\n  trakt_id: ~\n  trakt_secret: ~\nhandbrake:  # (6)\n  handbrake_pass: saltbox # must be less than eight characters\nmoviematch:  # (7)\n  libraries: Movies\n  plex_url: http://plex:32400\nombix:  # (8)\n  roles:\n    - 4k\noverseerrx: # (9)\n  roles:\n    - \"\"\nqbittorrentx:  # (10)\n  roles:\n    - 1080webdl\n    - 1080remux\nreadarrx:  # (11)\n  roles:\n    - ebooks\n    - audiobooks\nrequestrrx:  # (12)\n  roles:\n    - 1080\n    - 4k\nrfloodx:  # (13)\n  roles:\n    - 1080webdl\n    - 1080remux\ntautullix:  # (14)\n  tautulli: plex\n  tautulli2: plex2\ntransmissionx:  # (15)\n  roles:\n    - 1080webdl\n    - 1080remux\n</code></pre> <ol> <li> <p>AlternatrrX role, provide a list of \"X's\"     For each listed item an Alternatrr instance will be created and the item set to the subdomain.</p> </li> <li> <p>BazarrX role, provide a list of \"X's\"    For each listed item a Bazarr instance will be created and the item set to the subdomain.</p> </li> <li> <p>DelugeVPN settings block, replace the examples given with your own information.</p> </li> <li> <p>DelugeX role, provide a list of \"X's\"    For each listed item a Deluge instance will be created and the item set to the subdomain.</p> </li> <li> <p>Goplaxt    Trakt App ID and Secret</p> </li> <li> <p>Handbrake</p> </li> <li> <p>Moviematch</p> </li> <li> <p>Ombix role, provide a list of \"X's\"    For each listed item an Ombi instance will be created and the item set to the subdomain.</p> </li> <li> <p>OverseerrX role, provide a list of \"X's\"     For each listed item an Overseerr instance will be created and the item set to the subdomain.</p> </li> <li> <p>QbittorrentX role, provide a list of \"X's\"     For each listed item a QBitorrent instance will be created and the item set to the subdomain.</p> </li> <li> <p>ReadarrX role, provide a list of \"X's\"     For each listed item a Readarr instance will be created and the item set to the subdomain.</p> </li> <li> <p>RequestrrX role, provide a list of \"X's\"     For each listed item a Requestrr instance will be created and the item set to the subdomain.</p> </li> <li> <p>RfloodX role, provide a list of \"X's\"     For each listed item an RFlood instance will be created and the item set to the subdomain.</p> </li> <li> <p>TautulliX role, provide a list of \"X's\"     For each listed item a Tautulli instance will be created and the item set to the subdomain.</p> </li> <li> <p>TransmissionX role, provide a list of \"X's\"     For each listed item a Transmission instance will be created and the item set to the subdomain.</p> </li> </ol>","title":"The Settings File"},{"location":"community/apps/arrx/","text":"","title":"arrX"},{"location":"community/apps/arrx/#create-multiple-container-instances","text":"<p>Read through this entire page, even if you are only installing one of the apps.</p> <p>NOTE: This functionality is being moved to a more generalized and customizable multiple instances system.  As roles are transitioned, they will be removed from the table below.  As of this writing, Radarr, Sonarr, and Lidarr have been transitioned.</p>","title":"Create multiple container instances"},{"location":"community/apps/arrx/#background","text":"<p>There are a number of roles in the saltbox community repo which can be used to create multiple instances of an application.  Some of these include:</p>    Role Description     bazarrx Subtitle downloading   delugex Torrent client   ombix Request management   overseerrx Request management   qbittorrentx Torrent client   readarrx Ebook management   requestrrx Discord request bot   rfloodx Torrent client   tautullix Plex stats, data, actions   transmissionx Torrent client    <p>They're all named somethingX because they allow creation of X number of something.</p> <p>They are all configured in the same way.</p> <p>In general terms, you'll enter the instances you want into the community <code>settings.yml</code>:</p> <pre><code>appnamex:\n  roles:\n    - \"\"\n    - bing\n    - bang\n    - boing\n</code></pre> <p>That will create:</p> <ul> <li>appname</li> <li>appnamebing</li> <li>appnamebang</li> <li>appnameboing</li> </ul> <p>as docker containers, subdomain, and data directories in <code>/opt</code>.</p> <p>For example, with this configuration:</p> <pre><code>bazarrx:\n  roles:\n    - \"\"\n    - bing\n    - bang\n    - boing\n</code></pre> <p>Running the saltbox community <code>sonarrx</code> tag would produce:</p>    entry Container Config dir Subdomain Note     \"\" bazarr <code>/opt/bazarr</code> bazarr.YOURDOMAIN.TLD Replaces the stock container   bing bazarrbing <code>/opt/bazarrbing</code> bazarrbing.YOURDOMAIN.TLD    bang bazarrbang <code>/opt/bazarrbang</code> bazarrbang.YOURDOMAIN.TLD    boing bazarrboing <code>/opt/bazarrboing</code> bazarrboing.YOURDOMAIN.TLD     <p>NOTE: the names have to be compliant with both domain names and docker names, so no funny business. Do not use anything but a-z and 0-9, no spaces, no commas, no colons, no dash, no exclamation marks, no nothing!</p> <p>The names, within the constraints above, are completely arbitrary.  There is nothing magic about the example configs [1080webdl, 1080remux] given below.  They represent some common use cases, but you can use whatever names you wish, as in the \"bing, bang, boing\" examples above.</p> <p>You will need to configure these new containers just as you did the stock containers.  One change; if applicable, be sure each one gets a unique download category, so that each instance imports only those downloads meant for it.</p> <p>Also, you probably want to put some thought into the directory and library structure you want to use.  See \"Customizing Plex Libraries\".</p>","title":"Background"},{"location":"community/apps/arrx/#overwriting-the-stock-container","text":"<p>The example above shows a <code>\"\"</code> config entry.  For those apps which are also found in the stock saltbox install, this will overwrite the existing container.  Then, when you rerun the saltbox tag, this container will get overwritten by the stock one again.  You probably don't want that.</p> <p>For one thing, these \"arrX\" roles may be based on different images than the stock images.</p> <p>You probably want to overwrite your existing role with this one; that will ensure that all your instances of Bazarr are based on the same image and get updated in the same way.  It's up to you, though, how you want to manage them.</p>","title":"Overwriting the stock container"},{"location":"community/apps/arrx/#if-you-want-to-use-this-to-overwrite-your-existing-bazarretc-container","text":"<ol> <li>Include a <code>\"\"</code> entry in the config:    <pre><code> bazarrx:\n   roles:\n     - \"\"\n     - bing\n     - bang\n     - boing\n</code></pre></li> <li>Run the role as described below.    <code>bash   sb install cm-bazarrx</code></li> <li>Add the stock tag to the <code>[skip]</code> section in <code>\"/srv/git/saltbox/ansible.cfg\"</code>:    <pre><code>[tags]\nskip = bazarr,whatever,whatever\n</code></pre></li> </ol> <p>That will ensure that the stock <code>bazarr</code> tag doesn't overwrite the container you are creating here.</p> <p>When you want to update Bazarr, you'll run the Saltbox Community <code>bazarrx</code> tag instead.</p> <p>The same thing holds for every <code>arrX</code> variant discussed here.</p>","title":"If you want to use this to overwrite your existing Bazarr/etc container:"},{"location":"community/apps/arrx/#if-you-do-not-want-to-overwrite-your-existing-bazarretc-container","text":"<ol> <li>Make sure there IS NOT a <code>\"\"</code> entry in the config:    <pre><code>bazarrx:\n  roles:\n    - bing\n    - bang\n    - boing\n</code></pre></li> </ol> <p>That's all.  Your existing <code>bazarr</code> container will not be touched.</p> <p>Again, the same thing holds for every <code>arrX</code> variant discussed here.</p>","title":"If you DO NOT want to overwrite your existing Bazarr/etc container:"},{"location":"community/apps/arrx/#examples-multiple-bazarr-containers","text":"<ol> <li>Edit <code>settings.yml</code> and change the bazarrx roles to what you want:</li> </ol>  I want to add a BING [4K, kids, German, whatever] version and leave my existing container untouched.  <pre><code>bazarrx:\n  roles:\n    - BING\n</code></pre>   I want to add BING and BANG versions and leave my existing container untouched.  <pre><code>bazarrx:\n  roles:\n    - BING\n    - BANG\n</code></pre>   I want to replace my existing version and add BANG and BOING versions.  <pre><code>bazarrx:\n  roles:\n    - \"\"\n    - BANG\n    - BOING\n</code></pre>    **Refer to the notes above about overwriting the default container.**      <ol> <li>Run the bazarrx role as a normal saltbox community role.</li> </ol> <pre><code>sb install cm-bazarrx\n</code></pre> <p>Remember that all those names are arbitrary and purely cosmetic for your own use.  There is nothing that ties <code>readarr-romance.YOURDOMAIN.TLD</code> to romance literature aside from the configuration that you are going to give it.</p>","title":"Examples: multiple Bazarr containers"},{"location":"community/apps/bazarr/","text":"","title":"Bazarr"},{"location":"community/apps/bazarr/#what-is-it","text":"<p>Bazarr is a companion application to Sonarr and Radarr that manages and downloads subtitles based on your requirements.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"community/apps/bazarr/#1-installation","text":"<pre><code>sb install cm-bazarr\n</code></pre>","title":"1. Installation"},{"location":"community/apps/bazarr/#2-url","text":"<ul> <li>To access Bazarr, visit <code>https://bazarr._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"community/apps/bazarr/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"community/apps/bazarrx/","text":"","title":"BazarrX"},{"location":"community/apps/bazarrx/#what-is-it","text":"<p>bazarrX is an arrX role for bazarr.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"community/apps/bazarrx/#1-installation","text":"<pre><code>sb install cm-bazarrx\n</code></pre>","title":"1. Installation"},{"location":"community/apps/bazarrx/#2-url","text":"<ul> <li>To access bazarrX, visit <code>https://bazarrx._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"community/apps/bazarrx/#3-setup","text":"<ol> <li> <p>Read through the general arrX role instructions.</p> </li> <li> <p>Add your X instance names to the bazarrX section in community <code>settings.yml</code>: using a list format as below.</p> </li> </ol> <pre><code> bazarrx:\n   roles:\n     - 1080webdl\n     - 1080remux\n</code></pre> <ul> <li>For app specific instructions refer to the parent role,<ul> <li>bazarr</li> <li>and the upstream documentation   Documentation </li> </ul> </li> </ul>","title":"3. Setup"},{"location":"community/apps/deluge/","text":"","title":"Deluge"},{"location":"community/apps/deluge/#what-is-it","text":"<p>Deluge is a torrent client that can be used as an alternative to rutorrent.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"community/apps/deluge/#1-installation","text":"<pre><code>sb install cm-deluge\n</code></pre>","title":"1. Installation"},{"location":"community/apps/deluge/#2-url","text":"<ul> <li>To access Deluge, visit <code>https://deluge._yourdomain.com_</code></li> </ul>  <p>Info</p> <p>default login  <pre><code>    user: admin\npassword: deluge\n</code></pre></p>","title":"2. URL"},{"location":"community/apps/deluge/#3-setup","text":"<ul> <li> <p>Change login password.</p> </li> <li> <p>Click Preferences in the top bar and on the Downloads section enter the following paths: </p> <ul> <li>Download to:  <code>/mnt/unionfs/downloads/torrents/deluge/incoming</code></li> <li>Move completed to:  <code>/mnt/unionfs/downloads/torrents/deluge/completed</code></li> <li>Autoadd <code>.torrent files</code> from:  <code>/mnt/unionfs/downloads/torrents/deluge/watched</code></li> </ul> </li> <li> <p>Select Network section, uncheck <code>Use Random Ports</code> under Incoming Ports and set both input fields to <code>58112</code>.</p> </li> <li> <p>Click the <code>Plugins</code> section</p> <ul> <li>enable the <code>labels</code> plugin.</li> <li>enable and the <code>Extractor</code> plugin.    In order for Sonarr or Radarr to import media packaged within .rar files, they will have to be extracted.</li> <li>After clicking <code>\"Apply\"</code>, select the <code>Extractor</code>  plugin on the left.    Make sure the directory points to the <code>completed</code> folder within your Deluge data directory.   <code>/mnt/unionfs/downloads/torrents/deluge/completed</code>    Also, make sure that the Create torrent name sub-folder setting is checked.</li> </ul> </li> </ul>","title":"3. Setup"},{"location":"community/apps/deluge/#4-adding-to-sonarrradarr","text":"<p>To add Deluge as a download client in Sonarr/Radarr use the following settings. Both are able to remove completed torrents after they have finished seeding.</p> <p></p> <ul> <li> Documentation</li> </ul>","title":"4. Adding to Sonarr/Radarr"},{"location":"community/apps/delugex/","text":"","title":"DelugeX"},{"location":"community/apps/delugex/#what-is-it","text":"<p>DelugeX is an arrX role for Deluge.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"community/apps/delugex/#1-installation","text":"<pre><code>sb install cm-delugex\n</code></pre>","title":"1. Installation"},{"location":"community/apps/delugex/#2-url","text":"<ul> <li>To access DelugeX, visit <code>https://delugex._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"community/apps/delugex/#3-setup","text":"<ol> <li> <p>Read through the general arrX role instructions.</p> </li> <li> <p>Add your X instance names to the DelugeX section in community <code>settings.yml</code>: using a list format as below.</p> </li> </ol> <pre><code> delugex:\n   roles:\n     - 1080webdl\n     - 1080remux\n</code></pre> <ul> <li>For app specific instructions refer to the parent role,<ul> <li>deluge </li> <li>and the upstream documentation   Documentation </li> </ul> </li> </ul>","title":"3. Setup"},{"location":"community/apps/hetzner_nfs/","text":"","title":"Hetzner NFS VLAN"},{"location":"community/apps/hetzner_nfs/#what-is-it","text":"<p>Connect 2+ servers hosted on Hetzner using NFS and VLAN.</p> <p>Note 1: This comes with no support other than the instructions provided here.</p> <p>Note 2: This setup has been tested to work with standard Unionfs/Rclone VFS setup. Using either MergerFS or any non-standard setup will require you to tweak the appropriate mounts. You can look at the roles to see what changes need to be done.</p>","title":"What is it?"},{"location":"community/apps/hetzner_nfs/#1-installation","text":"<p>In this example, we'll set our Feederbox as the NFS server and our Mediabox as the NFS client - this is so that the feeder data can be available to the media server.</p> <p>There are 3 phases to the setup. They are broken down below.</p>","title":"1. Installation"},{"location":"community/apps/hetzner_nfs/#hetzner-robot","text":"<ol> <li> <p>Log into Hetzner Robot.</p> </li> <li> <p>Create a VLAN (vSwitch) and add servers to it. Note the VLAN ID.</p> </li> </ol> <p></p> <ol> <li> <p>Setup Firewall.</p> <ul> <li>Mediabox:</li> </ul> <p></p> <ul> <li>Feederbox:</li> </ul> <p></p> </li> </ol>","title":"Hetzner Robot"},{"location":"community/apps/hetzner_nfs/#nfs-server-feederbox","text":"<ol> <li> <p>Setup the Ansible role config.</p> </li> <li> <p>Add <code>vlan_id</code>.</p> </li> <li> <p><code>mount_client</code> setting is ignored for the NFS server (i.e. it will just use <code>2</code>).</p> <pre><code>nano /opt/community/hetzner_nfs.yml\n</code></pre> <pre><code>hetzner_nfs:\n  vlan_id: 4001\n  mount_client: 3\n</code></pre> </li> <li> <p>Run Ansible role to configure the NFS server.</p> <pre><code>sb install cm-hetzner_nfs_server\n</code></pre> </li> </ol>","title":"NFS Server (Feederbox)"},{"location":"community/apps/hetzner_nfs/#nfs-client-mediabox","text":"<ol> <li> <p>Setup the Ansible role config.</p> </li> <li> <p>Add <code>vlan_id</code>.</p> </li> <li> <p>Add <code>mount_client</code>.</p> <p>Note: <code>mount_client</code> will need to be either <code>3</code> or a number &gt; <code>250</code>.</p> <pre><code>nano /opt/community/hetzner_nfs.yml\n</code></pre> <pre><code>hetzner_nfs:\n  vlan_id: 4001\n  mount_client: 3\n</code></pre> </li> <li> <p>Run Ansible role to configure the NFS client.</p> <pre><code>sb install cm-hetzner_nfs_server\n</code></pre> </li> </ol>","title":"NFS Client (Mediabox)"},{"location":"community/apps/hetzner_nfs/#uninstall","text":"<p>Simply run the following commands on their respective servers:</p>","title":"Uninstall"},{"location":"community/apps/hetzner_nfs/#nfs-server-feederbox_1","text":"<pre><code>sb install cm-hetzner_nfs_server_uninstall\n</code></pre>","title":"NFS Server (Feederbox)"},{"location":"community/apps/hetzner_nfs/#nfs-client-mediabox_1","text":"<pre><code>sb install cm-hetzner_nfs_client_unmount\n</code></pre>","title":"NFS Client (Mediabox)"},{"location":"community/apps/qbittorrent/","text":"","title":"qBittorrent"},{"location":"community/apps/qbittorrent/#what-is-it","text":"<p>qBittorrent is a bittorrent client programmed in C++ / Qt that uses libtorrent (sometimes called libtorrent-rasterbar) by Arvid Norberg.</p> <p>It aims to be a good alternative to all other bittorrent clients out there. qBittorrent is fast, stable and provides unicode support as well as many features.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"community/apps/qbittorrent/#1-installation","text":"<pre><code>sb install cm-qbittorrent\n</code></pre>","title":"1. Installation"},{"location":"community/apps/qbittorrent/#2-url","text":"<ul> <li>To access qBittorrent, visit <code>https://qbittorrent._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"community/apps/qbittorrent/#3-setup","text":"<ul> <li> <p>Access qbittorrent at <code>https://qbittorrent._yourdomain.com_</code> <pre><code>  username: `admin`\n  password: `adminadmin`.\n</code></pre></p> </li> <li> <p>First go to <code>Options</code> -&gt; <code>Web UI</code> and set a new username and password.</p> <p></p> </li> <li> <p>Under <code>Options</code> -&gt; <code>Connection</code>, set the port to 56881.</p> <p></p> </li> <li> <p>Under <code>Options</code> -&gt; <code>Downloads</code>, set the following;</p> <ul> <li> <p>Save files to location: <code>/mnt/unionfs/downloads/torrents/qbittorrent/completed/</code></p> </li> <li> <p>Keep incomplete torrents in: <code>/mnt/unionfs/downloads/torrents/qbittorrent/incoming/</code></p> </li> <li> <p>Copy .torrent files to: <code>/mnt/unionfs/downloads/torrents/qbittorrent/torrents/</code></p> </li> <li> <p>Copy .torrent files for finished downloads to: <code>/mnt/unionfs/downloads/torrents/qbittorrent/torrents/</code></p> </li> <li> <p>Additionally you can set monitored folder to: <code>/mnt/unionfs/downloads/torrents/qbittorrent/watched/</code></p> </li> <li> <p>tick <code>Run external program on torrent completion</code> and paste this into the box: <code>/usr/bin/unrar x -r \"%F/.\" \"%F/\"</code></p> </li> </ul> <p></p> </li> </ul>  <p>Note</p> <p>if you're using private trackers be sure to go to <code>Options</code> -&gt; <code>BittTorrent</code> and uncheck everything in Privacy section.</p>  <ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"community/apps/qbittorrentx/","text":"","title":"qBittorrentX"},{"location":"community/apps/qbittorrentx/#what-is-it","text":"<p>qBittorrentX is an arrX role for qBittorrent.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"community/apps/qbittorrentx/#1-installation","text":"<pre><code>sb install cm-qBittorrentX\n</code></pre>","title":"1. Installation"},{"location":"community/apps/qbittorrentx/#2-url","text":"<ul> <li>To access qBittorrentX, visit <code>https://qbittorrentX._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"community/apps/qbittorrentx/#3-setup","text":"<ol> <li> <p>Read through the general arrX role instructions.</p> </li> <li> <p>Add your X instance names to the qBittorrentX section in community <code>settings.yml</code>: using a list format as below.</p> </li> </ol> <pre><code> qbittorrentx:\n   roles:\n     - longtermseed\n     - educational\n</code></pre> <ul> <li>For app specific instructions refer to the parent role,<ul> <li>qBittorrent</li> <li>and the upstream documentation   Documentation </li> </ul> </li> </ul>","title":"3. Setup"},{"location":"community/apps/radarrx/","text":"<p>Replaced by multiple instance support</p>","title":"RadarrX"},{"location":"community/apps/readarr/","text":"","title":"Readarr"},{"location":"community/apps/readarr/#what-is-it","text":"<p>Readarr is an ebook and audiobook collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new books from your favourite authors and will grab, sort and rename them.</p> <p>Note that only one type of a given book is supported.  If you want both an audiobook and ebook of a given book you will need multiple instances.</p>  <p>Note</p> <p>Readarr is currently in beta testing and is generally still in a work in progress. Features may be broken, incomplete, or cause spontaneous combustion.</p>     Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"community/apps/readarr/#1-installation","text":"<pre><code>sb install cm-readarr\n</code></pre>","title":"1. Installation"},{"location":"community/apps/readarr/#2-url","text":"<ul> <li>To access Readarr, visit <code>https://readarr._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"community/apps/readarr/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"community/apps/readarrx/","text":"","title":"ReadarrX"},{"location":"community/apps/readarrx/#what-is-it","text":"<p>ReadarrX is an arrX role for Readarr.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"community/apps/readarrx/#1-installation","text":"<pre><code>sb install cm-readarrx\n</code></pre>","title":"1. Installation"},{"location":"community/apps/readarrx/#2-url","text":"<ul> <li>To access ReadarrX, visit <code>https://readarrx._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"community/apps/readarrx/#3-setup","text":"<ol> <li> <p>Read through the general arrX role instructions.</p> </li> <li> <p>Add your X instance names to the ReadarrX section in community <code>settings.yml</code>: using a list format as below.</p> <pre><code>    readarrx:\n      roles:\n        - ebooks\n        - audiobooks\n</code></pre> </li> <li> <p>Run the Saltbox installer to generate your X instances of readarr.</p> <pre><code>    sb install cm-readarrx\n</code></pre> </li> <li> <p>For app specific instructions refer to the parent role,</p> <ul> <li>Readarr</li> <li>and the Readarr upstream documentation   Documentation </li> </ul> </li> </ol>","title":"3. Setup"},{"location":"community/apps/sonarrx/","text":"<p>Replaced by multiple instance support</p>","title":"SonarrX"},{"location":"community/apps/tautullix/","text":"","title":"TautulliX"},{"location":"community/apps/tautullix/#what-is-it","text":"<p>TautulliX is an arrX role for Tautulli.</p> <p>Tautulli is a 3rd party application that you can run alongside your Plex Media Server to monitor activity and track various statistics. Most importantly, these statistics include what has been watched, who watched it, when and where they watched it, and how it was watched. The only thing missing is \"why they watched it\", but who am I to question your 42 plays of Frozen. All statistics are presented in a nice and clean interface with many tables and graphs, which makes it easy to brag about your server to everyone else.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"community/apps/tautullix/#1-installation","text":"<pre><code>sb install cm-tautullix\n</code></pre>","title":"1. Installation"},{"location":"community/apps/tautullix/#2-url","text":"<ul> <li>To access TautulliX, visit <code>https://tautulliX._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"community/apps/tautullix/#3-setup","text":"<ol> <li> <p>Read through the general arrX role instructions.</p> </li> <li> <p>Add your X instance names to the TautulliX section in community <code>settings.yml</code>: using a list format as below.</p> <pre><code>    tautullix:\n      roles:\n        tautulli: plex\n        tautulli2: plex2\n</code></pre> </li> <li> <p>Run the Saltbox installer to generate your X instances of tautulli.</p> <pre><code>    sb install cm-tautullix\n</code></pre> </li> <li> <p>For app specific instructions refer to the parent role,</p> <ul> <li>tautulli</li> <li>and the tautulli upstream documentation   Documentation </li> </ul> </li> </ol>","title":"3. Setup"},{"location":"community/guides/aliases/","text":"<p>Handy guide to Saltbox Command line aliases.</p>","title":"Saltbox Aliases"},{"location":"community/guides/aliases/#sb-update","text":"<ul> <li> <p>Update Saltbox</p> </li> <li> <p>Usage:</p> <pre><code>    sb update\n</code></pre> </li> </ul>","title":"sb update"},{"location":"community/guides/aliases/#sb-list","text":"<ul> <li> <p>List Saltbox packages</p> </li> <li> <p>Usage:</p> <pre><code>    sb list\n</code></pre> </li> </ul>","title":"sb list"},{"location":"community/guides/aliases/#sb-install-package","text":"<ul> <li> <p>Install <code>&lt;package&gt;</code></p> </li> <li> <p>Usage:</p> <pre><code>    sb install plex\n</code></pre> </li> </ul>","title":"sb install <code>&lt;package&gt;</code>"},{"location":"community/guides/aliases/#sb-install-cm-package","text":"<ul> <li> <p>Install community <code>&lt;package&gt;</code></p> </li> <li> <p>Usage:</p> <pre><code>    sb install cm-jellyfin\n</code></pre> </li> </ul>","title":"sb install cm-<code>&lt;package&gt;</code>"},{"location":"community/guides/cloudbox/","text":"<p>Saltbox is a continuation of the Cloudbox project and is mostly compatible out of the box. Very little has to be done to bring your old Cloudbox data into Saltbox. Any customisations you have made or special roles are going to require extra work as Saltbox uses Traefik instead of nginx.</p>","title":"Migrating from Cloudbox to Saltbox"},{"location":"community/guides/cloudbox/#before-migration","text":"<p>Backup from Cloudbox as you normally would. You will need to make the backup drive available to your new saltbox install via rclone just as you would with a Cloudbox restore. We are really only interested in keeping the data stored in <code>/opt</code> and not the Cloudbox configuration files. We will be using the data from the configuration files so you may find it handy to download those locally to use as a reference. If you have community containers set up you should make a copy of those files as well. We are more interested in the data stored in these files so it is perfectly fine to just copy and paste the information into a text file for your reference as part of the installation process.</p> <ul> <li> <p>Cloudbox files to keep handy:  These files should be found in <code>~/cloudbox/</code></p> <pre><code>  accounts.yml\n</code></pre> <p>You may need to decrypt your <code>accounts.yml</code> file if you used the encryption option. Do this before you shut down or wipe your old server.</p> <pre><code>  adv_settings.yml\n  ansible.cfg\n  backup_config.yml\n</code></pre> <p>If you are using a service account to authenticate your rclone remote[s], you will need to put those files in place on the saltbox server before you run the restore.</p> </li> <li> <p>Community files to keep handy:  These files should be found in <code>/opt/community/</code></p> <pre><code>  ansible.cfg\n  hetzner_nfs.yml\n  settings.yml\n  telly.yml\n</code></pre> </li> <li> <p>Rclone configuration file     The rclone.conf file located in <code>~/.config/rclone/rclone.conf</code> if your configuration uses service accounts to authenticate the remotes you will need make sure the service accounts are accessible. </p> <pre><code>  rclone.conf\n</code></pre> </li> </ul>","title":"Before Migration"},{"location":"community/guides/cloudbox/#migration","text":"<ul> <li> <p>Install the saltbox dependencies </p> <pre><code>curl -sL https://install.saltbox.dev | sudo -H bash; cd /srv/git/saltbox\n</code></pre> </li> <li> <p>Copy <code>rclone.conf</code> to <code>/srv/git/saltbox</code>  and edit the configuration files as needed. You can follow the saltbox install instructions for saltbox for this</p> </li> </ul> <p>You can refer to your Cloudbox configuration files and copy relevant settings over from them, but do not just copy your existing cloudbox config files into place.  Direct compatibility with cloudbox config files is not guaranteed and will not be maintained going forward.</p> <ul> <li>Run the preinstall command.</li> </ul> <p>This step will create the specified user account, add it to sudoers, update the kernel, edit GRUB configuration, install Rclone, and reboot the server if needed. </p> <pre><code>``` { .shell }\n\n  sb install preinstall\n\n```\n</code></pre> <ul> <li> <p>switch to the newly created user specified in your configuration. </p> </li> <li> <p>run the restore command. </p> <pre><code>  sb install restore\n</code></pre> <p>Remember that if you use a service account file to authenticate an rclone remote, you need to manually put that file into place before running the restore.</p> <p>Then you should be able to install tags as you want.</p> </li> </ul>","title":"Migration"},{"location":"community/guides/hardlinking/","text":"<p>Hardlinking should more or less be in place if you have followed the saltbox setup guide.</p> <p>In short, if your container path mappings match your system mappings match your other container mappings then hardlinking should work fine within your arrs as long as your downloads path is on the same disk as your local media path.</p> <p>A more comprehensive guide will be added soon.</p>","title":"Hardlinking Guide"},{"location":"community/guides/links/","text":"","title":"Links"},{"location":"community/guides/links/#trakt-lists","text":"","title":"Trakt Lists"},{"location":"community/guides/links/#tv","text":"<ul> <li>TV Shows By Network</li> <li>More TV Shows By Network</li> <li>Animated/Anime Shows By Release Year</li> <li>4K TV Series (By a925sw)</li> </ul>","title":"TV"},{"location":"community/guides/links/#movies","text":"<ul> <li>4K Movies</li> <li>4k Movies (By Brian)</li> <li>Huge Movie Lists by year + Documentaries</li> <li>Rotten Tomatoes Best of 2018 - User also has Best of 2014/2015/2016/2017</li> <li>Latest Releases</li> <li>Lists by decades (By opposite_lock)</li> </ul>","title":"Movies"},{"location":"community/guides/links/#themed-lists","text":"<ul> <li>50 Best Christmas Movies</li> <li>50 Best Christmas Movies - Rotten Tomatoes</li> <li>Many Christmas Movies</li> <li>Halloween Movies</li> </ul>","title":"Themed Lists"},{"location":"community/guides/links/#miscusers-with-many-different-lists","text":"<ul> <li>Movies/TV By Genre</li> </ul>","title":"Misc/Users with many different lists"},{"location":"community/guides/plexguide/","text":"<p>These are some rough notes on migrating from PlexGuide to Saltbox</p> <p>PG rclone.conf Location: <code>/opt/appdata/plexguide/rclone.conf</code></p> <p>PG Service accounts Location: <code>/opt/appdata/plexguide/.blitzkeys</code></p> <p>if you are restoring the arrs from pg to saltbox you will need to make the below changes in SB</p> <pre><code>sudo mkdir /mnt/gdrive\n</code></pre> <pre><code>sudo chown $USER:$USER /mnt/gdrive\nchmod 775 /mnt/gdrive\n</code></pre> <p><pre><code>sudo cp \"/etc/systemd/system/rclone_vfs.service\" \"/etc/systemd/system/gdrive.service\"\nsudo nano \"/etc/systemd/system/gdrive.service\"\n</code></pre> Changes: <pre><code>  google: /mnt/remote\nbecomes\n  google: /mnt/gdrive\n</code></pre> AND</p> <pre><code>ExecStop=/bin/fusermount -uz /mnt/remote\nbecomes\nExecStop=/bin/fusermount -uz /mnt/gdrive\n</code></pre> <pre><code>sudo systemctl enable gdrive.service\nsudo systemctl start gdrive.service\n</code></pre>","title":"Migrating from PlexGuide to Saltbox"},{"location":"community/guides/suggested_reading/","text":"","title":"Suggested Reading"},{"location":"community/guides/suggested_reading/#trash-guides","text":"<ul> <li> <p> TRaSH Guides </p> </li> <li> <p> Discord</p> </li> </ul>","title":"TRaSH Guides"},{"location":"community/guides/suggested_reading/#servarr","text":"<p>The servarr wiki is home to information on Lidarr, Prowlarr, Radarr, Readarr, and Sonarr.</p> <ul> <li> Servarr </li> </ul> <p>Servarr Discussion</p> <ul> <li>Lidarr</li> <li> Official Lidarr Discord</li> <li> <p> Official Lidarr Reddit</p> </li> <li> <p>Prowlarr</p> </li> <li> Official Prowlarr Discord</li> <li> <p> Official Prowlarr Reddit</p> </li> <li> <p>Radarr</p> </li> <li> Official Radarr Discord</li> <li> <p> Official Radarr Reddit</p> </li> <li> <p>Readarr</p> </li> <li> Official Readarr Discord</li> <li> <p> Official Readarr Reddit</p> </li> <li> <p>Sonarr</p> </li> <li> Official Sonarr Discord</li> <li> Official Sonarr Reddit</li> </ul>","title":"Servarr"},{"location":"community/guides/suggested_reading/#kasper56s-plex-client-end-user-setup-wiki","text":"<ul> <li> Media Clients Wiki </li> </ul>","title":"Kasper56's Plex Client End User setup Wiki"},{"location":"community/guides/tautuliscripts/","text":"<p>This is a quick guide to installing and configuring a Tautulli custom script. It will teach you how to download and configure a Tautulli (plexpy) custom script that drops Plex video streams transcoding from a 4K source.</p>","title":"Introduction"},{"location":"community/guides/tautuliscripts/#install-the-script","text":"<p>Access your Saltbox server as your normal non-root user.</p> <p>We'll be installing the Killstream.py script from the JBOPS script collection.</p>","title":"Install the script"},{"location":"community/guides/tautuliscripts/#download-the-script-using-curl","text":"<pre><code>cd /opt/scripts/plexpy/\ncurl -O https://raw.githubusercontent.com/blacktwin/JBOPS/master/killstream/kill_stream.py\nsudo chown seed:seed kill_stream.py\nchmod a+x kill_stream.py\n</code></pre>","title":"Download the script using curl:"},{"location":"community/guides/tautuliscripts/#verify-that-the-script-was-downloaded-successfully-with","text":"<pre><code>ls -la kill_stream.py\n</code></pre> <p>The file should be around 9700 bytes in size.</p>","title":"Verify that the script was downloaded successfully with:"},{"location":"community/guides/tautuliscripts/#configure-tautulli-notification-agent","text":"<p>Enter Tautulli settings and find the Notification Agents link on the left side menu.\\ Click Add a new notification agent and scroll down to Script in the selection dialog.</p>","title":"Configure Tautulli Notification Agent"},{"location":"community/guides/tautuliscripts/#configuration-panel","text":"<p>Enter <code>/scripts/tautulli/</code> in the script folder and exit the text input field.</p> <p>Select the script named <code>./kill_stream.py</code> in the Script File drop-down.\\ Check your previous steps or bug someone on discord if the script is not listed.</p> <p>Enter <code>Terminate 4K transcodes</code> or something of your own choice in the description field.</p>","title":"Configuration panel"},{"location":"community/guides/tautuliscripts/#triggers-panel","text":"<p>Put a checkmark in <code>Playback Start</code> and <code>Transcode Decision Change</code></p>","title":"Triggers panel"},{"location":"community/guides/tautuliscripts/#notifications-conditions-panel","text":"<p>Condition {1}: <code>Video Decision</code> - <code>is</code> - <code>transcode</code></p> <p>Condition {2}: <code>Library Name</code> - <code>contains</code> - <code>4K</code></p> <p>Note: adjust the library name if your 4K libraries does not contain the name 4K.</p>","title":"Notifications Conditions panel"},{"location":"community/guides/tautuliscripts/#arguments-panel","text":"<p>Under Playback Start enter the following: <pre><code>--jbop stream --username {username} --sessionId {session_id} --killMessage 'Transcoding is not allowed from the 4K libraries.'\n</code></pre> Under Transcode Decision Change enter the following: <pre><code>--jbop stream --username {username} --sessionId {session_id} --killMessage 'Transcoding is not allowed from the 4K libraries.'\n</code></pre></p>","title":"Arguments panel"},{"location":"community/guides/tautuliscripts/#finishing-up","text":"<p>Click the Save button to save the new notification agent.</p> <p>You can test the agent by attempting to play a 4K movie through the Plex web app and downgrade the quality to 2Mbit. It will be transcoding for about 5-10 seconds, after which you should get the stream kill message.</p> <p>There is a list of when a notification agent is triggered in the Notification logs section of Tautulli logs.</p>","title":"Finishing up"},{"location":"community/guides/tautuliscripts/#credits-to-blacktwin","text":"<ul> <li>https://github.com/blacktwin/JBOPS</li> </ul>","title":"Credits to @blacktwin"},{"location":"community/guides/chazguides/base-domain/","text":"<p>This is a Cloudbox article that has not yet been updated for saltbox.  The information therein may not apply to Saltbox.</p> <p>I want some app to load at my base domain.</p>","title":"I want some app to load at my base domain"},{"location":"community/guides/chazguides/disk-full/","text":"<p>First, a quick refresher on how the system works:</p> <p>Your downloader puts files in <code>/mnt/local/downloads</code>. Sonarr/Radarr move [usenet] or copy [default torrent] these files to <code>/mnt/local/Media</code>. [They\u2019re actually moving files to <code>/mnt/unionfs/Media</code>, but the mergerfs config routes them in <code>/mnt/local/Media</code>] Once <code>/mnt/local/Media</code> hits 200GB, cloudplow uploads the contents to your cloud drive. Once that\u2019s complete they will show up in <code>/mnt/remote/Media</code> as well as <code>/mnt/unionfs/Media</code>. Chances are, if your disk is full, the cause is one of two things:</p> <ol> <li>Sonarr/Radarr are not importing downloaded media</li> <li>Cloudplow isn't uploading things to the cloud.</li> </ol> <p>If you are using rclone\u2019s --vfs-cache=full, then there\u2019s a third likely cause:</p> <ol> <li>Your rclone vfs cache is filling your disk</li> </ol> <p>This is written assuming Usenet downloads, so filling your disks with seeding torrents isn't covered.  You can use these tools to find out if that's the issue, though.</p>","title":"Why is my disk full?"},{"location":"community/guides/chazguides/disk-full/#where-is-the-space-going","text":"<p>The first step is to find out where the space is going on your disk; which directories contain all the files.</p> <p>At a command prompt, type:</p> <pre><code>sudo ncdu -x --exclude /opt/plex /\n</code></pre> <p>What\u2019s that command?</p> <pre><code>sudo    run with root privileges\nncdu    show graphic display of disk usage\n-x  don\u2019t cross filesystem boundaries [this will show only local space used and won't cross over to remote file systems like your google drive]\n--exclude /opt/plex ignore this directory; it\u2019s full of thousands of tiny files that take forever to scan and MOST LIKELY you\u2019re not going to want to delete anything from here. \n/   starting point of scan\n</code></pre> <p>You'll probably see something like this:</p> <pre><code>ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help\n--- / ------------------------------------------------------\n  558.0 GiB [##########] /mnt\n   20.9 GiB [          ] /var\n    3.5 GiB [          ] /usr\n</code></pre> <p>Drill into /mnt/local:</p> <pre><code>ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help\n--- /mnt/local ---------------------------------------------\n                         /..\n  472.9 GiB [##########] /downloads\n   43.9 GiB [          ] /Media\n   37.5 GiB [          ] /Backups\n    3.7 GiB [          ] /transcodes\n</code></pre> <p>Here, I have 473 GB of unimported downloads and 44 GB waiting to be uploaded by Cloudplow.</p> <p>Rclone vfs cache is more install-dependent.  I\u2019m going to assume that if you\u2019re reading this you didn\u2019t change things from the defaults, and chances are you\u2019ll see something like this:</p> <pre><code>ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help ------------------------------------------------------------\n  252.3 GiB [##########] /home\n  119.6 GiB [####      ] /mnt\n   29.5 GiB [#         ] /var\n    3.4 GiB [          ] /usr\n</code></pre> <p>Drill into /home/YOUR_USERNAME/:</p> <pre><code>ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help\n--- /home/seed ---------------------------------------------\n                         /..\n  203.0 GiB [##########] /.cache\n   37.9 MiB [          ] /.pkg-cache\n   34.5 MiB [          ] /.npm\n</code></pre> <p>And further into .cache/rclone:</p> <pre><code>ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help\n--- /home/seed/.cache/rclone -------------------------------\n                         /..\n  202.9 GiB [##########] /vfs\n    4.8 MiB [          ] /vfsMeta\n   16.0 KiB [          ] /webgui\n</code></pre> <p>That\u2019s your VFS cache.</p>","title":"Where is the space going?"},{"location":"community/guides/chazguides/disk-full/#radarrsonarr-didnt-import-stuff","text":"<p>Drill into downloads to examine what's there in more detail.  Chances are you\u2019ll find /mnt/local/nzbs/nzbget/downloads/completed is where all the files are.  Those are downloads that Radarr/Sonarr didn\u2019t import.</p> <p>Use Wanted -&gt; Manual Import to find out why particular things weren't imported.</p> <p></p> <p>Perhaps Radarr couldn\u2019t work out what movie a thing was:</p> <p></p> <p>Maybe it doesn\u2019t look like an upgrade for one reason or another:</p> <p></p> <p></p> <p>That same information is also available in the logs.</p> <p>You can import things from here after telling Radarr what movie it is or the like, or you can delete them from within ncdu or via whatever other means.</p>","title":"Radarr/Sonarr didn\u2019t import stuff!"},{"location":"community/guides/chazguides/disk-full/#cloudplow-isnt-uploading-stuff","text":"<p>If the bulk of the space is in staged-for-upload files sitting in <code>/mnt/local/Media</code>, then cloudplow hasn\u2019t uploaded those files yet.</p> <p>This is typically due to one of the following:</p> <ul> <li>Upload threshold hasn\u2019t been reached.</li> <li>You\u2019ve reached the Google Drive upload cap of 750GB/day</li> </ul> <p>The default threshold to start a Google upload is 200GB, so in my case above cloudplow wouldn\u2019t do anything until 150GB more gets put into <code>/mnt/local/Media</code>.</p> <p>At a command prompt, type: <pre><code>tail /opt/cloudplow/cloudplow.log\n</code></pre></p> <p>You should see something like: <pre><code>Uploader: google. Local folder size is currently 44 GB. Still have 156 GB remaining before its eligible to begin uploading...\n</code></pre></p> <p>If you do, cloudplow is working as expected.  If you want cloudplow to start uploading stuff sooner, you can adjust those thresholds in your cloudplow config file.  At the bottom of <code>/opt/cloudplow/config.json</code>, you\u2019ll find something like this:</p> <pre><code>\"google\": {\n    \"check_interval\": 30,\n    \"exclude_open_files\": true,\n    \"max_size_gb\": 200,\n    \"opened_excludes\": [\n        \"/downloads/\"\n    ],\n    \"service_account_path\": \"\",\n    \"size_excludes\": [\n        \"downloads/*\"\n    ]\n}\n</code></pre> <p>That\u2019s going to check every 30 minutes, and start uploading when the folder reaches 200GB.  Adjust those values to suit your use case. Restart the cloudplow service if you make changes here.</p> <p>In the default setup, you can upload 750GB per day.</p> <p>To see if you\u2019ve hit that quota, run a cloudplow upload manually.  At a command prompt, type:</p> <pre><code>cloudplow upload \n</code></pre> <p>This will kick off an upload without regard for the threshold.  You can run this anytime you want to upload whatever\u2019s pending right this very minute.</p> <p>PAY ATTENTION TO WHAT THE LOG SAYS.  The errors should let you know what\u2019s going on.</p> <p>If you want more detail:</p> <pre><code>cloudplow upload --loglevel=DEBUG\n</code></pre> <p>You'll get a great deal of information about what cloudplow is doing and why.</p> <p>If you find yourself hitting that 750GB cap regularly, you may want to set up service-account uploading.</p>","title":"Cloudplow isn\u2019t uploading stuff!"},{"location":"community/guides/chazguides/disk-full/#rclone-cache-is-out-of-control","text":"<p>If the bulk of the space is in your rclone VFS cache, you\u2019ll want to check the vfs_cache configuration for all your mounts to control this.  </p> <p>Perhaps you used a copy-pasted config that is setting the max cache to 200G or so, and applied that to four mounts.  That means your rclone cache might grow to 800GB, so adjust the configs on the mounts you're caching.</p> <p>Don\u2019t just delete the existing cached files.  You\u2019ll need to stop the mounts first before you adjust the cache sizes.</p>","title":"Rclone cache is out of control!"},{"location":"community/guides/chazguides/home-server/","text":"","title":"Installing Saltbox on a home server"},{"location":"community/guides/chazguides/home-server/#installing-saltbox-on-a-home-server","text":"<p>Prerequisites:  - Domain  - Static IP OR Dynamic DNS configured  - Router supports port forwarding  - ISP supports you running servers on ports 80 and 443.  Some ISPs don\u2019t allow or actively block this.  - Router supports hairpin NAT [or NAT loopback]    Saltbox assumes that you are accessing apps via subdomains like \u201cradarr.mydomain.com\u201d rather than ip and port like 192.168.1.25:7878.     Without \u201chairpin NAT\u201d, a request to \u201cradarr.mydomain.com\u201d from inside the network will not find its way to the proxy which does that routing.</p> <p>NOTE: None of this initial setup is Saltbox-specific. If you want to run a server on a machine behind your router and connect to it using a domain name, whether Saltbox sets it up or something else, you\u2019ll need to do these very same things.</p>","title":"Installing Saltbox on a home server"},{"location":"community/guides/chazguides/home-server/#domain","text":"<p>You need a domain.  They\u2019re cheap or even free.</p> <p>You can find cheap ones here:  https://tld-list.com/ There are a variety of places that provide free domains.  Here\u2019s one offered with no endorsement [It was the first google result for \u201cfree domain\u201d]: https://www.freenom.com/en/freeandpaiddomains.html</p> <p>Configure the DNS at your registrar to point your domain at your home external IP address.</p> <p>You can find that using something like: https://whatismyipaddress.com/</p> <p>You will need to configure \u201cdynamic DNS\u201d to make sure that domain keeps pointing to your home IP, which is subject to change, most likely.</p> <p>Probably your router has this available.  If not, there\u2019s a Dynamic DNS Client role available in saltbox you can install.  If you use Cloudflare for DNS, the ddns client configuration will be automatically done when you run the role.</p> <p>The saltbox role is ddclient, and you run it like any other saltbox role:</p> <pre><code>sb install ddclient\n</code></pre> <p>You\u2019ll do this AFTER you\u2019ve installed saltbox.</p>","title":"Domain:"},{"location":"community/guides/chazguides/home-server/#machine","text":"<p>I installed Ubuntu server 20.04 on the machine, accepting all defaults except: I enabled OpenSSH and imported my SSH keys from github That\u2019s all.</p> <p>Since I installed Ubuntu on my own hardware, the first user I created is a member of the sudoers group.  I\u2019ll be running the install as that user from the start rather than starting as root like you would on a remote server.</p>","title":"Machine:"},{"location":"community/guides/chazguides/home-server/#router","text":"<p>You need some ports forwarded to that machine on your router.  Explaining how to do that for any arbitrary router is out of scope, but I\u2019ll show you where it is on my Netgear.</p> <p>A remote server like one at Hetzner is just exposed to the open internet, so when you connect to that server on port 123, you\u2019re connecting directly to that specific machine.  Your home network doesn\u2019t work like that.  Your ISP gives you a single IP address, and your router translates all traffic in and out of your network to make sure it gets to the correct place.  Thas means that when a connection from the outside comes in, it is connecting to the router, not any individual machine.  You need to set up port forwarding so that when you try to connect to Radarr, for example, your router knows to send this request to the machine where you\u2019ve installed Radarr.</p> <p>There are two parts to what you need to do: GIve your server an unchanging local IP address Forward requests from the outside on relevant ports to that IP address.</p> <p>The first is required because typically your router will be able to configure port forwarding to an IP address, so you don\u2019t want the IP of your server changing.  Typically, on your router, everything gets an IP assigned automagically by the router\u2019s DHCP server, so the IP address of a specific thing might change.  Depending on how your network is set up, it may be unlikely, but it\u2019s a possibility nonetheless, so we\u2019re going to make sure it doesn\u2019t happen by telling the router \u201cAlways give this machine the IP address 1.2.3.4\u201d.</p> <p>On my Netgear, they call this \u201cAddress Reservation\u201d and it\u2019s found under \u201cLAN Setup\u201d:</p> <p>I scroll to the end of that list, click \u201cAdd\u201d, then choose a device and type in the address I want that thing to have.</p> <p>The server I\u2019m installing Saltbox on is \u201coberon\u201d, and I\u2019ve assigned it 192.168.1.5.</p> <p>Next, port forwarding:</p> <p>You can see here that I\u2019ve set it such that outside requests to port 80, 443, 2205, and 3468 get forwarded on to the IP we just assigned to the saltbox server. Depending on the applications you end up installing, you may need to forward other ports.  That example covers the reverse proxy, ssh, and Plex-Autoscan.</p> <p>If your ISP does not allow you to do this, STOP NOW.  You won\u2019t be able to run saltbox at home.</p> <p>At this point, you should be able to SSH to that machine using your domain.</p> <p>ssh YOU@YOUR_DOMAIN -p 2207</p> <p>That should work just like:</p> <p>ssh YOU@192.168.X.Y</p> <p>If it doesn\u2019t, verify all the port-forwarding details.</p> <p>You should also be able to connect to a web server running on that machine.</p> <p>Verify this part is working by installing apache on your server: sudo apt install apache2</p> <p>Then open a web browser and go to your domain [http://yourdomain.tld] . Maybe use your phone with wifi off to make sure the request is coming from outside your house.</p> <p>If you see the default apache page, you\u2019re set to go.</p> <p>Once verified, remove apache: sudo apt remove apache2</p> <p>With that done, we can move on to the install.</p> <p>IF THAT DOESN\u2019T WORK, DON\u2019T CONTINUE UNTIL IT DOES.  Verify your port forwarding setup and try again.  Verify that your ISP allows this.</p> <p>From this point on there is nothing special about the install process on this home server as opposed to a remote server.  I\u2019m just following the wiki.</p> <p>I ran the first (\u201cCombined\u201d) dependency/repo script on this page: https://github.com/Saltbox/Saltbox/wiki/Install%3A-Dependencies-%28Master-Branch%29</p> <p>That ran for a while, and ended here:</p> <p>In my accounts.yml, I\u2019m entering an existing account on the ubuntu machine:</p>  <p>user:   name: chaz   pass: REDACTED   domain: domain.tld   email: chaz@chazlarson.com plex:   user: REDACTED   pass: REDACTED cloudflare:   email: REDACTED   api: REDACTED pushover:   app_token:   user_key:   priority: apprise:</p> <p>I entered my cloudflare credentials because DNS for the domain I\u2019m using is set up there, so the saltbox install is going to create the subdomains for me.</p> <p>I made no changes to settings.yml.</p> <p>Run the preinstall: sudo ansible-playbook saltbox.yml --tags preinstall</p> <p>In my case there were no kernel updates required, so the preinstall didn\u2019t reboot:</p> <p>I am already logged in as the user I specified in accounts.yml, so I didn\u2019t have to log out of the root account and log back in as chaz.  If you specified a new account that the preinstall created, you need to log out and log in as that account.</p> <p>I then set up rclone remote as usual.</p> <p>Next, I ran saltbox setup:</p> <p>sudo ansible-playbook saltbox.yml --tags saltbox</p> <p>In my case the setup ran through without problems the first time:</p> <p>PLAY RECAP ************ localhost               : ok=713  changed=180  unreachable=0    failed=0</p>","title":"Router:"},{"location":"community/guides/chazguides/home-server/#tuesday-14-april-2020-113147-0500-00000040-01322200","text":"<p>docker : Start docker service -----------------------------------------------------...- 121.63s docker : Wait for 30 seconds before commencing ------------------------------------...- 30.65s iperf3 : Build and install iperf3 -------------------------------------------------...- 17.04s system : APT | APT upgrade --------------------------------------------------------...- 16.82s plex : Extra | Stop Plex Container ------------------------------------------------...- 11.39s plex : Create and start container -------------------------------------------------...- 11.30s remote : Rclone VFS | Start 'rclone_vfs.service' ----------------------------------...- 11.03s rutorrent : Settings | Wait for 10 seconds before stopping rutorrent container ----...- 10.43s ombi : Create and start container -------------------------------------------------...- 9.39s docker : Stop docker service ------------------------------------------------------...- 8.48s system : sysctl | Tuning ----------------------------------------------------------...- 7.49s nodejs : Install nodejs -----------------------------------------------------------...- 7.37s plexpy : Create and start container -----------------------------------------------...- 7.03s jackett : Create and start container ----------------------------------------------...- 6.78s nzbhydra2 : Create and start container --------------------------------------------...- 6.22s nodejs : Update npm ---------------------------------------------------------------...- 6.12s remote : Rclone VFS | \"Wait for 5 seconds\" ----------------------------------------...- 5.42s sanity_check : Get all available TAGS ---------------------------------------------...- 5.08s sonarr : Create and start container -----------------------------------------------...- 4.96s lidarr : Create and start container -----------------------------------------------...- 4.88s chaz@oberon:~/saltbox$</p> <p>Now I did one last log out and back in so I could access the docker command.</p> <p>At this point, everything is running and I\u2019m ready to go through the application setup.</p>","title":"Tuesday 14 April 2020  11:31:47 -0500 (0:00:00.040)     0:13:22.200 ***"},{"location":"community/guides/chazguides/no-media/","text":"<p>[in Plex, Emby, Radarr, Sonarr, etc]</p> <p>Usually this is a simple problem, but there are several places where it could be.</p> <p>There are several layers between your Google Drive and Plex [or other app].</p> <ul> <li>rclone remote, which provides the link to your Google Drive.  This is where you sign into your Google account.</li> <li>rclone_vfs service, which makes that rclone remote visible at <code>/mnt/remote</code></li> <li>mergerfs service which combines that mount point with a local \u201cstaging\u201d directory at <code>/mnt/unionfs</code>.</li> <li>mapping of the mergerfs into the various docker containers.</li> </ul> <p>If any layer is having problems, Plex isn\u2019t going to see your media.</p> <p>For purposes of these notes, I\u2019m assuming your setup is based on the current standard Saltbox configuration:</p> <ul> <li>rclone remote is mounted via <code>rclone_vfs</code> [this used to be done by plexdrive]</li> <li>/mnt/unionfs directory is created using <code>merger_fs</code> [used to be done by unionfs]</li> </ul> <p>I\u2019m further assuming that you are using the default file structure as suggested in the Saltbox wiki.</p> <p>See the end of this doc for some notes on how to tell if 1 and 2 are true.</p> <p>MY FOLDERS AND FILES IN THESE SCREENSHOTS WILL NOT MATCH YOURS.  THAT\u2019S FINE AND EXPECTED.</p> <p>When I refer to a shell command throughout, you\u2019re typing the part highlighted in blue and looking for the part highlighted in orange.</p> <p>In most cases, running the mounts tag will clear up any problems you may be having with the various auto-generated service files.</p> <pre><code>cd ~/cloudbox &amp;&amp; sudo ansible-playbook cloudbox.yml --tags mounts\n</code></pre>","title":"I can\u2019t see my media!"},{"location":"community/guides/chazguides/no-media/#a-quick-look","text":"<p>The df command can give you a quick look at things:</p> <pre><code>\u279c  ~ df -h\nFilesystem   Size   Used  Avail  Use%  Mounted on\n...\nlocal:remote  6.1P  107T   224G  100%  /mnt/unionfs\ngoogle:       1.0P  107T   1.0P   10%  /mnt/remote\n\u279c  ~\n</code></pre> <p>That shows a device called \u201cgoogle\u201d [created by rclone config] mounted at <code>/mnt/remote</code> [done by rclone_vfs.service], and then two directories [local and remote, which are both inside the /mnt directory] combined into <code>/mnt/unionfs</code> [that\u2019s done by mergerfs.service]</p> <p>If this looks good, your problem is most likely in the bind mounts within the containers.</p> <p>Now we\u2019ll step through the various layers involved in this and check them one at a time.</p>","title":"A quick look"},{"location":"community/guides/chazguides/no-media/#rclone-remote","text":"<p>The rclone config command should show you the google remote you defined during setup:</p> <pre><code>\u279c  ~ rclone config\nCurrent remotes:\n\nName                Type\n====                ====\ngoogle              drive\n\ne) Edit existing remote\n...\ne/n/d/r/c/s/q&gt; q\n</code></pre> <p>You should be able to get a file listing from that remote:</p> <pre><code>\u279c  ~ rclone lsd google:/Media\n        -1 2018-12-01 20:16:06      -1 Music\n        -1 2019-03-15 19:26:14      -1 Movies\n        -1 2018-12-01 20:14:35      -1 TV\n\u279c  ~\n</code></pre> <p>That file listing should match what\u2019s displayed on the Google Drive website.</p> <p>Yours will probably contain \u201cMovies\u201d and \u201cTV\u201d.</p> <p>If it doesn\u2019t, step one is to fix that.  Recreate or edit that google: rclone remote until the file listings match.</p> <p>Do not continue until those two file listings match.  They won\u2019t match mine; they should both show the same files from YOUR gdrive.</p> <p>Now that the rclone remote is known good, let\u2019s move to the next layer, the rclone_vfs mount.</p>","title":"rclone remote"},{"location":"community/guides/chazguides/no-media/#rclone_vfs-mount","text":"<p>First, let\u2019s check that the service is running:</p> <p><pre><code>\u279c  ~ sudo systemctl status rclone_vfs.service\n\u25cf rclone_vfs.service - Rclone VFS Mount\n   Loaded: loaded (/etc/systemd/system/rclone_vfs.service; enabled; vendor preset: enabled)\n   Active: active (running) since Sat 2019-11-02 06:45:34 EET; 10h ago\n  Process: 1053 ExecStartPre=/bin/sleep 10 (code=exited, status=0/SUCCESS)\n Main PID: 1247 (rclone)\n    Tasks: 23 (limit: 4915)\n   CGroup: /system.slice/rclone_vfs.service\n        \u2514\u25001247 /usr/bin/rclone mount --config=/home/seed/.config/rclone/rclone.conf --user-agent . . .\n\nNov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting Rclone VFS Mount...\nNov 02 06:45:34 Ubuntu-1804-bionic-64-minimal rclone[1247]: Serving remote control on http://127.0.0.1:5572/\nNov 02 06:45:34 Ubuntu-1804-bionic-64-minimal systemd[1]: Started Rclone VFS Mount.\n</code></pre> You want to see \u201c<code>active (running)</code>\u201d there.</p> <p>You can look at the log to find out what\u2019s wrong if it\u2019s not \u201c<code>active (running)</code>\u201d</p> <pre><code>\u279c  ~ sudo journalctl -fu rclone_vfs.service\n-- Logs begin at Mon 2019-08-05 16:56:44 EEST. --\nNov 02 06:42:44 Ubuntu-1804-bionic-64-minimal rclone[9625]: Serving remote control on http://127.0.0.1:5572/\nNov 02 06:42:44 Ubuntu-1804-bionic-64-minimal systemd[1]: Started Rclone VFS Mount.\nNov 02 06:44:09 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopping Rclone VFS Mount...\nNov 02 06:44:09 Ubuntu-1804-bionic-64-minimal rclone[9625]: Fatal error: failed to umount FUSE fs: exit status 1: fusermount: entry for /mnt/remote not found in /etc/mtab\nNov 02 06:44:09 Ubuntu-1804-bionic-64-minimal systemd[1]: rclone_vfs.service: Main process exited, code=exited, status=1/FAILURE\nNov 02 06:44:09 Ubuntu-1804-bionic-64-minimal systemd[1]: rclone_vfs.service: Failed with result 'exit-code'.\nNov 02 06:44:09 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopped Rclone VFS Mount.\n-- Reboot --\nNov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting Rclone VFS Mount...\nNov 02 06:45:34 Ubuntu-1804-bionic-64-minimal rclone[1247]: Serving remote control on http://127.0.0.1:5572/\nNov 02 06:45:34 Ubuntu-1804-bionic-64-minimal systemd[1]: Started Rclone VFS Mount.\n</code></pre> <p>In that log you can see an error from last night when my server ran out of disk space, the rclone_vfs service died, then a reboot [after clearing space]  and it came back up.</p> <p>If there are errors there, first try restarting the service:</p> <pre><code>sudo systemctl restart rclone_vfs\n</code></pre> <p>If that doesn\u2019t get you to an \u201c<code>active (running)</code>\u201d state, try a reboot of the machine.</p> <p>If that doesn\u2019t work, the problem is deeper; maybe a config problem or a failed install?  Read the log.  Chances are the specific problem is called out [missing directory, perhaps].  You\u2019re running a server.  Learn to read logs.  If all fails, take the log information to the Discord, but be prepared to describe what you\u2019ve done and provide details.  Don\u2019t come in with \u201cShit\u2019s busted, my dudes!  What\u2019s wrong?\u201d</p> <p>Now that the service is running, let\u2019s make sure the files are showing up where they are supposed to be.</p> <p>You can extract the location where the rclone_vfs service is mounting your google storage with a quick egrep command:</p> <pre><code>\u279c  ~ egrep -i -e \"/mnt/\" /etc/systemd/system/rclone_vfs.service\n  google: /mnt/remote\nExecStop=/bin/fusermount -uz /mnt/remote\n</code></pre> <p>You can see in that output that rclone_vfs is mounting your google: remote at /mnt/remote.</p> <p>That means that the content of your google drive should also appear at that location.  Let\u2019s check that:</p> <pre><code>\u279c  ~ ls -al /mnt/remote/Media\ntotal 0\ndrwxrwxr-x 1 seed seed 0 Dec  1  2018 Music\ndrwxrwxr-x 1 seed seed 0 Mar 15  2019 Movies\ndrwxrwxr-x 1 seed seed 0 Dec  1  2018 TV\n\u279c  ~\n</code></pre> <p>Note that that matches the file listing from the Google Drive web UI above.</p> <p>If it doesn\u2019t, there\u2019s a problem running the rclone_vfs.service.  Perhaps try running the mounts tag.</p> <p>Do not continue until those two file listings match.  They won\u2019t match mine; they should both show the same files from YOUR gdrive.</p> <p>We\u2019ve established that the rclone remote is good, and the rclone_vfs service is mounting it as a file system at the expected location.</p> <p>The next step is the mergerfs mount where all the apps look for your files.</p>","title":"rclone_vfs mount"},{"location":"community/guides/chazguides/no-media/#mergerfs-service","text":"<p>Just like we did with the rclone_vfs service, check the mergerfs status:</p> <pre><code>\u279c  ~ sudo systemctl status mergerfs.service\n\u25cf mergerfs.service - MergerFS Mount\n   Loaded: loaded (/etc/systemd/system/mergerfs.service; enabled; vendor preset: enabled)\n   Active: active (running) since Sat 2019-11-02 06:45:24 EET; 11h ago\n  Process: 1034 ExecStart=/usr/bin/mergerfs -o category.create=ff,minfreespace=0,allow_other -o dropcacheonclose=true,security_capability=false,xattr=nosys -o statfs_ignore=ro,use_ino,auto_\n    Tasks: 9 (limit: 4915)\n   CGroup: /system.slice/mergerfs.service\n        \u2514\u25001074 /usr/bin/mergerfs -o category.create=ff,minfreespace=0,allow_other -o dropcacheonclose=true,security_capability=false,xattr=nosys -o statfs_ignore=ro,use_ino,auto_cache,um\n\nNov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting MergerFS Mount...\nNov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Started MergerFS Mount.\n</code></pre> <p>As before, if not \u201c<code>active (running)</code>\u201d, you can check the mergerfs log for some clue:</p> <pre><code>\u279c  ~ sudo journalctl -fu mergerfs.service\n-- Logs begin at Mon 2019-08-05 16:56:44 EEST. --\nOct 13 17:00:11 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting MergerFS Mount...\nOct 13 17:00:11 Ubuntu-1804-bionic-64-minimal systemd[1]: Started MergerFS Mount.\n-- Reboot --\nNov 02 06:42:54 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopping MergerFS Mount...\nNov 02 06:42:56 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopped MergerFS Mount.\nNov 02 06:43:06 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting MergerFS Mount...\nNov 02 06:43:06 Ubuntu-1804-bionic-64-minimal systemd[1]: Started MergerFS Mount.\nNov 02 06:44:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopping MergerFS Mount...\nNov 02 06:44:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopped MergerFS Mount.\n-- Reboot --\nNov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting MergerFS Mount...\nNov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Started MergerFS Mount.\n</code></pre> <p>If everything looks good, you can check the contents of the filesystem:</p> <pre><code>\u279c  ~ ls -al /mnt/unionfs/Media\ntotal 0\ndrwxrwxr-x 1 seed seed   120 Sep 28 18:32 .\ndrwxrwxr-x 1 seed seed    62 Sep 28 18:31 ..\ndrwxrwxr-x 1 seed seed   338 Oct 18 20:21 Music\ndrwxrwxr-x 1 seed seed    78 May  3  2019 Movies\ndrwxrwxr-x 1 seed seed 28196 Nov  2 01:42 TV\n\u279c  ~\n</code></pre> <p>Again, this should match all the file listings you\u2019ve looked at so far, at least.</p> <p>There may be some extra folders here depending on a variety of things; other mounts that are included in the mergerfs and so forth.  Probably not, given my assumption that you are using the default configuration.</p> <p>Do not continue until those two file listings match.  They won\u2019t match mine; they should both show the same files from YOUR gdrive.</p> <p>So at this point we know that all the layers on the host are working, so the last step is to check the views inside the containers.</p>","title":"Mergerfs service"},{"location":"community/guides/chazguides/no-media/#docker-volume-maps","text":"<p>All the docker containers that need to access your media files have the relevant directories mapped inside them.  You can have a look at specifically how with the docker inspect command:</p> <pre><code>\u279c  ~ docker inspect plex | head -n 90\n[\n    {\n        \"Id\": \"070d5fc16d4372156c39a6cf2923e6edb2e8576817cbcf9b6432f88f2237a2e8\",\n        \"Created\": \"2019-10-16T19:45:29.93111423Z\",\n        \"Path\": \"/init\",\n        \"Args\": [],\n        \"State\": {\n            \"Status\": \"running\",\n...\n        \"HostConfig\": {\n            \"Binds\": [\n                \"/mnt/unionfs/Media:/data:rw\",\n                \"/tmp:/tmp:rw\",\n                \"/mnt/local/transcodes/plex:/transcode:rw\",\n                \"/opt/plex:/config:rw\",\n                \"/mnt:/mnt:rw\",\n                \"/opt/scripts:/scripts:rw\",\n                \"/dev/shm:/dev/shm:rw\"\n            ],\n...\n\u279c  ~\n</code></pre> <p>I\u2019ve trimmed some stuff out there particularly on the top].  If the \u201cBinds\u201d section isn\u2019t visible, try scrolling up, or increase the \u201c90\u201d to display more lines.  It should be right around the same place as mine, though.</p> <p>Take a look at the \u201c<code>Binds</code>\u201d section.  Each entry there shows a path on the host [on the left] and the location where those files appear inside the container.</p>","title":"Docker volume maps"},{"location":"community/guides/chazguides/no-media/#media-related-defaults","text":"Container/Application INSIDE CONTAINER ON HOST     sonarr <code>/tv</code> <code>/mnt/unionfs/Media/TV</code>   radarr <code>/movies</code> <code>/mnt/unionfs/Media/Movies</code>   lidarr <code>/music</code> <code>/mnt/unionfs/Media/Music</code>   plex <code>/data</code> <code>/mnt/unionfs/Media</code>    <p>For example, that plex line shows that <code>/mnt/unionfs/Media</code> appears inside the container at <code>/data</code>.  Let\u2019s check that:</p> <pre><code>\u279c  ~ docker exec plex ls -al /data\ntotal 4\ndrwxrwxr-x 1 plex plex   120 Sep 28 18:32 .\ndrwxr-xr-x 1 root root  4096 Oct 16 22:45 ..\ndrwxrwxr-x 1 plex plex   338 Oct 18 20:21 Music\ndrwxrwxr-x 1 plex plex    78 May  3  2019 Movies\ndrwxrwxr-x 1 plex plex 28196 Nov  2 01:42 TV\n</code></pre> <p>Again, all the same files as always.</p> <p>If that doesn\u2019t show your files as expected, chances are something happened to the mounts while the container was running and the map has broken.  First restart the container and if that doesn\u2019t work restart the server.</p> <pre><code>\u279c  ~ docker restart plex\nplex\n\u279c  ~\n</code></pre> <p>Then try the \u201c<code>docker exec plex ls -al /data</code>\u201d command again.</p> <p>You may notice above that the /mnt directory is passed through to the container, as well.  This means that, inside the container,      <code>/data</code> and <code>/mnt/unionfs/Media</code> point to the very same location, so these two directory listings should look the same:</p> <p><pre><code>\u279c  ~ docker exec plex ls -al /data\n...\ndrwxrwxr-x 1 plex plex   338 Oct 18 20:21 Music\ndrwxrwxr-x 1 plex plex    78 May  3  2019 Movies\ndrwxrwxr-x 1 plex plex 28196 Nov  2 01:42 TV\n</code></pre> <pre><code>\u279c  ~ docker exec plex ls -al /mnt/unionfs/Media\ntotal 4\n...\ndrwxrwxr-x 1 plex plex   338 Oct 18 20:21 Music\ndrwxrwxr-x 1 plex plex    78 May  3  2019 Movies\ndrwxrwxr-x 1 plex plex 28196 Nov  2 01:42 TV\n</code></pre></p> <p>On my own servers, I typically don\u2019t use the \u201c<code>/data</code>\u201d style mounts.  Since the <code>/mnt</code> directory is mapped into all the containers that use it, I point Radarr, Sonarr, Plex, etc.  all at <code>/mnt/unionfs/Media/BLAH</code> directly.  I do this so that I never have to translate any paths in things like Plex AutoScan.  A given movie file is at <code>/mnt/unionfs/Media/Movies/Whatever (2019)</code> no matter the context.</p> <p>Some common problems are:</p> <p><code>/mnt/unionfs</code> not empty when the mergerfs service starts.</p> <p>The log in that case will look something like this:</p> <pre><code>ubuntu systemd[1]: Starting MergerFS Mount...\nUbuntu mergerfs[10803]: fuse: mountpoint is not empty\nubuntu mergerfs[10803]: fuse: if you are sure this is safe, use the 'nonempty' mount option\nubuntu systemd[1]: mergerfs.service: Control process exited, code=exited status=1\nubuntu systemd[1]: mergerfs.service: Failed with result 'exit-code'.\nubuntu systemd[1]: Failed to start MergerFS Mount.\n</code></pre> <p>If you see this, rerunning the mounts tag, with or without rebuild, actually checks for non empty paths left there as part of a previous failure, and moves the folder to <code>/mnt/unionfs_&lt;date&gt;</code> before mounting again.</p> <pre><code>cd ~/cloudbox &amp;&amp; sudo ansible-playbook cloudbox.yml --tags mounts\n</code></pre> <p>If this is the result of something writing into that directory while the mergerfs service was down, the mounts tag won\u2019t address it.  You\u2019ll have to clean out <code>/mnt/unionfs</code> yourself first.</p>","title":"Media-related defaults:"},{"location":"community/guides/chazguides/no-media/#how-do-i-know-if-i-am-using-rclone_vfs-and-mergerfs","text":"<p>There are a few things you can look at:</p> <p>If you installed recently, rclone_vfs and mergerfs have become the default, so you\u2019re probably using them.  If you installed over a year ago, you\u2019re probably using plexdrive/unionfs.</p> <p>In the following examples, you\u2019re typing the part in blue and looking for the part highlighted in orange.</p> <p>Look at the settings file:</p> <pre><code>\u279c  cloudbox git:(master) head adv_settings.yml\n---\nSystem:\n  timezone: auto\nMounts:\n  unionfs: mergerfs     &lt;&lt;&lt;&lt; RIGHT\n  remote: rclone_vfs    &lt;&lt;&lt;&lt; HERE\nPlex:\n  open_port: no\n  force_auto_adjust_quality: no\n  force_high_output_bitrates: no\n\u279c  cloudbox git:(master)\n</code></pre> <p>Check the status of the services <pre><code>\u279c  cloudbox git:(master) service rclone_vfs status\n\u25cf rclone_vfs.service - Rclone VFS Mount\n   Loaded: loaded (/etc/systemd/system/rclone_vfs.service; enabled; vendor preset: enabled)\n   Active: active (running) since Sun 2019-06-16 22:41:58 EEST; 1 day 18h ago\n\u2026\n\n\u279c  cloudbox git:(master) service mergerfs status\n\u25cf mergerfs.service - MergerFS Mount\n   Loaded: loaded (/etc/systemd/system/mergerfs.service; enabled; vendor preset: enabled)\n   Active: active (running) since Sun 2019-06-16 22:41:48 EEST; 1 day 18h ago\n\u2026\n</code></pre></p> <p>If you\u2019re not using either rclone_vfs or mergerfs you\u2019ll see errors there instead.</p> <p>Check the filesystem behind the mounts:</p> <pre><code>\u279c  cloudbox git:(master) sudo mount | egrep \"remote\"\nlocal:remote on /mnt/unionfs type fuse.mergerfs \u2026  &lt;&lt;&lt;&lt; Mergerfs\ngoogle: on /mnt/remote type fuse.rclone \u2026          &lt;&lt;&lt;&lt; RClone\n\u279c  cloudbox git:(master)\n</code></pre>","title":"HOW DO I KNOW IF I AM USING RCLONE_VFS AND MERGERFS?"},{"location":"community/guides/chazguides/pas-map/","text":"<p>There are these things in the Plex Autoscan config, and they seem to cause a great deal of consternation.</p>","title":"Plex Autoscan Mappings; how do they work?"},{"location":"community/guides/chazguides/pas-map/#server_path_mappings","text":"<p>Here is one of mine, for example:</p> <pre><code>\"SERVER_PATH_MAPPINGS\": {\n  \"/mnt/unionfs/Media/Movies/\": [\n    \"/movies/\",\n    \"/mnt/unionfs/Media/Movies/\",\n    \"Movies/Media/Movies/\"\n  ]\n},\n</code></pre> <p>Plex Autoscan is going to use these \u201cmaps\u201d to decide what path to tell Plex to scan.</p> <p>Each one should be filled out like this:</p> <pre><code>   \"Plex sees files at this path\": [\n      \"App #1 sees those same files at this path\",\n      \"App #2 sees those same files at this path\",\n      \"Google Drive #1 path to those files\",\n      ...etc\n    ],\n</code></pre> <p>Case is significant.  \u201cMovies\u201d does not match \u201cmovies\u201d, for example.</p> <p>The JSON formatting is significant.  Those brackets and such matter.</p> <p>The various paths are only required if you're using them.  For example, if you aren't using Google Drive Monitoring you don't have to include the Google Drive path.</p>","title":"<code>SERVER_PATH_MAPPINGS</code>:"},{"location":"community/guides/chazguides/pas-map/#what-does-plex-autoscan-do-with-them","text":"<p>Here's a generic setup just for this example:</p> <pre><code>   \"SERVER_PATH_MAPPINGS\": {\n     \"/plex/Movie/path/\": [\n       \"/radarr/movie/path/\",\n       \"/google/drive/movie/path/\"\n     ],\n     \"/plex/TV/path/\": [\n       \"/sonarr/tv/path/\",\n       \"/google/drive/tv/path/\"\n     ]\n   },\n</code></pre> <p>Plex Autoscan gets a request for a path like this:</p> <pre><code>/radarr/movie/path/Big Space Movie (2022)/Big Space Movie (2022).mkv\n</code></pre> <p>It looks at the table above to find which one matches the path.  In this case it's:</p> <pre><code>     \"/plex/Movie/path/\": [\n       \"/radarr/movie/path/\",     &lt;&lt;&lt;&lt; THIS ONE RIGHT HERE\n       \"/google/drive/movie/path/\"\n     ],\n</code></pre> <p>PAS then changes \"<code>/radarr/movie/path/</code>\" to \"<code>/plex/Movie/path/</code>\" to make it into</p> <pre><code>/plex/Movie/path/Big Space Movie (2022)/Big Space Movie (2022).mkv\n</code></pre> <p>Then tells Plex to scan that location.</p> <p>Part of \u201ctells Plex to scan\u201d is finding out which library contains the thing.  To do this PAS gets a list of libraries from Plex, then loops through all of them comparing the root paths in the libraries to the path it's about to send. If there\u2019s a match, PAS then issues the scan request to Plex.</p> <p>If there is no Plex Library that matches the path, PAS will display an error in its log [\u201cunable to map to a section ID\u201d].</p> <p>This can also happen if the Plex path is incorrectly entered [It\u2019s not actually the folder configured in a library] or if one of the source paths is incorrect [Radarr isn\u2019t set to save files in the path listed] or some combination of that sort of thing.</p>","title":"What does Plex Autoscan do with them?"},{"location":"community/guides/chazguides/pas-map/#actual-example-from-a-working-setup","text":"<p>Let\u2019s look at one of my sections.</p> <pre><code>  \"/mnt/unionfs/Media/Movies/\": [\n    \"/mnt/unionfs/Media/Movies/\",\n    \"Movies/Media/Movies/\"\n  ],\n</code></pre>","title":"Actual example from a working setup:"},{"location":"community/guides/chazguides/pas-map/#plex","text":"<p>One Plex Movie library is pointed at \"/mnt/unionfs/Media/Movies/Movies\":</p> <p></p> <p>So that\u2019s the \u201cheading\u201d on this map:</p> <pre><code>  \"/mnt/unionfs/Media/Movies/\": [  &lt;&lt;&lt;  PLEX PATH RIGHT HERE\n    \"/mnt/unionfs/Media/Movies/\",\n    \"Movies/Media/Movies/\"\n  ],\n</code></pre>","title":"Plex:"},{"location":"community/guides/chazguides/pas-map/#radarr","text":"<p>Radarr is configured to send updates to Plex Autoscan, so let\u2019s go take a look at it:</p> <p>My root dir for movies in Radarr is \"/mnt/unionfs/Media/Movies/\":</p> <p></p> <p>For example:</p> <p></p> <p>So that\u2019s an element of this map:</p> <pre><code>  \"/mnt/unionfs/Media/Movies/\": [\n    \"/mnt/unionfs/Media/Movies/\",  &lt;&lt;&lt;  RADARR PATH RIGHT HERE\n    \"Movies/Media/Movies/\"\n  ],\n</code></pre>","title":"Radarr:"},{"location":"community/guides/chazguides/pas-map/#google-drive","text":"<p>Lastly, I have Google Drive monitoring enabled, and all my movies get uploaded to a Teamdrive:</p> <p></p> <p>So that\u2019s the last element of this map:</p> <pre><code>  \"/mnt/unionfs/Media/Movies/\": [\n    \"/mnt/unionfs/Media/Movies/\",\n    \"Movies/Media/Movies/\"         &lt;&lt;&lt;  GOOGLE DRIVE PATH RIGHT HERE\n  ],\n</code></pre> <p>Note: the first \u201cMovies\u201d is the name of the drive as it appears in the Google Drive web UI, not the name of your rclone remote.</p> <p>If you had other teamdrives you were monitoring that were also merged into your unionfs, those could come next:</p> <pre><code>  \"/mnt/unionfs/Media/Movies/\": [\n    \"/mnt/unionfs/Media/Movies/\",\n    \"Movies/Media/Movies/\",\n    \"TEAMDRIVE_01/OLD_MOVIES/\"\n  ],\n</code></pre>","title":"Google Drive:"},{"location":"community/guides/chazguides/pas-map/#multiple-applications-or-sources","text":"<p>You need a mapping for each unique library path; for example:</p> <pre><code>   \"SERVER_PATH_MAPPINGS\": {\n     \"plex/Movie/path/\": [\n       \"/radarr/movie/path/\",\n       \"/google/drive/movie/path/\"\n     ],\n     \"plex/TV/path/\": [\n       \"/sonarr/tv/path/\",\n       \"/google/drive/tv/path/\"\n     ]\n   },\n</code></pre> <p>If there are common roots, they can be consolidated.  For example, this:</p> <pre><code>   \"SERVER_PATH_MAPPINGS\": {\n     \"/mnt/unionfs/Media/Movies/\": [\n       \"/incoming/Movies/\",\n       \"/google_drive/Stuff/Movies/\"\n     ],\n     \"/mnt/unionfs/Media/TV/\": [\n       \"/incoming/TV/\",\n       \"/google_drive/Stuff/TV/\"\n     ]\n   },\n</code></pre> <p>Could be reduced to:</p> <pre><code>   \"SERVER_PATH_MAPPINGS\": {\n     \"/mnt/unionfs/Media/\": [\n       \"/incoming/\",\n       \"/google_drive/Stuff/\"\n     ]\n   },\n</code></pre> <p>That\u2019s possible since the TV and Movie folders are all the same until that bottom level.</p> <p>This is just a string replacement.  You don\u2019t need a map for every media type, necessarily.  You need a map for each unique set of answers to the question:</p> <p>\u201cWhen some app sees a file at location /what/ever/it/is, where does Plex sees it?\u201d</p>","title":"Multiple applications or sources"},{"location":"community/guides/chazguides/pas-map/#generalized-process-flow","text":"<p>Now, what Plex Autoscan is going to do with that, in generic form:</p> <p>Given this SERVER_PATH_MAPPING:</p> <pre><code>\"PATH_WHERE_PLEX_LOOKS\":[\n    \"PATH_WHERE_RADARR_LOOKS\",\n    \"PATH_WHERE_APP_TWO_LOOKS\",\n    \"PATH_ON_GOOGLE_DRIVE\"\n],\n</code></pre>","title":"Generalized Process Flow"},{"location":"community/guides/chazguides/pas-map/#example-1","text":"<p>Plex Autoscan processes <pre><code>PATH_WHERE_RADARR_LOOKS/bing/bang/boing\n</code></pre> based on a request from Radarr.</p> <p>Plex Autoscan finds <pre><code>PATH_WHERE_RADARR_LOOKS\n</code></pre> in the list, so it does a substitution based on the map and tells Plex to scan: <pre><code>PATH_WHERE_PLEX_LOOKS/bing/bang/boing\n</code></pre></p>","title":"Example 1"},{"location":"community/guides/chazguides/pas-map/#example-2","text":"<p>Plex Autoscan processes <pre><code>PATH_WHERE_APP_TWO_LOOKS/bing/bang/boing\n</code></pre> based on a request from a second application; maybe it's a second Radarr, or Couch Potato, or a custom script.  Whatever the source, this source sees those same files at <code>PATH_WHERE_APP_TWO_LOOKS</code>, so that\u2019s what it sends to Plex Autoscan.</p> <p>Plex Autoscan finds <pre><code>PATH_WHERE_APP_TWO_LOOKS\n</code></pre> in the list, so it does a substitution based on the map and tells Plex to scan <pre><code>PATH_WHERE_PLEX_LOOKS/bing/bang/boing\n</code></pre></p>","title":"Example 2"},{"location":"community/guides/chazguides/pas-map/#example-3","text":"<p>Plex Autoscan processes <pre><code>PATH_ON_GOOGLE_DRIVE/bing/bang/boing\n</code></pre> based on Google Drive Monitoring.</p> <p>Plex Autoscan finds <pre><code>PATH_ON_GOOGLE_DRIVE\n</code></pre> in the list, so it does a substitution based on the map and tells Plex to scan <pre><code>PATH_WHERE_PLEX_LOOKS/bing/bang/boing\n</code></pre></p>","title":"Example 3"},{"location":"community/guides/chazguides/pas-map/#example-4-error-case","text":"<p>Plex Autoscan processes <pre><code>SOME_RANDOM_PATH/bing/bang/boing\n</code></pre> based on some trigger, maybe a manual scan.</p> <p>Plex Autoscan DOES NOT find <code>SOME_RANDOM_PATH</code> in the list, so no substitution is done and PAS tells Plex to scan <pre><code>SOME_RANDOM_PATH/bing/bang/boing\n</code></pre></p> <p>Plex Autoscan then logs: <code>\u201cunable to map to a section ID\u201d</code> since that path doesn't correspond to any library in Plex.</p>","title":"Example 4 [error case]"},{"location":"community/guides/chazguides/pas-map/#server_file_exist_path_mappings","text":"<p>PAS uses this map to alter path mappings before checking that the file exists.</p> <pre><code>\"SERVER_FILE_EXIST_PATH_MAPPINGS\": {\n    \"Files are on host at this path\": [\n        \"Plex sees files at this path\"\n    ]\n},\n</code></pre> <p>Following the example above, my mappings here is:</p> <pre><code>\"SERVER_FILE_EXIST_PATH_MAPPINGS\": {\n  \"/mnt/unionfs/Media/Movies/\": [\n    \"/mnt/unionfs/Media/Movies/\",\n    ]\n},\n</code></pre> <p>In the default case, it looks like this:</p> <pre><code>\"SERVER_FILE_EXIST_PATH_MAPPINGS\": {\n  \"/mnt/unionfs/Media/\": [\n    \"/data/\",\n    ]\n},\n</code></pre> <p>Files are visible on the host at \u2018/mnt/unionfs/Media/Movies/\u2026\u2019 and inside Plex at \u2018/data/Movies/\u2026\u2019.</p> <p>Same string substitution concepts as above apply here.</p>","title":"<code>SERVER_FILE_EXIST_PATH_MAPPINGS</code>:"},{"location":"community/guides/chazguides/server/","text":"<p>Yes.</p> <p>Wait, no.</p> <p>Um, maybe.  Try it and see.</p> <p>The answer to this question depends on a whole bunch of things, including but not limited to:</p> <ul> <li>CPU</li> <li>Memory</li> <li>Storage type</li> <li>Format of media</li> <li>Location of server</li> <li>Location of clients</li> <li>Type of clients</li> <li>Number of simultaneous streams</li> <li>Transcoding or not</li> <li>Expectations of clients</li> <li>Random nonsense</li> </ul>","title":"Can I run Saltbox on this server?"},{"location":"community/guides/chazguides/server/#server-hardware","text":"<p>For example, at time of writing the author had a Hetzner EX42-NVME in Helsinki.  Nearly all users were in the Minneapolis area on Comcast cable.  One user in Utah, one in Brisbane, Australia.  No 4K media.  The box was an AIO; usenet downloading happened on that box as well as streaming and no throttles were in place to slow NZBget or Cloudplow while Plex was streaming.</p> <p>For the most part, this box met requirements during its tenure.  All author's streaming happened over a 1G fiber line to an AppleTV.  Most other active streamers used Plex Web, Roku, or a Smart TV Plex app.  The guy in Brisbane had trouble streaming due to his local ISP [Telstra], but streaming worked great from a Gold Coast hotel.</p> <p>However, another fellow, who lives blocks away from the author, got one of these same servers and found it unusable for his target usage.  Maybe that was a config issue [didn't seem to be], but it illustrates that there is no \"one-size-fits-all\" answer.</p> <p>Ultimately, there\u2019s not really a sure way to answer this question.</p> <p>Plex\u2019 article on the topic is here.</p>","title":"Server Hardware"},{"location":"community/guides/chazguides/server/#plex-metadata","text":"<p>Plex saves metadata [posters, etc] for all your media; that gets stored in <code>/opt/plex</code> and as your library grows so does that directory.  Required disk space therefore grows over time.  This directory can be quite large.</p> <p>For example:</p> <p>Here Plex has 9640 movies and 137140 TV episodes.  Radarr is tracking 11608 movies and Sonarr 3070 series.</p> <pre><code>ncdu 1.14.1 ~ Use the arrow keys to navigate, press ? for help\n--- /opt -------------------------------------------------------\n   78.3 GiB [##########] /plex\n   10.0 GiB [#         ] /radarr\n    4.2 GiB [          ] /sonarr\n</code></pre> <p>Here Plex has a lot more than that.</p> <pre><code>ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help\n--- /opt -------------------------------------------------------\n  274.5 GiB [##########] /plex\n   23.2 GiB [          ] /cj1\n    7.4 GiB [          ] /tautulli\n</code></pre>","title":"Plex Metadata:"},{"location":"community/guides/chazguides/server/#plex-transcoding","text":"<p>Ideally, all your clients would Direct Play everything; in that case the server is just shoveling bits out as fast as it can and you don\u2019t need any CPU power.  In practice, some transcoding will be happening.</p> <p>There are two types of transcoding; hardware or software.  Software transcoding is CPU intensive, but higher-quality.  Hardware transcoding doesn\u2019t burden your CPU [so it\u2019s free to continue extracting rar files or something], but it\u2019s typically lower quality.  Depending on the specific CPU, dramatically lower quality.</p> <p>Some Intel CPUs support hardware transcoding, a smaller subset of AMD processors support hardware transcoding, so if you want hardware transcoding you probably want Intel [assuming you\u2019re not using a separate GPU on a video card to do it].</p> <p>But that\u2019s just Plex.</p>","title":"Plex transcoding:"},{"location":"community/guides/chazguides/server/#context-acquisition","text":"<p>You\u2019re looking to run Saltbox, so chances are you\u2019re downloading via Usenet or torrents, so there are other concerns.</p>","title":"Context Acquisition:"},{"location":"community/guides/chazguides/server/#usenet","text":"<p>Usenet is all about speed of disk access as things are unrar\u2019ed.  An SSD should be considered required, and NVME highly recommended.  In practical terms, you should have at least 300GB of space available for downloading and extracting.  That\u2019s a general idea; sure you can make do with less, but it may be tight.  The author's first cloud server had a 160GB disk, and it was very tight.</p>","title":"Usenet:"},{"location":"community/guides/chazguides/server/#torrents","text":"<p>If you\u2019re downloading torrents from private servers, you probably need to seed things for some minimal amount of time; so multiple TBs of disk space are a plus.</p>","title":"Torrents:"},{"location":"community/guides/chazguides/server/#client-peering-to-the-server","text":"<p>Depending on where you are in the world, peering to cloud servers will be different.  If you\u2019re in the US, Hetzner\u2019s German data centers are typically pretty good, but YMMV.</p> <p>If you want a server in the US for that reason, it will probably be more expensive.</p> <p>And so on.</p> <p>So, the only way to answer this question is:</p> <p>Maybe; try it and see.</p> <p>The other way this question is posed is:</p>","title":"Client Peering to the Server:"},{"location":"community/guides/chazguides/server/#what-is-the-cheapest-vps-or-dedi-on-which-i-can-run-saltbox","text":"<p>That question cannot be answered in any meaningful sense other than the requirements laid out in the docs.</p> <p>Saltbox itself and the apps it installs do not have particularly great hardware requirements to run.  Some docker containers, a couple services.  You can install Saltbox on a tiny little Digital Ocean instance or the like.</p> <p>The apps obviously have higher requirements if you want them to actually do anything, so whether a given box will work for you is entirely down to what you\u2019re going to do with it.</p> <p>Refer to the previous section.</p> <p>Again, the only way to answer this question is:</p> <p>Maybe; try it and see.</p>","title":"What is the cheapest VPS or dedi on which I can run saltbox?"},{"location":"community/guides/chazguides/success/","text":"<p>Did my Saltbox install succeed?</p> <p>If you started with the first install step</p> <p>And went through the first five steps, completely and without seeing any errors, it should be.</p> <p>Perhaps you skipped some of those 5 required steps.  If so, why?  Go back to the beginning and start again.</p> <p>Perhaps you ignored some errors.  If so, why?  Go back to the beginning and start again.</p> <p>The install is complete when you get to the end of this step with no errors.</p> <p>It\u2019s not complete until then.</p> <p>What does success look like?</p> <p>After running the Saltbox install command:</p> <pre><code>~$ sb install saltbox\n</code></pre> <p>A lot of logging information will scroll by.</p> <p>Eventually, it will stop, and if successful, will display something like this:</p> <p>TODO: REPLACE WITH SALTBOX VERSION</p> <pre><code>PLAY RECAP ************************************************************************************\nlocalhost               : ok=713  changed=180  unreachable=0    failed=0\n\nTuesday 14 April 2020  11:31:47 -0500 (0:00:00.040)     0:13:22.200 *********\n===============================================================================\ndocker : Start docker service -----------------------------------------------------...- 121.63s\ndocker : Wait for 30 seconds before commencing ------------------------------------...- 30.65s\niperf3 : Build and install iperf3 -------------------------------------------------...- 17.04s\nsystem : APT | APT upgrade --------------------------------------------------------...- 16.82s\nplex : Extra | Stop Plex Container ------------------------------------------------...- 11.39s\nplex : Create and start container -------------------------------------------------...- 11.30s\nremote : Rclone VFS | Start 'rclone_vfs.service' ----------------------------------...- 11.03s\nrutorrent : Settings | Wait for 10 seconds before stopping rutorrent container ----...- 10.43s\nombi : Create and start container -------------------------------------------------...- 9.39s\ndocker : Stop docker service ------------------------------------------------------...- 8.48s\nsystem : sysctl | Tuning ----------------------------------------------------------...- 7.49s\nnodejs : Install nodejs -----------------------------------------------------------...- 7.37s\nplexpy : Create and start container -----------------------------------------------...- 7.03s\njackett : Create and start container ----------------------------------------------...- 6.78s\nnzbhydra2 : Create and start container --------------------------------------------...- 6.22s\nnodejs : Update npm ---------------------------------------------------------------...- 6.12s\nremote : Rclone VFS | \"Wait for 5 seconds\" ----------------------------------------...- 5.42s\nsanity_check : Get all available TAGS ---------------------------------------------...- 5.08s\nsonarr : Create and start container -----------------------------------------------...- 4.96s\nlidarr : Create and start container -----------------------------------------------...- 4.88s\nchaz@oberon:~/cloudbox$\n\nNote this part: it\u2019s even color-coded:\nPLAY RECAP ************************************************************************************\nlocalhost               : ok=713  changed=180  unreachable=0    failed=0\n\nNo red there.\n\nEmphasizing what you want to see:\nok=713   changed=180   unreachable=0   failed=0\n\nZero failures.\n\nIf you are not left at a prompt like this after running the cloudbox install, chances are an error occurred during the install, and typically that error is shown at the end here.\n\nIf you come to the discord asking for help, this log will be the first thing we ask you for.\n\nOnce more for emphasis:\nIf you come to the discord asking for help, this log will be the first thing we ask you for.\nWhat does an error look like?\n\n\nFor example, if I enter a bad domain in my accounts.yml:\n\n---\nuser:\n  name: REDACTED\n  pass: REDACTED\n  domain: bing.bang.boing\n  email: REDACTED\n...\n\nIt runs for a bit and stops here:\n\nTASK [pre_tasks : Add Subdomain | Cloudflare: Add 'cloudbox' subdomain to 'bing.bang.boing'] *********************************************************************************\nTuesday 14 April 2020  11:53:29 -0500 (0:00:00.142)     0:00:52.680 *********\nfatal: [localhost]: FAILED! =&gt; {\"changed\": false, \"msg\": \"No zone found with name bing.bang.boing\"}\n\nPLAY RECAP **********************************************************************\nlocalhost               : ok=131  changed=3 unreachable=0   failed=1\n\nTuesday 14 April 2020  11:53:30 -0500 (0:00:00.779)     0:00:53.460 *********\n===============================================================================\nsanity_check : Get all available TAGS ---------------------------------------------------------------------------------...- 5.02s\nGathering Facts ---------------------------------------------------------------------------------...- 1.51s\n...\nTRIMMED FOR SPACE\n...\nsettings : Copy | Check if 'ansible.cfg' exists ---------------------------------------------------------------------------------...- 0.35s\nchaz@oberon:~/cloudbox$\n\nLots of red there, showing exactly what went wrong.\n\nOr, If I set the cloudflare email in the config to a bad value:\n\n...\ncloudflare:\n  email: bing@bang.boing\n  api: REDACTED\n...\n\n\nTASK [pre_tasks : Add Subdomain | Cloudflare: Add 'cloudbox' subdomain to 'DOMAIN.TLD'] ********************************************************************************************\nTuesday 14 April 2020  11:56:54 -0500 (0:00:00.224)     0:00:52.892 *********\nfatal: [localhost]: FAILED! =&gt; {\"changed\": false, \"msg\": \"API request not authenticated; Status: 403; Method: GET: Call: /zones?name=DOMAIN.TLD; Error details: code: 9103, error: Unknown X-Auth-Key or X-Auth-Email; \"}\n\nPLAY RECAP *********************************************************************************\nlocalhost               : ok=131  changed=2 unreachable=0   failed=1\n\nTuesday 14 April 2020  11:56:55 -0500 (0:00:00.686)     0:00:53.579 *********\n===============================================================================\nsanity_check : Get all available TAGS ---------------------------------------------------------------------------------...- 5.06s\nGathering Facts ---------------------------------------------------------------------------------...- 1.52s\n...\nTRIMMED FOR SPACE\n...\n\nsettings : Start | Check to see if yyq is installed ---------------------------------------------------------------------------------...- 0.35s\nchaz@oberon:~/cloudbox$\n\nAgain, lots of red there, showing exactly what went wrong.\n\nTypically, all errors will be displayed in that manner.\n\nMaybe docker didn\u2019t get installed, maybe your Plex credentials are bad, maybe some network issue prevented the install from grabbing a thing from github, etc.\n\nWhatever it is will be displayed in that install log, and no one can say anything more than \u201cI\u2019m sorry it didn\u2019t work\u201d if this output is not provided.\n\nIf you come to the discord asking for help, this log will be the first thing we ask you for.\n\nOnce more for emphasis:\nIf you come to the discord asking for help, this log will be the first thing we ask you for.\nWhat now?\nIs DNS configured?\nIf you entered your cloudflare credentials into the settings, the install should have created subdomains at cloudflare for you.\n\nYou can verify this with the ping utility:\n\n(nothing special about my choice of ombi here)\n\nYou should see something like:\n\nchaz@oberon:~/cloudbox$ ping ombi.YOURDOMAIN.TLD\nPING ombi.YOURDOMAIN.TLD (111.222.333.444): 56 data bytes\n64 bytes from 111.222.333.444: icmp_seq=0 ttl=48 time=114.425 ms\n\nThat IP address should be the IP address of the server.  If this is a home server, it should be your external IP.\n\nIf instead you should see something like:\n\nchaz@oberon:~/cloudbox$ ping ombi.YOURDOMAIN.TLD\nping: cannot resolve ombi.YOURDOMAIN.TLD: Unknown host\n\n...then you need to fix your DNS setup.  Either enter valid Cloudflare credentials in the settings, OR, if you are not using Cloudflare, go set up the required subdomains manually at your DNS provider.\nAre the containers running?\nThe install should leave you with all the docker containers  set up and running.\n\nVerify this with docker ps\n\n(The display here has been edited for readability and space)\n\nchaz@oberon:~/cloudbox$ docker ps\nCONTAINER ID   IMAGE                                      CREATED           STATUS\n99c552628534   hotio/lidarr                               27 minutes ago    Up 27 minutes\nfae88a0e46d1   hotio/radarr                               27 minutes ago    Up 27 minutes\na5858358c3f8   hotio/sonarr:phantom                       27 minutes ago    Up 27 minutes\n84e39d15fbdd   hotio/nzbhydra2                            27 minutes ago    Up 27 minutes\na579ca009eb2   hotio/jackett                              27 minutes ago    Up 27 minutes\n0d879c79a547   horjulf/rutorrent-autodl                   28 minutes ago    Up 28 minutes\na1d387692b30   hotio/nzbget                               28 minutes ago    Up 28 minutes\nc4b5b3a73aeb   organizrtools/organizr-v2:plex             29 minutes ago    Up 29 minutes\n974f5bc87364   portainer/portainer                        29 minutes ago    Up 29 minutes\n7ac30109104c   hotio/ombi                                 29 minutes ago    Up 29 minutes\n0cb9c230f5f1   tautulli/tautulli:nightly                  30 minutes ago    Up 30 minutes\nbed4af6dc439   cloudb0x/plex:latest                       31 minutes ago    Up 30 minutes\n18b10e11029a   jrcs/letsencrypt-nginx-proxy-companion  31 minutes ago   Up 31 minutes\n51b214fdf273   jwilder/nginx-proxy                        31 minutes ago    Up 31 minutes\n</code></pre> <p>That\u2019s the list of containers installed by the default setup at the time of writing.</p> <p>There should be no way for the install to complete without errors, but leave no containers running. Is the proxy running?</p> <p>You can verify the proxy with curl:</p> <p>(nothing special about my choice of ombi here)</p> <pre><code>chaz@oberon:~/cloudbox$ curl http://ombi.DOMAIN.TLD | head -n 20\n  % Total   % Received % Xferd  Average Speed   Time    Time    Time  Current\n                                Dload  Upload   Total   Spent   Left  Speed\n100   169  100   169    0   0  12071    0 --:--:-- --:--:-- --:--:-- 12071\n&lt;html&gt;\n&lt;head&gt;&lt;title&gt;301 Moved Permanently&lt;/title&gt;&lt;/head&gt;\n&lt;body&gt;\n&lt;center&gt;&lt;h1&gt;301 Moved Permanently&lt;/h1&gt;&lt;/center&gt;\n&lt;hr&gt;&lt;center&gt;nginx/1.17.6&lt;/center&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>That\u2019s expected, it\u2019s the standard cloudbox behavior where the non-secure URL forwards to the secure URL.</p> <p>Tell curl to follow the redirect by adding -L:</p> <p>You're ready to start the application setup in the wiki.</p>","title":"Did my Saltbox install succeed?"},{"location":"community/guides/chazguides/teamdrive/","text":"<p>This is a Cloudbox article that has not yet been updated for saltbox.  The information therein may not apply to Saltbox.</p> <p>How do I mount a teamdrive?</p>","title":"How do I mount a teamdrive?"},{"location":"community/guides/chazguides/tip44/","text":"<p>This is a Cloudbox article that has not yet been updated for saltbox.  The information therein may not apply to Saltbox.</p> <p>Tip 44: UNSUPPORTED Shared Drive/Service Account setup for Cloudbox</p>","title":"Tip 44 Guide to Shared Drive/Service Account setup for Saltbox"},{"location":"faq/Backup%20and%20Restore/","text":"<p>IT IS QUITE PROBABLE THAT SOME INFORMATION HERE IS OUTDATED</p> <p>PLEASE OPEN ISSUES</p>","title":"Backup and Restore"},{"location":"faq/Backup%20and%20Restore/#what-is-backed-up","text":"<p>Only app data located in <code>/opt</code> and relevant config files (as listed below) are backed up.  The backup script does this by creating tarball files (.tar) for each folder in <code>/opt</code>/ and placing them into your backup folder (as set in <code>backup_config.yml</code>). The folders in <code>/opt</code> are all* backed up without regard for whether Saltbox created them in the first place.  For example, if you create <code>/opt/bingbangboing</code> it will be backed up and restored by Saltbox.</p> <p>If you have set it up, the community repo is located in <code>/opt</code>, so it will get backed up [this includes any changes you've made in that repo to the config or roles].  There is no catalog kept of what community roles you may have run, so none of the roles themselves will be run automatically on restore, but the data will be backed up and restored.</p> <p>Service files from <code>/etc/systemd/system</code> are synced to <code>/opt/systemd-backup</code> as part of the backup, so they are included in the tarball creation.  This includes things like the <code>rclone_vfs</code>, <code>mergerfs</code>, <code>cloudplow</code>, <code>plex_autoscan</code>, and other system service files.  If you have added additional mounts and the like via your own service files [perhaps with tip #44 or <code>samount</code> or the like], these extra service files will be backed up, but will not be automatically restored.</p> <p>Torrent seeding content, NZBGet queue, anything in <code>/mnt/</code>, <code>/home/</code>, or anywhere else other than the <code>/opt/</code> folder, will NOT be backed up (media files are moved to the cloud via Cloudplow, anyway). If you do want to backup your seeding data, check out the scripts located in <code>/opt/scripts/rclone/</code> folder.</p> <p>If Rclone/Rsync are enabled, the backup will be uploaded to a remote destination. </p> <p>If <code>keep_local_copy</code> is enabled, the backup will remain locally in the backup folder; If NOT, the backup will be deleted. If you decide to disable Rclone/Sync, then at least have <code>keep_local_copy</code> enabled, or else the backup will be created and then deleted right after. </p> <p>The config files that are backed up are: </p> <ul> <li> <p><code>ansible.cfg</code></p> </li> <li> <p><code>accounts.yml</code></p> </li> <li> <p><code>settings.yml</code></p> </li> <li> <p><code>adv_settings.yml</code></p> </li> <li> <p><code>rclone.conf</code></p> </li> <li> <p><code>backup_excludes.txt</code> (if one exists in the <code>saltbox</code> folder).</p> </li> </ul> <p>These files are kept separately from the backup tarball files to allow for easy access.</p> <p>Note that the <code>.ansible_vault</code> file is NOT backed up.</p> <p>Nice table to see what is restored during simple backup/restore:</p>    <pre>                         </pre> Items Backed UP <pre>     </pre> Backed Up From <pre>     </pre> Restored To     Application Data <code>/opt/</code> <code>/opt/</code>   Ansible Config <code>/srv/git/saltbox/ansible.cfg</code>    Account Settings <code>/srv/git/saltbox/accounts.yml</code>    Saltbox Settings <code>/srv/git/saltbox/settings.yml</code>    Saltbox Advanced Settings <code>/srv/git/saltbox/adv_settings.yml</code>    Backup Excludes List (custom) <code>/srv/git/saltbox/backup_excludes_list.txt</code> <code>~/saltbox/backup_excludes_list.txt</code>   Rclone Config <code>~/.config/rclone/rclone.conf</code> <code>~/.config/rclone/rclone.conf</code>","title":"What is backed up?"},{"location":"faq/Backup%20and%20Restore/#what-is-cloudbox-restore-service","text":"<p>An optional service that allows for easy backing up and restoring of CLIENT-SIDE ENCRYPTED config files.</p> <p>The config files that are backed up are: </p> <ul> <li> <p><code>ansible.cfg</code></p> </li> <li> <p><code>accounts.yml</code></p> </li> <li> <p><code>settings.yml</code></p> </li> <li> <p><code>adv_settings.yml</code></p> </li> <li> <p><code>backup_config.yml</code></p> </li> <li> <p><code>rclone.conf</code></p> </li> </ul> <p>These files are the ones needed to run a successful restore. </p> <p>Note: <code>backup_excludes_list.txt</code> are not backed up into the Restore Service, simply because it is not important for a restore to work and also because it IS automatically restored during the restore process itself.</p> <p>How does this work?</p> <ol> <li> <p>User fills in a username and password for Restore Service in the [[backup config |Saltbox-Backup-and-Restore-Settings]]. </p> </li> <li> <p>During backup, config files are encrypted on the client-side, using a salt-hashed version of the username and password (your raw username is never sent to the Restore Service), and then uploaded to the Restore Service.</p> </li> <li> <p>When a user needs to restore their backup on a new box, they can pull their backed up config files from the Restore Service with a single command.</p> </li> </ol> <p>The source code for the Restore Service Scripts are listed below: - https://github.com/saltyorg/Saltbox/blob/master/roles/backup/tasks/restore_service.yml (Backup Script) - https://github.com/saltyorg/scripts/blob/master/restore.sh (Restore Script)</p>","title":"What is Cloudbox Restore Service?"},{"location":"faq/Cloud%20Storage/","text":"","title":"Cloud Storage"},{"location":"faq/Cloud%20Storage/#does-saltbox-support-encrypted-data-on-the-cloud","text":"<p>In short, no. Saltbox does not come with encryption support out-of-box.</p>","title":"Does Saltbox support encrypted data on the cloud?"},{"location":"faq/Cloud%20Storage/#why-does-saltbox-not-support-encryption-data-on-the-cloud","text":"<p>While there are pro's and cons for using either encrypted or unencrypted data on cloud services, we've decided to not deal with encryption for the out of box setup.</p> <p>However, since Saltbox uses Rclone VFS to mount cloud data, you can tweak the mounts and remotes to do this yourself. But doing so comes with no support/help from us. </p>","title":"Why does Saltbox not support encryption data on the cloud?"},{"location":"faq/Cloud%20Storage/#dont-see-your-remote-files-in-mntremote","text":"<p>See here</p>","title":"Don't see your remote files in /mnt/remote?"},{"location":"faq/Cloudflare/","text":"","title":"Cloudflare"},{"location":"faq/Cloudflare/#api-request-not-authenticated","text":"<p>If you get this error during SB Install:</p> <pre><code>fatal: [localhost]: FAILED! =&gt; {\"changed\": false, \"msg\": \"API request not authenticated; Status: 403; Method: GET: Call: /zones?name=; Error details: code: 9103, error: Unknown X-Auth-Key or X-Auth-Email; \"}\n</code></pre> <p>Make sure:</p> <ul> <li> <p>The <code>email</code> in settings.yml matches the one you have listed for your Cloudflare.com account.</p> </li> <li> <p>The <code>cloudflare_api_key</code> in  settings.yml matches your <code>domain</code>'s Cloudflare Global API Key.</p> </li> </ul>","title":"API request not authenticated"},{"location":"faq/Cloudplow/","text":"","title":"Cloudplow"},{"location":"faq/Cloudplow/#stuck-on-waiting-for-running-upload-to-finish-before-proceeding","text":"<p>If the activity log is stuck on:</p> <pre><code>2018-06-03 13:44:59,659 - INFO       - cloudplow            - do_upload                      - Waiting for running upload to finish before proceeding...\n</code></pre> <p>This means that an upload task was prematurely canceled and it left lock file(s) to prevent another upload.</p> <p>To fix this, run this command:</p> <pre><code>rm -rf /opt/cloudplow/locks/*\n</code></pre> <p>or</p> <pre><code>sudo systemctl restart cloudplow\n</code></pre>","title":"Stuck on \"Waiting for running upload to finish before proceeding...\""},{"location":"faq/Docker/","text":"","title":"Docker"},{"location":"faq/Docker/#why-does-saltbox-use-the-docker-network-saltbox-instead-of-bridge","text":"<p>(1) keeps all Saltbox containers organized under one network; and (2), bridge network does not allow network aliases.</p>","title":"Why does Saltbox use the Docker network \"saltbox\" instead of bridge?"},{"location":"faq/Install/","text":"<p>IT IS QUITE PROBABLE THAT SOME INFORMATION HERE IS OUTDATED</p> <p>PLEASE OPEN ISSUES</p>","title":"Install"},{"location":"faq/Install/#ansible-tags","text":"","title":"Ansible Tags"},{"location":"faq/Install/#multiple-tags","text":"<p>Run multiple tags together by separating them with commas, no spaces. Quotes are optional. Order is not important.</p> <p>Use this to install containers or roles that are not included in \"default\" install types.  </p> <p>Example:</p> <pre><code>sb install core,emby,sonarr,radarr,nzbget,nzbhydra2\n</code></pre>","title":"Multiple Tags"},{"location":"faq/Install/#skip-tags","text":"<p>Skip tags you dont want to run by listing them with <code>--skip-tags</code> and separated by commas. Quotes are optional. Order is not important.</p> <p>Use this to skip containers or roles that are included in the \"default\" install types. </p> <p>Example:</p> <pre><code>sb install saltbox --skip-tags rutorrent,jackett\n</code></pre> <p>Note: But be careful on what you skip, as some things are needed by Saltbox to function properly.</p>","title":"Skip Tags"},{"location":"faq/Install/#merging-tags-and-skip-tags","text":"<p>You can even merge <code>--tags</code> and <code>--skip-tags</code> into one command. Order is not important (e.g. skip tags can come before tags). </p> <p>Example:</p> <pre><code>sb install core,emby,sonarr,radarr,nzbget,nzbhydra2 --skip-tags rutorrent,jackett\n</code></pre> <p>Can also be used along with one of the \"default\" tags (e.g. <code>cloudbox</code>).</p> <p>Example:</p> <pre><code>sb install cloudbox,sabnzbd --skip-tags rutorrent,jackett\n</code></pre>","title":"Merging Tags and Skip-Tags"},{"location":"faq/Install/#persistent-skip-tags","text":"<p>You can \"permanently\" skip tags by adding the following lines to <code>/srv/git/saltbox/ansible.cfg</code>.</p> <p>Format: </p> <p><pre><code>[tags]\nskip = TAG1,TAG2,etc\n</code></pre> And then continue to install with the normal <code>--tags</code> command. </p> <p>Example:</p> <pre><code>cat /srv/git/saltbox/ansible.cfg\n</code></pre> <pre><code>[tags]\nskip = rutorrent,jackett\n</code></pre> <pre><code>sb install saltbox,sabnzbd\n</code></pre> <p>In this example, the Saltbox installer will install with all the default items and sabnzbd, but will not install rutorrent and jackett.</p>","title":"Persistent Skip Tags"},{"location":"faq/Install/#error-while-fetching-server-api-version","text":"<p>Full error message:</p> <pre><code>Error Connecting:  Error while fetching server API version: Timeout value connect was Timeout(connect=60, read=60, total=None), but it must be an int or float.\n</code></pre> <p>Run <code>sudo pip install requests==2.10.0</code> and retry.</p>","title":"Error while fetching server API version"},{"location":"faq/Install/#403-client-error-forbidden-endpoint-with-name-container-name-already-exists-in-network-network-name","text":"<p>Example:</p> <pre><code>fatal: [localhost]: FAILED! =&gt; {\"changed\": false, \"failed\": true, \"msg\": \"Error starting container 6fb60d4cdabe938986042e06ef482012a1d85a66a099d861f08062d8262c2ef7: 403 Client Error: Forbidden (\\\"{\\\"message\\\":\\\"endpoint with name jackett already exists in network bridge\\\"}\\\")\"}\n    to retry, use: --limit @/home/seed/saltbox/saltbox.retry\nPLAY RECAP *********************************************************************\nlocalhost                  : ok=2    changed=1    unreachable=0    failed=1\n</code></pre> <p>You have a remnant of the container in the Docker's network.</p> <p>You can verify with the command below (replace <code>&lt;network name&gt;</code> and <code>&lt;container name&gt;</code> is replaced with the network name and container name mentioned in the error, respectively): <pre><code>docker inspect network &lt;network name&gt; | grep &lt;container name&gt;\n</code></pre></p> <p>To remove the remnant, run this command and try again:</p> <pre><code>docker network disconnect -f &lt;network name&gt; &lt;container name&gt;\n</code></pre>","title":"403 Client Error: Forbidden: endpoint with name \\&lt;container name&gt; already exists in network \\&lt;network name&gt;"},{"location":"faq/Install/#500-server-error-internal-server-error-driver-failed-programming-external-connectivity-on-endpoint-container-name-bind-for-0000port-number-failed-port-is-already-allocated","text":"<pre><code>sudo service docker stop\nsudo service docker start\n</code></pre>","title":"500 Server Error: Internal Server Error: driver failed programming external connectivity on endpoint \\&lt;container name&gt; bind for 0.0.0.0:\\&lt;port number&gt; failed: port is already allocated"},{"location":"faq/Install/#updating-saltbox","text":"<p>Follow the appropriate steps from this page</p>","title":"Updating Saltbox"},{"location":"faq/Misc/","text":"<p>IT IS QUITE PROBABLE THAT SOME INFORMATION HERE IS OUTDATED</p> <p>PLEASE OPEN ISSUES</p>","title":"Misc"},{"location":"faq/Misc/#backuprestore-nextclouddb","text":"<p>DB data is stored in /opt/mariadb and backed up along with Saltbox Backup.</p> <p>However, you can separately make a backup of the DB into a single <code>nextcloud_backup.sql</code> file, by running the following command.</p> <pre><code>docker exec mariadb /usr/bin/mysqldump -u root --password=password321 nextcloud  &gt; nextcloud_backup.sql\n</code></pre> <p>And restoring it back:</p> <pre><code>cat nextcloud_backup.sql | docker exec -i mariadb /usr/bin/mysql -u root --password=password321 nextcloud\n</code></pre>","title":"Backup/Restore NextcloudDB"},{"location":"faq/Misc/#json-format-errors","text":"<p>Python or script errors mentioning an issue with the config file is usually due to an invalid JSON format in the file.</p> <p>Examples:</p> <pre><code>Traceback (most recent call last):\n  File \"scan.py\", line 52, in &lt;module&gt;\n    conf.load()\n  File \"/opt/plex_autoscan/config.py\", line 157, in load\n    cfg = self.upgrade(json.load(fp))\n  File \"/usr/lib/python2.7/json/__init__.py\", line 291, in load\n    **kw)\n  File \"/usr/lib/python2.7/json/__init__.py\", line 339, in loads\n    return _default_decoder.decode(s)\n  File \"/usr/lib/python2.7/json/decoder.py\", line 364, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File \"/usr/lib/python2.7/json/decoder.py\", line 380, in raw_decode\n    obj, end = self.scan_once(s, idx)\nValueError: Expecting , delimiter: line 20 column 2 (char 672)\n</code></pre> <pre><code>Traceback (most recent call last):\n  File \"/opt/plex_autoscan/scan.py\", line 52, in &lt;module&gt;\n    conf.load()\n  File \"/opt/plex_autoscan/config.py\", line 157, in load\n    cfg = self.upgrade(json.load(fp))\n  File \"/usr/lib/python2.7/json/init.py\", line 291, in load\n    **kw)\n  File \"/usr/lib/python2.7/json/init.py\", line 339, in loads\n    return _default_decoder.decode(s)\n  File \"/usr/lib/python2.7/json/decoder.py\", line 364, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File \"/usr/lib/python2.7/json/decoder.py\", line 382, in raw_decode\n    raise ValueError(\"No JSON object could be decoded\")\nValueError: No JSON object could be decoded\n</code></pre> <pre><code>Traceback (most recent call last):\n  File \"/usr/local/bin/cloudplow\", line 60, in &lt;module&gt;\n    conf.load()\n  File \"/opt/cloudplow/utils/config.py\", line 227, in load\n    cfg, upgraded = self.upgrade_settings(json.load(fp))\n  File \"/usr/lib/python3.5/json/__init__.py\", line 268, in load\n    parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n  File \"/usr/lib/python3.5/json/__init__.py\", line 319, in loads\n    return _default_decoder.decode(s)\n  File \"/usr/lib/python3.5/json/decoder.py\", line 339, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File \"/usr/lib/python3.5/json/decoder.py\", line 355, in raw_decode\n    obj, end = self.scan_once(s, idx)\njson.decoder.JSONDecodeError: Expecting ',' delimiter: line 46 column 13 (char 1354)\n</code></pre> <p>Fixes:</p> <ol> <li>Paste the JSON file at jsonformatter.curiousconcept.com and click <code>process</code>. This will tell you what the issue is and fix it for you.</li> </ol> <p>or</p> <ol> <li>Run:</li> </ol> <pre><code>jq '.' config.json\n</code></pre> <p>If there are no issues, it will simply print out the full JSON file.</p> <p>If there is an issue, a msg will display the location of the issue:</p> <pre><code>parse error: Expected separator between values at line 7, column 10\n</code></pre>","title":"JSON Format Errors"},{"location":"faq/Plex-Autoscan/","text":"<p>IT IS QUITE PROBABLE THAT SOME INFORMATION HERE IS OUTDATED</p> <p>PLEASE OPEN ISSUES</p>","title":"Plex Autoscan"},{"location":"faq/Plex-Autoscan/#newly-downloaded-media-from-sonarr-and-radarr-are-not-being-added-to-plex","text":"<ul> <li> <p>Test another download and run the following command:   <pre><code> tail -f /opt/plex_autoscan/plex_autoscan.log\n</code></pre></p> </li> <li> <p>If you see this...</p> </li> </ul> <pre><code>terminate called after throwing an instance of 'boost::filesystem::filesystem_error'\nboost::filesystem::create_directories: Permission denied: \"/config/Library/Logs\"\n</code></pre> <p>There is an issue with the permissions on that folder that you'll need to fix manually (Saltbox can't fix this as Plex creates this folder after the first scan)</p> <p>To fix this, Run the following command. Replace <code>user</code> and <code>group</code> to match yours' (see here).</p> <pre><code>docker stop plex\nsudo chown -R user:group /opt/plex\ndocker start plex\n</code></pre> <p>Example of a successful scan:</p> <pre><code>2017-10-10 17:48:26,429 -    DEBUG -      PLEX [ 6185]: Waiting for turn in the scan request backlog...\n2017-10-10 17:48:26,429 -     INFO -      PLEX [ 6185]: Scan request is now being processed\n2017-10-10 17:48:26,474 -     INFO -      PLEX [ 6185]: No 'Plex Media Scanner' processes were found.\n2017-10-10 17:48:26,474 -     INFO -      PLEX [ 6185]: Starting Plex Scanner\n2017-10-10 17:48:26,475 -    DEBUG -      PLEX [ 6185]: docker exec -u plex -i plex bash -c 'export LD_LIBRARY_PATH=/usr/lib/plexmediaserver;/usr/lib/plexmediaserver/Plex\\ Media\\ Scanner --scan --refresh --section 1 --directory '\"'\"'/data/Movies/Ravenous (1999)'\"'\"''\n2017-10-10 17:48:33,712 -     INFO -     UTILS [ 6185]: GUI: Scanning Ravenous (1999)\n2017-10-10 17:48:33,959 -     INFO -     UTILS [ 6185]: GUI: Matching 'Ravenous'\n2017-10-10 17:48:38,556 -     INFO -     UTILS [ 6185]: GUI: Score for 'Ravenous' (1999) is 117\n2017-10-10 17:48:38,607 -     INFO -     UTILS [ 6185]: GUI: Requesting metadata for 'Ravenous'\n2017-10-10 17:48:38,705 -     INFO -     UTILS [ 6185]: GUI: Background media analysis on Ravenous\n2017-10-10 17:48:39,201 -     INFO -      PLEX [ 6185]: Finished scan!\n</code></pre>","title":"Newly downloaded media from Sonarr and Radarr are not being added to Plex?"},{"location":"faq/Plex-Autoscan/#plex-autoscan-log-shows-error-during-empty-trash-request","text":"<pre><code>ERROR - PLEX [10490]: Unexpected response status_code for empty trash request: 401\n</code></pre> <p>You need to generate another token and re-add that back into the config. See Plex Autoscan.</p>","title":"Plex Autoscan log shows error during empty trash request"},{"location":"faq/Plex-Autoscan/#plex-autoscan-error-with-metadata-item-id","text":"<p>Example Log: <pre><code> 2017-11-21 04:26:32,619 -    ERROR -      PLEX [ 7089]: Exception finding metadata_item_id for '/data/TV/Gotham/Season 01/Gotham - S01E01 - Pilot.mkv':\n 2017-11-21 04:26:32,619 -     INFO -      PLEX [ 7089]: Aborting analyze of '/data/TV/Gotham/Season 01/Gotham - S01E01 - Pilot.mkv' because could not find a metadata_item_id for it\n</code></pre></p> <p>Possible Issues:</p> <ul> <li> <p>One of the mounts has changed (e.g. Rclone_VFS or MergerFS was restarted).</p> </li> <li> <p>Permission issues (see [here]).</p> </li> </ul> <p>Solution 1:</p> <ol> <li>Make sure the remote mount is working OK (pick the relevant one below).</li> </ol> <p>The current default used for mounting cloud storage is Rclone VFS:</p> <pre><code>sudo systemctl status rclone_vfs\n</code></pre> <ol> <li>Make sure the union mount is working OK. </li> </ol> <p>The current default used for creating the union mount is MergerFS:</p> <pre><code>sudo systemctl status mergerfs\n</code></pre> <ol> <li>Restart Plex:    <pre><code>docker stop plex &amp;&amp; docker start plex\n</code></pre></li> </ol> <p>Solution 2:</p> <p>If all else fails, disable analyze in config.</p> <ol> <li>Open <code>/opt/plex_autoscan/config/config.json</code></li> </ol> <pre><code>nano /opt/plex_autoscan/config/config.json\n</code></pre> <ol> <li>Make the following edit:</li> </ol> <pre><code>\"PLEX_ANALYZE_TYPE\": \"off\",\n</code></pre> <ol> <li>Restart Plex Autoscan</li> </ol> <pre><code>sudo systemctl restart plex_autoscan\n</code></pre>","title":"Plex Autoscan error with metadata item id"},{"location":"faq/Plex-Autoscan/#purpose-of-a-control-file-in-plex-autoscan","text":"<p>Every time Sonarr or Radarr downloads a new file, or upgrades a previous one, a request is sent to Plex via Plex Autoscan to scan the movie folder or TV season path and look for changes. Since Sonarr and Radarr delete previous files on upgrades, the scan will cause the new media to show up in your Plex Library, however, the deleted files would be missing, and instead, marked as \"unavailable\" (i.e. trash icon). When the control file is present and the option in the Plex Autoscan config is enabled (default), Plex Autoscan will empty the trash for you, thereby, removing the deleted media from the library.</p> <p>If the remote mount for you cloud storage provider (e.g. Google Drive) ever disconnected during a Plex scan of your media, Plex would mark the missing files as unavailable and emptying the trash would cause them to be removed out of the library. To avoid this from happening, Plex Autoscan checks for a control file in the unionfs path (i.e. <code>/mnt/unionfs/mounted.bin)</code> before running any empty trash commands. The control file is just a blank file that resides on the root folder of your Rclone remote (i.e. cloud storage provider) and let's Plex Autoscan know that it is still mounted.</p> <p>Once the remote is remounted, all the files marked unavailable in Plex will be playable again and Plex Autoscan will resume its emptying trash duties post-scan.</p> <p>To learn more about Plex Autoscan, visit https://github.com/l3uddz/plex_autoscan.</p> <p>TLDR: Plex Autoscan will not remove deleted media out of Plex without it.</p>","title":"Purpose of a Control File in Plex Autoscan"},{"location":"faq/Plex-Autoscan/#plex-autoscan-localhost-setup","text":"<p>If you are using an all-in-one Saltbox and don't want to have the Plex Autoscan port open, you may set it up so that it runs on the localhost only.</p> <p>To do so, follow these steps:</p> <p>Option 1</p> <p>Plex Autoscan: (only if changed from default)</p> <ol> <li>Open <code>/opt/plex_autoscan/config/config.json</code></li> </ol> <pre><code>nano /opt/plex_autoscan/config/config.json\n</code></pre> <ol> <li>Make the following edit:</li> </ol> <pre><code>\"SERVER_IP\": \"0.0.0.0\",\n</code></pre> <p>Note: This is the default config.</p> <ol> <li>Restart Plex Autoscan</li> </ol> <pre><code>sudo systemctl restart plex_autoscan\n</code></pre> <p>Sonarr/Radarr:</p> <ul> <li>Retrieve the 'Docker Gateway IP Address' by running the following:</li> </ul> <pre><code>docker inspect -f '{{ .NetworkSettings.Networks.saltbox.Gateway }}' sonarr\n</code></pre> <ul> <li>Replace the Plex Autoscan URL with:</li> </ul> <pre><code>http://docker_gateway_ip_address:3468/yourserverpass\n</code></pre> <ul> <li>You Plex Autoscan URL will now look like this:</li> </ul> <pre><code>http://172.18.0.1:3468/yourserverpass\n</code></pre> <p>Option 2</p> <p>Alternatively, you can set it up this way:</p> <p>Note: This method benefits from completely closing off Plex Autoscan to the outside.</p> <p>Plex Autoscan:</p> <ol> <li>Retrieve the 'Docker Gateway IP Address' by running the following:</li> </ol> <pre><code>docker inspect -f '{{ .NetworkSettings.Networks.saltbox.Gateway }}' sonarr\n</code></pre> <ol> <li>Open <code>/opt/plex_autoscan/config/config.json</code></li> </ol> <pre><code>nano /opt/plex_autoscan/config/config.json\n</code></pre> <ol> <li>Make the following edit:</li> </ol> <pre><code>\"SERVER_IP\": \"docker_network_gateway_ip_address\",\n</code></pre> <ol> <li>This will now look like this:</li> </ol> <pre><code>\"SERVER_IP\": \"172.18.0.1\",\n</code></pre> <ol> <li>Restart Plex Autoscan</li> </ol> <pre><code>sudo systemctl restart plex_autoscan\n</code></pre> <p>Sonarr/Radarr:</p> <ul> <li>Replace the Plex Autoscan URL with:</li> </ul> <pre><code>http://docker_gateway_ip_address:3468/yourserverpass\n</code></pre> <ul> <li>You Plex Autoscan URL will now look like this:</li> </ul> <pre><code>http://172.18.0.1:3468/yourserverpass\n</code></pre>","title":"Plex Autoscan Localhost Setup"},{"location":"faq/Plex-Autoscan/#why-is-server_scan_delay-set-to-180-seconds-by-default","text":"<p>When Plex Autoscan gets a scan request from Sonarr, it tells Plex to scan the relevant TV Show season folder. So to avoid multiple Plex scans of the same season when more episodes of that same season come in, Plex Autoscan can wait (ala SERVER_SCAN_DELAY) and merge multiple scan requests into a single one. This is particularly noticeable when consecutive episodes are being downloaded/imported into Sonarr. </p> <p>During this SERVER_SCAN_DELAY, if another request comes in for the same season folder, it will restart the delay timer again, thus allowing for even more time for new items to come in. </p> <p>SERVER_SCAN_DELAY of 180 seconds was calculated with an average episode download time of a few minutes each. </p> <p>There is no harm in multiple Plex scans of the same season folder, except for more busyness of Plex, and perhaps more stress to it, so this delay will try to alleviate that. </p> <p>Alternative recommended settings are: 120 and 90 seconds. </p>","title":"Why is SERVER_SCAN_DELAY set to 180 seconds by default?"},{"location":"faq/Plex/","text":"<p>IT IS QUITE PROBABLE THAT SOME INFORMATION HERE IS OUTDATED</p> <p>PLEASE OPEN ISSUES</p>","title":"Plex"},{"location":"faq/Plex/#if-you-are-unable-to-find-your-plex-server","text":"<p>You may resolve this by either</p> <ul> <li> <p>Installing Saltbox again (do this for new Plex DBs/installs):</p> </li> <li> <p>THIS WILL DELETE ANY EXISTING PLEX CONFIGURATION SUCH AS LIBRARIES</p> </li> <li> <p>Remove Plex Container (it may show \"Error response from daemon: No such container\" if not created yet):</p> <pre><code>sudo docker rm -f plex\n</code></pre> </li> <li> <p>Remove the Plex folder:</p> <pre><code>sudo rm -rf /opt/plex\n</code></pre> </li> <li> <p>Reinstall the Plex container:</p> <pre><code>sb install plex\n</code></pre> </li> <li> <p>Installing Saltbox again (do this for existing Plex DBs/installs):</p> </li> <li> <p>THIS WILL LEAVE ANY EXISTING PLEX LIBRARIES AND METADATA INTACT</p> </li> <li> <p>Remove Plex Preferences file. </p> <pre><code>sudo rm \"/opt/plex/Library/Application Support/Plex Media Server/Preferences.xml\"\n</code></pre> </li> <li> <p>Reinstall the Plex container by running the following command:</p> <pre><code>sb install plex\n</code></pre> </li> <li> <p>Using SSH Tunneling to log into Plex and set your credentials:</p> </li> <li> <p>On your host PC (replace <code>&lt;user&gt;</code> with your user name and <code>&lt;yourserveripaddress&gt;</code> with your serveripaddress - no arrows):</p> <pre><code>ssh &lt;user&gt;@&lt;yourserveripaddress&gt; -L 32400:0.0.0.0:32400 -N\n</code></pre> <p>This will just hang there without any message. That is normal.</p> </li> <li> <p>In a browser, go to http://localhost:32400/web.</p> </li> <li> <p>Log in with your Plex account.</p> </li> <li> <p>On the \"How Plex Works\" page, click \u201cGOT IT!\u201d.</p> </li> <li> <p>Close the \"Plex Pass\" pop-up if you see it.</p> </li> <li> <p>Under \"Server Setup\", you will see \"Great, we found a server!\". Give your server a name and tick \u201cAllow me to access my media outside my home\u201d. Click \"NEXT\".</p> </li> <li> <p>On \"Organize Your Media\", hit \"NEXT\" (you will do this later). Then hit \"DONE\".</p> </li> <li> <p>At this point, you may <code>Ctrl + c</code> on the SSH Tunnel to close it.</p> </li> </ul> <p>If Plex shows you an incorrect title with the filename (eg RARBG releases)</p> <p>Reorder the Plex agents for TV/Movies so that local assets are at the bottom.</p>","title":"If you are unable to find your Plex server"},{"location":"faq/Plex/#fix-permission-issues-with-plex-logs","text":"<p>Replace <code>user</code> and <code>group</code> to match yours' (see here).</p> <pre><code>sudo chown -R user:group /opt/plex/Library/Logs\nsudo chmod -R g+s /opt/plex/Library/Logs\n</code></pre> <p>Note: If you have a separate Plex and Feeder setup, this will be done on the server where Plex is installed.</p>","title":"Fix permission issues with Plex logs"},{"location":"faq/Rclone/","text":"","title":"Rclone"},{"location":"faq/Rclone/#rclone-error-failed-to-save-config-file-open-homeuserconfigrclonercloneconf-permission-denied","text":"<p>Replace <code>user</code> and <code>group</code> to match yours' (see here).</p> <pre><code>sudo chown -R user:group ~/.config/rclone/\nsudo chmod -R 0755 ~/.config/rclone/\n</code></pre>","title":"Rclone error: Failed to save config file: open /home/\\&lt;user&gt;/.config/rclone/rclone.conf: permission denied"},{"location":"faq/System/","text":"<p>IT IS QUITE PROBABLE THAT SOME INFORMATION HERE IS OUTDATED</p> <p>PLEASE OPEN ISSUES</p>","title":"System"},{"location":"faq/System/#system","text":"","title":"System"},{"location":"faq/System/#can-i-install-this-on-an-arm-machine","text":"<p>ARM is not supported.</p>","title":"Can I install this on an ARM machine?"},{"location":"faq/System/#if-you-are-using-a-scaleway-server","text":"<ol> <li> <p>Choose an X86 server (vs ARM).</p> </li> <li> <p>Select \"Ubuntu Xenial\" as the distribution.</p> </li> <li> <p>Click the server on the list.</p> </li> <li> <p>Under \"ADVANCED OPTIONS\", click \"SHOW\".</p> </li> <li> <p>Set \"ENABLE LOCAL BOOT\" to <code>off</code>.</p> </li> </ol> <p></p> <ol> <li>Click the \"BOOTSCRIPT\" link and select one above &gt; 4.10.</li> </ol> <p></p> <ol> <li>Start the server.</li> </ol> <p>Reference: https://www.scaleway.com/docs/bootscript-and-how-to-use-it/</p>","title":"If you are using a Scaleway server..."},{"location":"faq/System/#if-you-are-using-an-ovh-server","text":"<p>If you are having issues upgrading the kernel on ovh, where the kernel upgrade is not taking effect..</p> <p><code>uname -r</code> to see if you have <code>grs</code> in kernel version string...</p> <p>if so, see https://pterodactyl-daemon.readme.io/v0.4/docs/updating-ovh-kernel on how to update the kernel.</p>","title":"If you are using an OVH server..."},{"location":"faq/System/#find-your-user-id-uid-and-group-id-gid","text":"<p>Use the following commands to find out your account's user name and group info:</p> <p><pre><code>id\n</code></pre> or</p> <p><pre><code>id `whoami`\n</code></pre> You'll see a line like the following:</p> <pre><code>uid=XXXX(yourusername) gid=XXXX(yourgroup) groups=XXXX(yourgroup)\n</code></pre>","title":"Find your User ID (UID) and Group ID (GID)"},{"location":"faq/System/#how-to-create-a-user-account","text":"<ul> <li>Run the following commands line by line:</li> </ul> <pre><code>sudo useradd -m &lt;username&gt;\nsudo usermod -aG sudo &lt;username&gt;\nsudo passwd &lt;username&gt;\nsudo chsh -s /bin/bash &lt;username&gt;\nsu &lt;username&gt;\n</code></pre>","title":"How to create a user account"},{"location":"faq/System/#change-shell-of-user-account-to-bash","text":"<p>How to check current shell:</p> <pre><code>echo $0\n-sh\n</code></pre> <p>or</p> <pre><code>echo ${SHELL}\n/bin/sh\n</code></pre> <p>Run this command to set bash as your shell (where <code>&lt;user&gt;</code> is replaced with your username):</p> <pre><code>sudo chsh -s /bin/bash &lt;user&gt;\nsudo reboot\n</code></pre>","title":"Change shell of user account to bash"},{"location":"faq/System/#how-to-fix-permission-issues","text":"<p>/opt folder</p> <ol> <li>Stop all docker containers</li> </ol> <pre><code>docker stop $(docker ps -a -q)\n</code></pre> <ol> <li>Change ownership of /opt. Replace <code>user</code> and <code>group</code> to match yours' (see here).</li> </ol> <pre><code>sudo chown -R user:group /opt\n</code></pre> <ol> <li>Change permission inheritance of /opt.</li> </ol> <pre><code>sudo chmod -R ugo+X /opt\n</code></pre> <ol> <li>Start all docker containers</li> </ol> <pre><code>docker start $(docker ps -a -q)\n</code></pre> <p>/mnt folder</p> <ol> <li>Run the <code>mounts</code> tag</li> </ol> <pre><code>sb install mounts\n</code></pre>","title":"How to fix permission issues"},{"location":"faq/ruTorrent/","text":"<p>IT IS QUITE PROBABLE THAT SOME INFORMATION HERE IS OUTDATED</p> <p>PLEASE OPEN ISSUES</p>","title":"ruTorrent"},{"location":"faq/ruTorrent/#change-rutorrent-download-path-after-installation","text":"<ol> <li>Stop ruTorrent Docker container:</li> </ol> <pre><code>docker stop rutorrent\n</code></pre> <ol> <li>Edit the <code>rtorrent.rc</code> file:</li> </ol> <pre><code>/opt/rutorrent/rtorrent/rtorrent.rc\n</code></pre> <ol> <li>Set the following options:</li> </ol> <pre><code>directory = /downloads/rutorrent\n</code></pre> <ol> <li>Start ruTorrent Docker container:</li> </ol> <pre><code>docker restart rutorrent\n</code></pre>","title":"Change ruTorrent download path after installation"},{"location":"faq/ruTorrent/#enable-access-to-public-torrent-trackers","text":"<p>By default access to DHT, UDP, and PEX are disabled since most private trackers (and some server providers) do not allow this. Attempting to add a torrent from a public tracker would result in the torrent being stuck, like this:</p> <p></p> <p>To enable access to public trackers, do the following:</p> <ol> <li>Stop ruTorrent Docker container:</li> </ol> <pre><code>docker stop rutorrent\n</code></pre> <ol> <li>Edit the <code>rtorrent.rc</code> file:</li> </ol> <pre><code>/opt/rutorrent/rtorrent/rtorrent.rc\n</code></pre> <ol> <li>Set the following options:</li> </ol> <pre><code>dht.mode.set = on\n</code></pre> <pre><code>trackers.use_udp.set = yes\n</code></pre> <pre><code>protocol.pex.set = yes\n</code></pre> <ol> <li>Start ruTorrent Docker container:</li> </ol> <pre><code>docker start rutorrent\n</code></pre>","title":"Enable access to public torrent trackers"},{"location":"reference/accounts/","text":"","title":"Accounts and Settings"},{"location":"reference/accounts/#options-in-accountsyml","text":"<ul> <li> <p><code>user</code>: User information.</p> <ul> <li> <p><code>name</code>: User name for the server.</p> <ul> <li>If user account with this name does not already exist, it will be created during install.</li> <li>Also used to create first-time logins for NZBGet, ruTorrent, NZBHydra2, and potentially other apps.</li> <li>Default is <code>seed</code>.</li> <li>This parameter is required.</li> </ul> </li> <li> <p><code>pass</code>: Password for the user account and for misc apps.</p> <ul> <li>Sets password for the server's user account when creating a new account. This will not change the password of an existing account.</li> <li>Also used to create first-time logins for NZBGet, ruTorrent, NZBHydra2, and potentially other apps.</li> <li>This parameter is required.</li> <li> <p>Don't leave it blank. Even if you are planning to use SSH keys to connect to your box.  This user and password are used to set up authentication for some applications in this repo and Community, and a blank password may cause trouble there.</p> </li> <li> <p>Relevant XKCD</p> </li> <li> <p>See the password considerations below.</p> </li> </ul> </li> <li> <p><code>domain</code>: Domain name for the Saltbox server.</p> <ul> <li>If you don't have one, see here.</li> <li>This should be the domain \"below\" the saltbox subdomains.  For example, if you want to access Sonarr at \"sonarr.domain.tld\", enter \"domain.tld\".  If you want \"sonarr.foo.domain.tld\", enter \"foo.domain.tld\".</li> <li>Leave this blank to run without the reverse proxy and access the apps via IP:PORT</li> </ul> </li> <li> <p><code>email</code>: E-mail address.</p> <ul> <li>This is used for the Let's Encrypt SSL certificates.</li> <li>It does not have to be an email address at the domain above.</li> <li>This parameter is required if you're using the reverse proxy.</li> </ul> </li> </ul> </li> <li> <p><code>cloudflare</code>: Cloudflare Account</p> <ul> <li> <p><code>email</code>: E-mail address used for the Cloudflare account.</p> </li> <li> <p><code>api</code>: Global API Key.</p> </li> <li> <p>This parameter is optional.</p> </li> <li> <p>Default is blank.</p> </li> <li> <p>Fill this in to have Saltbox add subdomains on Cloudflare, automatically; leave it blank, to have all Cloudflare related functions disabled.</p> </li> <li> <p>Note: if you are using a subdomain, like WHATEVER.DOMAIN.TLD, as your domain above, leave these blank. The Cloudflare automation does not work in that case and the install will stop with an error.</p> </li> </ul> </li> <li> <p><code>plex</code>: Plex.tv account credentials.</p> <ul> <li> <p>This will be used to:</p> <ul> <li>claim the Plex server under your username, and</li> <li>generate Plex Access Tokens for apps such as Plex Autoscan, etc.</li> </ul> </li> <li> <p><code>user</code> - Plex username or email address on the profile.</p> </li> <li> <p><code>pass</code> - Plex password. See the password considerations below.</p> </li> <li> <p><code>tfa</code> - \"yes\" or \"no\" depending on whether you want to use the two-factor authentication [TFA] compatible Plex connection system.</p> </li> <li> <p>This parameter is required.</p> </li> <li> <p>Note: The \"tfa\" setting controls whether Saltbox uses the newer authentication method or not; this newer method is required for use with TFA, but will work even with it off; it's the \"Open an URL, log into Plex, grant access to this app\" workflow you may be familiar with from other contexts.</p> </li> <li> <p>If you use the <code>tfa</code> workflow, a random client ID and a Plex Access Token will be stored in <code>/opt/saltbox/plex.ini</code> for later use.  Consider securing this file if you are running Saltbox on a shared machine.</p> </li> </ul> </li> <li> <p><code>dockerhub</code>: DockerHub account credentials.</p> <ul> <li> <p>Entering Dockerhub credentials increases the number of images one can pull</p> </li> <li> <p><code>user</code> - Docker Hub username.</p> </li> <li> <p><code>token</code> - Docker Hub access token.</p> </li> </ul> </li> <li> <p><code>apprise</code>: apprise url.</p> <ul> <li>This will be used to send out messages during certain tasks (e.g. backup).</li> <li>This parameter is not nested like the others in this file.</li> <li>This parameter is optional.</li> </ul> </li> </ul>","title":"Options in accounts.yml"},{"location":"reference/accounts/#options-in-settingsyml","text":"<p>Note: Having <code>{{user}}</code> in the path tells Ansible to fill in the username, automatically. You do not need to fill in your actual username.</p>  <ul> <li> <p><code>downloads</code>: Where downloads go.</p> <ul> <li> <p><code>nzbs</code>: Path for Usenet app downloads.</p> </li> <li> <p>Default is <code>/mnt/unionfs/downloads/nzbs</code>.</p> </li> <li> <p>Example: With the default path, NZBGet downloads would go to <code>/mnt/unionfs/downloads/nzbs/nzbget/completed</code> and SABnzbd downloads would go to <code>/mnt/unionfs/downloads/nzbs/sabnzbd/complete</code>.</p> </li> <li> <p><code>torrents</code>: Path for BitTorrent app downloads.</p> <ul> <li>Default is <code>/mnt/unionfs/downloads/torrents</code>.</li> </ul> </li> <li> <p>Example: With the default path, ruTorrent downloads would go to <code>/mnt/unionfs/downloads/torrents/rutorrent/completed</code>.</p> </li> </ul> </li> <li> <p><code>transcodes</code>: Path of temporary transcoding files.</p> <ul> <li> <p>Default is <code>\"/mnt/local/transcodes\"</code>.</p> </li> <li> <p>Note: It is recommended to not use <code>/tmp</code> or <code>/dev/shm</code> as a transcode location because the paths are cleared on reboots, causing Docker to create the folder as root and Plex transcoder to crash. Another reason why not to: https://forums.plex.tv/discussion/comment/1502936/#Comment_1502936.</p> </li> </ul> </li> <li> <p><code>rclone</code>: Rclone options.</p> <ul> <li> <p><code>version</code>: Rclone version that is installed by Saltbox.</p> <ul> <li> <p>Choices are <code>latest</code> (or <code>current</code>), <code>beta</code>, or a specific version number (e.g. <code>1.42</code>).</p> </li> <li> <p>Default is <code>latest</code>.</p> </li> </ul> </li> <li> <p><code>remote</code>: Rclone remote that Saltbox will use to setup Rclone VFS mount and Cloudplow.</p> <ul> <li> <p>Default is <code>google</code>.</p> </li> <li> <p>Can be left blank to run without cloud storage].</p> </li> </ul> </li> </ul> </li> <li> <p><code>shell</code>: Type of shell to use.</p> <ul> <li> <p>Choices are <code>bash</code> or <code>zsh</code>.</p> </li> <li> <p>Default is <code>bash</code>.</p> </li> </ul> </li> <li> <p><code>authelia</code>: Authelia options.</p> <ul> <li> <p><code>subdomain</code>: subdomain for the Authelia login page</p> <ul> <li>Default is <code>login</code>.</li> </ul> </li> </ul> </li> </ul>","title":"Options in settings.yml"},{"location":"reference/accounts/#options-in-adv_settingsyml","text":"<ul> <li> <p><code>system</code>: Various system-level settings.</p> <ul> <li> <p><code>timezone</code>: Timezone to use on the server.</p> </li> <li> <p>Default is <code>auto</code>, which will pick the timezone based on geolocation of the server.</p> </li> <li> <p>Enter a \"TZ database name\" as shown in this table.  For example, \"America/Costa_Rica\".</p> </li> <li> <p><code>timedatectl list-timezones</code> at your server's command prompt will also list the options.</p> </li> </ul> </li> <li> <p><code>dns</code>: DNS-related settings.</p> <ul> <li> <p><code>enabled</code>: Controls whether subdomains are created at Cloudflare</p> </li> <li> <p>Default is <code>yes</code>.</p> </li> <li> <p><code>proxied</code>: Controls whether Cloudflare records should be \"proxied\" or \"DNS only\".</p> </li> <li> <p>Default is <code>no</code>.</p> </li> <li> <p><code>ipv6</code>: Enable/disable ipv6 configuration.</p> </li> <li> <p>Default is <code>no</code>.</p> </li> <li> <p><code>zerossl</code>: Controls whether zerossl is used.</p> </li> <li> <p>Default is <code>no</code>.</p> </li> </ul> </li> <li> <p><code>traefik</code>: traefik-related settings.</p> <ul> <li> <p><code>tls</code>: Use TLS.</p> </li> <li> <p>Default is <code>no</code>.</p> </li> <li> <p><code>metrics</code>: enable metrics subdomain.</p> </li> <li> <p>Default is <code>no</code>.</p> </li> <li> <p><code>tracing</code>: Enable tracing.</p> </li> <li> <p>Default is <code>no</code>.</p> </li> <li> <p><code>hsts</code>: enable hsts.</p> </li> <li> <p>Default is <code>no</code>.</p> </li> </ul> </li> <li> <p><code>mounts</code>: cloud storage mount settings.</p> <ul> <li> <p><code>remote</code>: What type of remote to use.</p> </li> <li> <p>Default is <code>rclone_vfs</code>.</p> </li> <li> <p><code>feeder</code>: Should a feeder mount be created?</p> </li> <li> <p>Default is <code>no</code>.</p> </li> </ul> </li> <li> <p><code>gpu</code>: GPU settings.</p> <ul> <li> <p><code>intel</code>: Should system be set up for Intel GPU?</p> </li> <li> <p>Default is <code>yes</code>.</p> </li> <li> <p><code>nvidia</code>: Should system be set up for NVidia GPU?</p> </li> <li> <p>Default is <code>no</code>.</p> </li> </ul> </li> </ul>","title":"Options in adv_settings.yml"},{"location":"reference/accounts/#password-considerations","text":"<p>These are a YAML files, and values you enter here are subject to YAML file format rules.  If you use special characters in your password, wrap the password in quotes [or escape the characters correctly, if you are familiar with that concept].  It would be easiest to avoid using quote characters themselves within your password.</p> <p>For example:</p> <ul> <li><code>pass: MyP4s5w0rd1s4w350m3</code></li> <li><code>pass: \"!@#$%^&amp;*\"</code></li> <li><code>pass: multiple words work fine unquoted</code></li> <li><code>pass: \"or quote them to be safe\"</code></li> </ul>","title":"Password considerations"},{"location":"reference/cloud/","text":"","title":"Cloud Storage"},{"location":"reference/cloud/#provider","text":"<p>If you want to forego cloud storage and put your media on something like your own NAS, there are some notes here.</p> <p>Saltbox can be set up to use any cloud storage provider that Rclone supports. However, Google Drive via G-Suite Business is the popular choice among users.  Some of the components are designed expressly for Google Drive, like the Google Drive monitoring in plex-autoscan and the service-account rotation in cloudplow.</p> <p>It is advised that you do NOT use a educational GSuite account or any GSuite account or Shared Drive you may buy on the secondary market [eBay and the like], unless you are aware of and planning for the likelihood that it disappears one day.</p> <p>Note that rclone offering support for a storage backend does not mean that backend is suitable for the Saltbox use case.  The only backend that sees any significant testing and use is Google Drive.</p>","title":"Provider"},{"location":"reference/cloud/#basics","text":"<p>Out of the box, Saltbox stores the media unencrypted in cloud storage utilizing an Rclone VFS mount to access it. If you prefer your data is stored encrypted, you will need to do some tweaking to the Rclone config. There are no plans to document these tweaks here.</p> <p>Media will be stored in <code>Movies</code> and <code>TV</code> folders, all within a <code>Media</code> folder in root (i.e. <code>/Media</code>). [1] </p> <p>Saltbox is opinionated about this <code>/Media/&lt;type&gt;</code> file structure; changing it is not trivial.</p>","title":"Basics"},{"location":"reference/cloud/#setup","text":"<pre><code>Media\n\u251c\u2500\u2500 Movies\n\u251c\u2500\u2500 Music\n\u2514\u2500\u2500 TV\n</code></pre> <ul> <li>Example from Google Drive:</li> </ul> <p></p> <p>If you have media in other folders, you can simply move them into these folders via the Cloud Storage Provider's web site.</p> <p>Note 1: For Google Drive, you can use the Shift-Z trick to \"symlink\" folders here. </p> <p>Note 2: All the paths/folders mentioned here, and elsewhere, are CASE SENSITIVE (see Saltbox Paths).</p>","title":"Setup"},{"location":"reference/cloud/#google-my-drive-vs-shared-drives","text":"<p>Google provides two \"types\" of storage in  a GSuite account: \"My Drive\" and \"Shared Drives\".</p> <p>Shared Drives provide advantages for our purposes over My Drive, while My Drive offers no advantages over Shared Drives.</p> <p>The primary advantage of Shared Drives is that access to them can be controlled via Service accounts, which allows credential rotation to increase upload limits and reduce likelihood of usage-based server-side bans.</p> <p>Some newer related utilities [like the Golang \"Autoscan\" replacement for plex-autoscan] have features that work exclusively with Shared Drives.</p> <p>The primary disadvantage ot Shared Drives is that they have a fixed limit of 400,000 files.  For this reason one common strategy is to create separate Shared Drives for each media type.</p> <p>For those reasons, this documentation will discuss ONLY Shared Drives.</p> <p>As a note, if you are unable to create Shared Drives in the Google Drive Web UI, that's a sign that you have the wrong type of Google Drive account.</p> <p></p>","title":"Google \"My Drive\" vs. \"Shared Drives\""},{"location":"reference/cloud/#running-saltbox-without-cloud-storage","text":"<p>While the typical use case for Saltbox includes cloud storage, nothing prevents using it without cloud storage.</p> <p>If, in <code>settings.yml</code>, you leave the rclone remote name blank, neither <code>cloudplow</code> nor the rclone_vfs mount will be configured.  Your media will be imported to <code>/mnt/local</code> and stay there.  You can mount whatever storage you wish to use at <code>/mnt/local</code>.</p> <p>Alternatively, you can configure an rclone remote pointing at your primary storage [named \"google\"], then install normally.  Everything would then work as it typically does, except that cloudplow would move media from the local system to your NAS or whatever.  Perhaps that would allow downloads and imports to go faster.</p>  <p> 1 If you would like to customize your Plex libraries beyond what is listed above, see Customizing Plex Libraries.</p>","title":"Running Saltbox without cloud storage"},{"location":"reference/cloudplow-config/","text":"<p>The default Cloudplow setup uploads to the <code>google</code> remote using a single account, which limits you to 750GB/day of upload.</p> <p>To utilize rotating service accounts to upload more than this, you'll need to configure cloudplow to upload to the individual shared drives.</p> <p>If you used the scripted rclone method, there is a script in the sb_gd repo that will make the required modifications to the cloudplow config.</p> <p>NOTE: This script is assuming that your service account file are in <code>/opt/sa/all</code>, which is where the scripted rclone method puts them.</p> <p>The script is also assuming a totally stock Cloudplow <code>config.json</code> as it comes from the original saltbox install.  If you have added <code>remote</code>s or <code>uploader</code>s it will fail with an error.</p> <p>This script is only useful if you have used the scripted rclone method.</p> <p>You will have to have completed <code>sb install saltbox</code> before using this script.</p> <ol> <li> <p>Run the script</p> <pre><code>cd /opt/sb_gd\nsource sb_gd/bin/activate\npython sb_cp.py\n</code></pre> <p>If that doesn't work, update to the latest version of the files from the repo with <code>git pull</code> and try again.</p> </li> <li> <p>Restart the cloudplow service:</p> <pre><code>sudo systemctl restart cloudplow\n</code></pre> </li> </ol>","title":"Shared-Drive Cloudplow Setup"},{"location":"reference/cloudplow/","text":"","title":"Example Cloudplow configs"},{"location":"reference/cloudplow/#cloudplow-with-default-config","text":"<p>This is the default config; it contains a single remote/uploader pair.  This set uploads everything from <code>/mnt/local/Media</code> to <code>google:/Media</code> once there is 200GB in <code>/mnt/local/Media</code>.</p>  Example config.json (click to expand) <pre><code>{\n    \"core\": {\n        \"dry_run\": false,\n    \"rclone_config_path\": \"/home/seed/.config/rclone/rclone.conf\"\n    },\n    \"hidden\": {\n        \"/mnt/local/.unionfs-fuse\": {\n            \"hidden_remotes\": [\n                \"google\"\n            ]\n        }\n    },\n    \"notifications\": {\n    },\n    \"remotes\": {\n        \"google\": {\n            \"hidden_remote\": \"google:\",\n            \"rclone_excludes\": [\n                \"**partial~\",\n                \"**_HIDDEN~\",\n                \".unionfs/**\",\n                \".unionfs-fuse/**\"\n            ],\n            \"rclone_extras\": {\n                \"--checkers\": 16,\n                \"--drive-chunk-size\": \"64M\",\n                \"--stats\": \"60s\",\n                \"--transfers\": 8,\n                \"--verbose\": 1\n            },\n            \"rclone_sleeps\": {\n                \"Failed to copy: googleapi: Error 403: User rate limit exceeded\": {\n                    \"count\": 5,\n                    \"sleep\": 25,\n                    \"timeout\": 3600\n                }\n            },\n            \"remove_empty_dir_depth\": 2,\n            \"sync_remote\": \"google:/Media\",\n            \"upload_folder\": \"/mnt/local/Media\",\n            \"upload_remote\": \"google:/Media\"\n        }\n    },\n    \"syncer\": {\n    },\n    \"uploader\": {\n        \"google\": {\n            \"check_interval\": 30,\n            \"exclude_open_files\": true,\n            \"max_size_gb\": 200,\n            \"opened_excludes\": [\n                \"/downloads/\"\n            ],\n            \"size_excludes\": [\n                \"downloads/*\"\n            ]\n        }\n    }\n}\n</code></pre>","title":"Cloudplow with Default Config"},{"location":"reference/cloudplow/#cloudplow-with-multiple-remotes","text":"<p>A couple points:</p> <ul> <li>Uploader tasks run sequentially (vs in parallel)</li> <li>Each <code>uploader</code> task needs a separate <code>remote</code>. You can't have two \u201cuploaders\u201d referencing one \u201cremote\u201d. </li> </ul>  Example config.json (click to expand) <pre><code>{\n    \"core\": {\n        \"dry_run\": false,\n        \"rclone_binary_path\": \"/usr/bin/rclone\",\n        \"rclone_config_path\": \"/home/seed/.config/rclone/rclone.conf\"\n    },\n    \"hidden\": {\n        \"/mnt/local/.unionfs-fuse\": {\n            \"hidden_remotes\": [\n                \"google\",\n                \"dropbox\"\n            ]\n        }\n    },\n    \"notifications\": {\n        \"Pushover\": {\n            \"app_token\": \"xxxxx\",\n            \"priority\": 0,\n            \"service\": \"pushover\",\n            \"user_token\": \"xxxxx\"\n        }\n    },\n    \"nzbget\": {\n        \"enabled\": false,\n        \"url\": \"https://user:password@nzbget.domain.com\"\n    },\n    \"plex\": {\n        \"enabled\": false,\n        \"max_streams_before_throttle\": 1,\n        \"poll_interval\": 30,\n        \"rclone\": {\n            \"throttle_speeds\": {\n                \"1\": \"50M\",\n                \"2\": \"40M\",\n                \"3\": \"30M\",\n                \"4\": \"20M\",\n                \"5\": \"10M\"\n            },\n            \"url\": \"http://localhost:7949\"\n        },\n        \"token\": \"xxxxxx\",\n        \"url\": \"https://plex.domain.com\",\n        \"verbose_notifications\": false\n    },\n    \"remotes\": {\n        \"google\": {\n            \"hidden_remote\": \"google:\",\n            \"rclone_excludes\": [\n                \"**partial~\",\n                \"**_HIDDEN~\",\n                \".unionfs/**\",\n                \".unionfs-fuse/**\"\n            ],\n            \"rclone_extras\": {\n                \"--checkers\": 8,\n                \"--drive-chunk-size\": \"128M\",\n                \"--stats\": \"60s\",\n                \"--transfers\": 8,\n                \"--verbose\": 1\n            },\n            \"rclone_sleeps\": {\n                \"Failed to copy: googleapi: Error 403: User rate limit exceeded\": {\n                    \"count\": 5,\n                    \"sleep\": 6,\n                    \"timeout\": 7200\n                }\n            },\n            \"rclone_command\": \"copy\",\n            \"remove_empty_dir_depth\": 1,\n            \"upload_folder\": \"/mnt/local/Media/\",\n            \"upload_remote\": \"google:/Media/\"\n        },\n        \"dropbox\": {\n            \"hidden_remote\": \"dropbox:\",\n            \"rclone_excludes\": [\n                \"**partial~\",\n                \"**_HIDDEN~\",\n                \".unionfs/**\",\n                \".unionfs-fuse/**\"\n            ],\n            \"rclone_extras\": {\n                \"--checkers\": 8,\n                \"--drive-chunk-size\": \"128M\",\n                \"--stats\": \"60s\",\n                \"--transfers\": 8,\n                \"--verbose\": 1\n            },\n            \"rclone_sleeps\": {\n            },\n            \"rclone_command\": \"move\",\n            \"remove_empty_dir_depth\": 1,\n            \"upload_folder\": \"/mnt/local/Media/\",\n            \"upload_remote\": \"dropbox:/Media/\"\n        }\n    },\n    \"syncer\": {},\n    \"uploader\": {\n        \"google\": {\n            \"check_interval\": 30,\n            \"exclude_open_files\": true,\n            \"max_size_gb\": 100,\n            \"opened_excludes\": [\n                \"/downloads/\"\n            ],\n            \"size_excludes\": [\n                \"downloads/*\"\n            ]\n        },\n        \"dropbox\": {\n            \"check_interval\": 30,\n            \"exclude_open_files\": true,\n            \"max_size_gb\": 50,\n            \"opened_excludes\": [\n                \"/downloads/\"\n            ],\n            \"size_excludes\": []\n        }\n    }\n}\n</code></pre>","title":"Cloudplow with Multiple Remotes"},{"location":"reference/cloudplow/#cloudplow-with-multiple-folders","text":"<p>This config uploads everything from <code>/mnt/local/Media</code> to <code>google:/Media</code> [triggered at 100GB] and  everything in <code>/mnt/local/downloads/torrents/rutorrent/completed/</code> to <code>google:/Downloads/</code> [triggered at 50GB].</p>  Example config.json (click to expand) <pre><code>{\n    \"core\": {\n        \"dry_run\": false,\n        \"rclone_binary_path\": \"/usr/bin/rclone\",\n        \"rclone_config_path\": \"/home/seed/.config/rclone/rclone.conf\"\n    },\n    \"hidden\": {\n        \"/mnt/local/.unionfs-fuse\": {\n            \"hidden_remotes\": [\n                \"google\"\n            ]\n        }\n    },\n    \"notifications\": {\n        \"Pushover\": {\n            \"app_token\": \"xxxxx\",\n            \"priority\": 0,\n            \"service\": \"pushover\",\n            \"user_token\": \"xxxxx\"\n        }\n    },\n    \"nzbget\": {\n        \"enabled\": false,\n        \"url\": \"https://user:password@nzbget.domain.com\"\n    },\n    \"plex\": {\n        \"enabled\": false,\n        \"max_streams_before_throttle\": 1,\n        \"poll_interval\": 30,\n        \"rclone\": {\n            \"throttle_speeds\": {\n                \"1\": \"50M\",\n                \"2\": \"40M\",\n                \"3\": \"30M\",\n                \"4\": \"20M\",\n                \"5\": \"10M\"\n            },\n            \"url\": \"http://localhost:7949\"\n        },\n        \"token\": \"xxxxxx\",\n        \"url\": \"https://plex.domain.com\",\n        \"verbose_notifications\": false\n    },\n    \"remotes\": {\n        \"media_to_google\": {\n            \"hidden_remote\": \"google:\",\n            \"rclone_excludes\": [\n                \"**partial~\",\n                \"**_HIDDEN~\",\n                \".unionfs/**\",\n                \".unionfs-fuse/**\"\n            ],\n            \"rclone_extras\": {\n                \"--checkers\": 8,\n                \"--drive-chunk-size\": \"128M\",\n                \"--stats\": \"60s\",\n                \"--transfers\": 8,\n                \"--verbose\": 1\n            },\n            \"rclone_sleeps\": {\n                \"Failed to copy: googleapi: Error 403: User rate limit exceeded\": {\n                    \"count\": 5,\n                    \"sleep\": 6,\n                    \"timeout\": 7200\n                }\n            },\n            \"remove_empty_dir_depth\": 1,\n            \"upload_folder\": \"/mnt/local/Media/\",\n            \"upload_remote\": \"google:/Media/\"\n        },\n        \"downloads_to_google\": {\n            \"hidden_remote\": \"\",\n            \"rclone_excludes\": [\n                \"**partial~\",\n                \"**_HIDDEN~\",\n                \".unionfs/**\",\n                \".unionfs-fuse/**\"\n            ],\n            \"rclone_extras\": {\n                \"--checkers\": 8,\n                \"--drive-chunk-size\": \"128M\",\n                \"--stats\": \"60s\",\n                \"--transfers\": 8,\n                \"--verbose\": 1\n            },\n            \"rclone_sleeps\": {\n                \"Failed to copy: googleapi: Error 403: User rate limit exceeded\": {\n                    \"count\": 5,\n                    \"sleep\": 25,\n                    \"timeout\": 7200\n                }\n            },\n            \"remove_empty_dir_depth\": 1,\n            \"upload_folder\": \"/mnt/local/downloads/torrents/rutorrent/completed/\",\n            \"upload_remote\": \"google:/Downloads/\"\n        }\n    },\n    \"syncer\": {},\n    \"uploader\": {\n        \"media_to_google\": {\n            \"check_interval\": 30,\n            \"exclude_open_files\": true,\n            \"max_size_gb\": 100,\n            \"opened_excludes\": [\n                \"/downloads/\"\n            ],\n            \"size_excludes\": [\n                \"downloads/*\"\n            ]\n        },\n        \"downloads_to_google\": {\n            \"check_interval\": 30,\n            \"exclude_open_files\": true,\n            \"max_size_gb\": 50,\n            \"opened_excludes\": [\n                \"/downloads/\"\n            ],\n            \"size_excludes\": []\n        }\n    }\n}\n</code></pre>","title":"Cloudplow with Multiple Folders"},{"location":"reference/cloudplow/#cloudplow-with-notifications-enabled","text":"<p>This is the default config with Pushover notifications configured.</p>  Example config.json (click to expand) <pre><code>{\n    \"core\": {\n        \"dry_run\": false,\n    \"rclone_config_path\": \"/home/seed/.config/rclone/rclone.conf\"\n    },\n    \"hidden\": {\n        \"/mnt/local/.unionfs-fuse\": {\n            \"hidden_remotes\": [\n                \"google\"\n            ]\n        }\n    },\n    \"notifications\": {\n        \"Pushover\": {\n            \"app_token\": \"XXXXXXXXXXX\",\n            \"service\": \"pushover\",\n            \"user_token\": \"XXXXXXXXXXXX\",\n            \"priority\": 0\n        }\n    },\n    \"remotes\": {\n        \"google\": {\n            \"hidden_remote\": \"google:\",\n            \"rclone_excludes\": [\n                \"**partial~\",\n                \"**_HIDDEN~\",\n                \".unionfs/**\",\n                \".unionfs-fuse/**\"\n            ],\n            \"rclone_extras\": {\n                \"--checkers\": 16,\n                \"--drive-chunk-size\": \"64M\",\n                \"--stats\": \"60s\",\n                \"--transfers\": 8,\n                \"--verbose\": 1\n            },\n            \"rclone_sleeps\": {\n                \"Failed to copy: googleapi: Error 403: User rate limit exceeded\": {\n                    \"count\": 5,\n                    \"sleep\": 25,\n                    \"timeout\": 3600\n                }\n            },\n            \"remove_empty_dir_depth\": 2,\n            \"sync_remote\": \"google:/Media\",\n            \"upload_folder\": \"/mnt/local/Media\",\n            \"upload_remote\": \"google:/Media\"\n        }\n    },\n    \"syncer\": {\n    },\n    \"uploader\": {\n        \"google\": {\n            \"check_interval\": 30,\n            \"exclude_open_files\": true,\n            \"max_size_gb\": 200,\n            \"opened_excludes\": [\n                \"/downloads/\"\n            ],\n            \"size_excludes\": [\n                \"downloads/*\"\n            ]\n        }\n    }\n}\n</code></pre>","title":"Cloudplow with Notifications Enabled"},{"location":"reference/dependencies/","text":"<p>If you want to examine the dependencies script before running it:</p> <pre><code>curl -sL https://install.saltbox.dev | more\n</code></pre> <p>This script will:</p> <ol> <li>install <code>git</code></li> <li>delete an existing repo</li> <li>clone the saltbox repo to the system [default location <code>/srv/git/sb</code>]</li> <li>create some script aliases</li> <li>run <code>sb_dep.sh</code></li> <li>run <code>sb_repo.sh</code></li> </ol> <p>At the end of this you will have a local copy of the Saltbox repo, and all the things that Saltbox relies on to install will be available.</p>","title":"Dependencies"},{"location":"reference/domain/","text":"","title":"Domain Name"},{"location":"reference/domain/#domain-name","text":"<p>You will need a domain name as Saltbox apps are only accessed via https://appname.yourdomain.com (see Accessing Saltbox Apps). The steps below will help you set up a domain and DNS settings for use with Saltbox.</p> <p>Ports are [for the most part] bound only to the internal <code>saltbox</code> docker network, which means they are not visible on the host; you won't be able to connect externally to the apps using <code>IP:PORT</code>.</p>","title":"Domain Name"},{"location":"reference/domain/#1-domain-provider","text":"<p>Get a domain name from any domain name registry (e.g. Namecheap, Godaddy, Namesilo, etc).</p> <p>If you already have one, you may skip this step.</p> <p>Note: Free domain name providers, such as Freenom, do not support wildcard DNS settings, and paid domain names can be had for less than a dollar per year (see promo deals on various sites). However, you can add them to Cloudflare and not have to worry about it.</p> <p>If you are planning to use the automatic Cloudflare integration, there are some top-level domains [TLDs] that will not work with it.  Refer to this page.</p> <p>As of 2020/07/26:  \"DNS API cannot be used for domains with .cf, .ga, .gq, .ml, or .tk TLDs.\"</p>","title":"1. Domain Provider"},{"location":"reference/domain/#2-dns-setup","text":"<p>Pick one of the setups below. Your choice will depend on whether you meet certain criteria, as listed under the \"Notes\" section.</p>","title":"2. DNS Setup"},{"location":"reference/domain/#i-wildcard-dns-setup","text":"<p>Notes:</p> <ul> <li> <p>For DNS providers that allow wildcards.</p> </li> <li> <p>For [[Saltbox install type|Basics: Saltbox Install Types]].</p> </li> </ul> <p>Steps:</p> <p>Created an A Record for your subdomains with <code>*</code> for host and set the value to your server IP address.</p>    Type Host Value TTL     A Record * Server IP Address 300    Example  Namecheap &gt; Domain List &gt; Manage &gt; Advanced DNS &gt; Add New Record &gt; A Record &gt; `*` for Host &gt; Server IP for Value.  ![](../images/cloudflare/cloudflare-a-record.png)","title":"i. Wildcard DNS Setup"},{"location":"reference/domain/#ii-non-wildcard-dns-setup","text":"<p>Notes:</p> <ul> <li> <p>For DNS providers that do not allow wildcards (e.g. Freenom).</p> </li> <li> <p>For Mediabox / Feederbox  install types.</p> </li> <li> <p>For Cloudflare users.</p> </li> </ul> <p>Note: if you provide a Cloudflare email and API Key in your settings, the Saltbox installer will set this up for you automatically, provided you enter a top-level domain in the settings [i.e. <code>DOMAIN.TLD</code>, not <code>WHATEVER.DOMAIN.TLD</code>]</p> Saltbox Install TypeMediabox / Feederbox Install Type   <p>You will need to create A Records for all Saltbox subdomains.</p>    Type Host Value TTL     A Record plex Saltbox IP Address 300   A Record tautulli Saltbox IP Address 300   A Record jackett Saltbox IP Address 300   A Record radarr Saltbox IP Address 300   A Record sonarr Saltbox IP Address 300   A Record rutorrent Saltbox IP Address 300   A Record nzbget Saltbox IP Address 300   A Record nzbhydra2 Saltbox IP Address 300   A Record organizr Saltbox IP Address 300   A Record portainer Saltbox IP Address 300      <p>You will need to create A Records for both IP addresses (Media and Feeder boxes) and set them to their respective subdomains.</p> <p>Mediabox</p>    Type Host Value TTL     A Record plex Mediabox IP Address 300   A Record tautulli Mediabox IP Address 300    <p>Feederbox</p>    Type Host Value TTL     A Record jackett Feederbox IP Address 300   A Record radarr Feederbox IP Address 300   A Record sonarr Feederbox IP Address 300   A Record rutorrent Feederbox IP Address 300   A Record nzbget Feederbox IP Address 300   A Record nzbhydra2 Feederbox IP Address 300   A Record organizr Feederbox IP Address 300   A Record portainer Feederbox IP Address 300","title":"ii. Non-Wildcard DNS Setup"},{"location":"reference/domain/#cloudflare","text":"","title":"Cloudflare"},{"location":"reference/domain/#intro","text":"<p>Cloudflare a service that, among other things, protects and accelerates a wide network of websites. By being the \"man in the middle\", it can act like a free DNS provider.</p> <p>Saltbox makes adding subdomains to Cloudflare's DNS settings a breeze via automation. All you need is the API key.</p> <p>Note that there are some top-level domains [TLDs] that will not work with this automation. Refer to this page.</p> <p>As of 2020/07/26: \"DNS API cannot be used for domains with .cf, .ga, .gq, .ml, or .tk TLDs.\"</p> <p>Although Cloudflare is not required for Saltbox, it is still recommended because:</p> <ol> <li> <p>DNS changes propagate almost instantly (a lot faster than a domain provider's DNS service).</p> </li> <li> <p>Hide your server's IP behind Cloudflare's.</p> </li> <li> <p>Makes setting up Mediabox / Feederbox a lot quicker.</p> </li> <li> <p>Allows for automated setup of subdomains for Saltbox add-on apps.</p> </li> <li> <p>It's free.</p> </li> </ol> <p>Note: Saltbox does not enable CDN / Proxy by default, but you may do so yourself after installing Saltbox (see section [[below|Prerequisites: Cloudflare#post-setup]]).</p>","title":"Intro"},{"location":"reference/domain/#sign-up","text":"<ol> <li> <p>Sign up for a free Cloudflare account.</p> </li> <li> <p>On your Domain Registrar's website (e.g. GoDaddy, Namecheap, etc), set the Name Servers to what Cloudflare instructs you to.</p> </li> </ol> Namecheap.comNamesilo.com   <p>\"Dashboard\" -&gt; your domain.tld -&gt; \"Manage\" -&gt; \"Name Servers\" -&gt; \"Custom DNS\" -&gt; add the nameservers in.</p> <p></p>   <p>\"Manage My Domains\" -&gt; your domain.tld -&gt; \"NameServers\" -&gt; \"Change\" -&gt;  add the nameservers in.</p> <p></p>","title":"Sign Up"},{"location":"reference/domain/#setup","text":"<ol> <li> <p>Go to Cloudflare.com.</p> </li> <li> <p>Here you will see that your domain will have an \"Active\" status. Click on your domain to continue.</p> </li> </ol> <p></p> <ol> <li> <p>Click the SSL/TLS tab.</p> </li> <li> <p>Set SSL to <code>Full (strict)</code>.</p> </li> </ol> <p></p>","title":"Setup"},{"location":"reference/domain/#cloudflare-api-key","text":"<ol> <li> <p>Go to Cloudflare.com.</p> </li> <li> <p>Click the Overview tab.</p> </li> <li> <p>Click Get your API token.</p> </li> </ol> <p></p> <ol> <li>Under API Keys and then Global API Key click View.</li> </ol> <p></p> <ol> <li>On the login popup, type in your password and click View.</li> </ol> <p></p> <ol> <li>Save your API key.</li> </ol> <p></p>","title":"Cloudflare API Key"},{"location":"reference/domain/#post-setup","text":"<p>After Saltbox has added in the subdomains, you may go back in and turn on CDN for for them if you like.  NOte, however, that enabling proxying on your plex or emby subdomains [or more generally proxying large amounts of non-HTML content] is against Cloudflare TOS and may end up getting your Cloudflare account banned.</p> <p>Do this AFTER all your certs have been assigned and you have confirmed that all the Saltbox app sites are loading OK.</p> <p>This also applies to any app/subdomains you add in the future - wait till after you get certs before enabling CDN.</p> <p>Note 1: Leave the subdomains <code>saltbox</code>, <code>mediabox</code>, and <code>feederbox</code> as <code>DNS Only</code>, as they were created to reach your servers directly and not behind a CDN proxy (i.e. they need to resolve to the server's IP and not Cloudflare's).</p> <p>Note 2: If you enable proxying on plex/emby subdomains despite it being against TOS, you may find that performance suffers badly.</p> <p>You can do this by:</p> <ol> <li> <p>Going to Cloudflare.com.</p> </li> <li> <p>Clicking the DNS tab.</p> </li> <li> <p>Find the subdomain of interest.</p> </li> <li> <p>Under \"Status\", click the switch next to the gray cloud icon (i.e. <code>DNS Only</code>) to switch to an orange one (i.e. <code>DNS and HTTP proxy (CDN)</code>).</p> </li> </ol> <p></p>","title":"Post-Setup"},{"location":"reference/google-account-perms/","text":"<p>This guide will show you how to verify that your Google account has the correct permissions required for the shared drive creation.</p> <p>It's assuming you're working through the steps from here.</p> <p>NOTE: This guide is assuming a Google Gsuite Business/Workspace account.</p> <ol> <li> <p>Go to https://admin.google.com; from the left-hand menu select \"Apps &gt; Google Workspace &gt; Drive and Docs\":</p> <p></p> </li> <li> <p>Verify that Drive is turned on for your organization:</p> <p></p> </li> <li> <p>If it is not, click on the triangle on the right of that section and enable it if needed.  After clicking \"SAVE\" [if you changed the setting] click back to \"Settings for Drive and Docs\":</p> <p></p> </li> <li> <p>Back on the that screen, click on the \"Sharing settings\" section:</p> <p></p> </li> <li> <p>Scroll down and verify that and verify that your \"Shared Drive Settings\" match these.  Change them if required and save:</p> <p></p> </li> <li> <p>You're done.</p> </li> </ol> <p>If you are going through the manual rclone instructions, continue with the next step</p>","title":"Google Permissions"},{"location":"reference/google-gcloud-tools-install/","text":"<p>This guide will show you how to set up a Google SDK tools.</p> <p>It's assuming you're working through the steps from here and have completed the following steps:</p> <ul> <li>verified account drive permissions</li> <li>created the required project</li> <li>created the required group</li> </ul> <p>Simplified extract from here:</p> <ol> <li> <p>Run the following commands, one at a time:</p> <p><pre><code>sudo apt-get install apt-transport-https ca-certificates gnupg\n</code></pre> <pre><code>echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main\" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list\n</code></pre> <pre><code>curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -\n</code></pre> <pre><code>sudo apt-get update &amp;&amp; sudo apt-get install google-cloud-sdk -y\n</code></pre></p> </li> <li> <p>Run the following command:</p> <pre><code>gcloud init\n</code></pre> <p>Follow the prompts:</p> <p><pre><code>Welcome! This command will take you through the configuration of gcloud.\n\n...\n\nYou must log in to continue. Would you like to log in (Y/n)?  Y\n\nGo to the following link in your browser:\n\nhttps://accounts.google.com/o/oauth2/auth?response_type=code&amp;client_id=32...X4&amp;code_challenge_method=S256\n</code></pre> 3. Log into your Google account and approve the access request:</p> <p></p> <p>Copy the verification code.</p> </li> <li> <p>Continue in the terminal:</p> <pre><code>Enter verification code: 4/1AX4XfWjkg8C8r...ujs332G8\nYou are logged in as: [YOUR_GOOGLE_ACCOUNT].\n</code></pre> <p>You will now be asked to choose a default project.  Choose the one you created earlier.</p> <pre><code>Pick cloud project to use:\n [1] THE_PROJECT_YOUR_CREATED_FOR_SALTBOX\n [2] Create a new project\nPlease enter numeric choice or text value (must exactly match list item):  1\n\nYour current project has been set to: [THE_PROJECT_YOUR_CREATED_FOR_SALTBOX].\n</code></pre> <p>You may be asked to choose a default zone/region.  If so, you can choose the closest to you, but since we are not creating any location-specific objects, you can skip that.</p> </li> <li> <p>Run the following command:</p> <pre><code>gcloud organizations list\n</code></pre> <p>Your organization ID will be displayed in the table:</p> <pre><code>DISPLAY_NAME            ID  DIRECTORY_CUSTOMER_ID\nYOUR-DOMAIN   123456789098              XXXXXXXXX\n              ^^^ HERE ^^^\n</code></pre> <p>Make a note of that ID; if you're going through the manual rclone instructions you'll need it in the next step.</p> </li> <li> <p>Google SDK is installed and configured.</p> </li> </ol> <p>If you are going through the manual rclone instructions, continue with the next step</p>","title":"Google SDK"},{"location":"reference/google-group-setup/","text":"<p>This guide will show you how to set up a Google Group for use with service accounts.</p> <p>It's assuming you're working through the steps from here and have completed the following steps:</p> <ul> <li>verified account drive permissions</li> <li>created the required project</li> </ul> <p>NOTE: This guide is assuming a Google Gsuite Business/Workspace account.</p> <ol> <li>Open the Google Admin site: https://admin.google.com/ and login with your Google account.  Click on the groups heading:</li> </ol> <p></p> <ol> <li>You should now see a list of your groups [which may be empty].  Click on \"Create Group\":</li> </ol> <p></p> <ol> <li>Enter a name, description and email address for the group; choose an owner [this should be the account with which you just logged in]. Click \"Next\".</li> </ol> <p></p> <ol> <li>Scroll down, change \"Who can join\" to \"Only invited users\", and toggle \"Allow members outside your organization\". Click \"Create Group\".</li> </ol> <p></p> <ol> <li>Click \"Done\".</li> </ol> <p></p> <p>If you are going through the manual rclone instructions, continue with the next step</p>","title":"Google Group"},{"location":"reference/google-project-setup/","text":"<p>This guide will show you how to set up a Google Project and create credentials that will work for safire or sa-gen or similar tools.</p> <p>It's assuming you're working through the steps from here and have completed the following steps:</p> <ul> <li>verified account drive permissions</li> </ul> <p>This guide is assuming you are using a standard GSuite Business or GSuite Workspace account.</p> <ol> <li> <p>Open Google APIs Console site: https://console.developers.google.com and login with your Google account.</p> <p>Click on the project or organization at the top:</p> <p></p> </li> <li> <p>Click \"New Project\":</p> <p></p> </li> <li> <p>Name the project. Click \"Create\".</p> <p></p> <p>You'll see a progress dialog, when it's complete, click \"Select Project\"</p> <p></p> </li> <li> <p>Click \"Go to APIs overview\".</p> <p></p> </li> <li> <p>Click \"ENABLE APIS AND SERVICES\" at the top.</p> <p></p> <p>You'll be taken to the \"API Library\":</p> <p></p> </li> <li> <p>Search for \"Admin\". Click \"Admin SDK API\".</p> <p></p> <p>Click the button to enable the API:</p> <p></p> <p>You'll go to a API Overview page.  Click the browser back button twice:</p> <p></p> <p>Repeat this process for six more APIs:</p> <pre><code>- Google Drive API\n- Identity and Access Management (IAM) API\n- Cloud Resource Manager API\n- Service Usage API\n- Service Management API\n- Google Sheets API\n</code></pre> <p>You may find that some of these APIs have been enabled already as dependencies of others, like Service Management here:</p> <p></p> <p>In that case, click the website back arrow once and move on to the next one.</p> </li> <li> <p>Now click \"APIS and Services\" then \"Credentials\" in the left column to go to the credentials dash:</p> <p></p> </li> <li> <p>Click \"Configure consent screen\" over on the right:</p> <p></p> </li> <li> <p>Choose \"Internal\" user type and click \"Create\":</p> <p></p> </li> <li> <p>On this screen:</p> <ol> <li>type in the App Name (e.g. Rclone)</li> <li>Enter a \"User support email\"</li> <li>Scroll to the bottom</li> <li>Enter an email address under \"Developer contact information\"</li> <li>Click \"SAVE AND CONTINUE\".</li> </ol> <p></p> <p></p> </li> <li> <p>Click  \"SAVE AND CONTINUE\" on the scopes screen:</p> <p></p> <p>And \"BACK TO DASHBOARD\" on the final summary:</p> <p></p> </li> <li> <p>Click \"Credentials\" in the sidebar:</p> <p></p> </li> <li> <p>Click \"Create Credentials\", then \"OAuth client ID\":</p> <p></p> </li> <li> <p>Choose \"Desktop App\", give the app a name, and click \"CREATE\":</p> <p></p> </li> <li> <p>You'll be presented with the Client ID and Secret.  Copy and save them somewhere; you will need them to configure Plex Autoscan Google Drive Monitoring later.  Click on \"DOWNLOAD JSON\" to download the credential file:</p> <p></p> </li> </ol> <p>If you are going through the manual rclone instructions, continue with the next step</p>","title":"Google Project"},{"location":"reference/google-service-accounts/","text":"<p>This guide will show you how to create projects and service accounts using <code>sa-gen</code> and add them to a Google Group.</p> <p>It's assuming you're working through the steps from here and have completed the following steps:</p> <ul> <li>verified account drive permissions</li> <li>created the required project</li> <li>created the required group</li> <li>installed the gcloud SDK tools</li> </ul> <p>NOTE: This guide is assuming a Google Gsuite Business/Workspace account.</p> <ol> <li> <p>Make sure /opt/sa is writable by you.</p> <pre><code>sudo chown -R &lt;user&gt;:&lt;group&gt; /opt/sa\n</code></pre> <p>Enter the user name that you entered in <code>accounts.yml</code>; group is the same as the user.</p> <pre><code>---\nuser:\n  name: seed #   &lt;&lt;&lt; THIS VALUE\n...\n</code></pre> <p>You can also run <code>id</code> to get this information:</p> <pre><code>~ id\nuid=1000(marco) gid=1000(marco) groups=1000(marco),4(adm),24(cdrom),27(sudo),30(dip),44(video),46(plugdev),116(lxd),1001(docker)\n         ^&lt;user&gt;         ^&lt;group&gt;\n</code></pre> </li> <li> <p>Create a dir within that:</p> <pre><code>mkdir /opt/sa/all\n</code></pre> <p>The scripts in this setup all use this location.  Don't change it if you are using these scripts.</p> </li> <li> <p>Verify that the google project has the right APIs enabled:</p> <pre><code>gcloud services list --enabled\n</code></pre> <p>You should see:</p> <pre><code>NAME                                 TITLE\nadmin.googleapis.com                 Admin SDK API\nbigquery.googleapis.com              BigQuery API\nbigquerystorage.googleapis.com       BigQuery Storage API\ncloudapis.googleapis.com             Google Cloud APIs\nclouddebugger.googleapis.com         Cloud Debugger API\ncloudresourcemanager.googleapis.com  Cloud Resource Manager API\ncloudtrace.googleapis.com            Cloud Trace API\ndatastore.googleapis.com             Cloud Datastore API\ndrive.googleapis.com                 Google Drive API\niam.googleapis.com                   Identity and Access Management (IAM) API\niamcredentials.googleapis.com        IAM Service Account Credentials API\nlogging.googleapis.com               Cloud Logging API\nmonitoring.googleapis.com            Cloud Monitoring API\nservicemanagement.googleapis.com     Service Management API\nserviceusage.googleapis.com          Service Usage API\nsheets.googleapis.com                Google Sheets API\nsql-component.googleapis.com         Cloud SQL\nstorage-api.googleapis.com           Google Cloud Storage JSON API\nstorage-component.googleapis.com     Cloud Storage\nstorage.googleapis.com               Cloud Storage API\n</code></pre> <p>If any of these are missing from your list, go back to the project setup and add all the APIs shown there to the project.</p> </li> <li> <p>Retrieve the <code>sa-gen</code> code</p> <pre><code>cd /opt &amp;&amp; git clone https://github.com/88lex/sa-gen &amp;&amp; cd sa-gen\n</code></pre> </li> <li> <p>Edit the <code>sa-gan</code> script:</p> <pre><code>nano sa-gen\n</code></pre> <p>Edit the beginning of the script as indicated by <code>&lt;&lt;&lt;&lt;</code> below:</p> <pre><code>#!/bin/bash\n# Running this script requires gcloud command line tools. To install go to https://cloud.google.com/sdk/docs/quickstarts\n# See readme.md to understand the variables used in this script\n\nKEYS_DIR=/opt/sa/all               &lt;&lt;&lt;&lt; path where you want to store sa JSON files [you will need to add the /all here, most likely]\nORGANIZATION_ID=\"123456789098\"     &lt;&lt;&lt;&lt; organization ID from gcloud SDK step\nGROUP_NAME=\"mygroup@mydomain.com\"  &lt;&lt;&lt;&lt; the group [full address as shown] you created previously\nPROJECT_BASE_NAME=\"mgbtbnfkkt\"     &lt;&lt;&lt;&lt; the prefix you generated previously\nFIRST_PROJECT_NUM=1\nLAST_PROJECT_NUM=3\nSA_EMAIL_BASE_NAME=\"mgbtbnfkkt\"    &lt;&lt;&lt;&lt; the prefix you generated previously\nFIRST_SA_NUM=1\nNUM_SAS_PER_PROJECT=100\n...\n</code></pre> </li> <li> <p>Run the <code>sa-gan</code> script:</p> <pre><code>./sa-gen\n</code></pre> <p><code>sa-gen</code> will create three projects, 300 SAs, and download them to <code>/opt/sa/all</code>:</p> <pre><code>Total SA json keys before running sa-gen = 0\nCreating project = mgbtbnfkkt1\n++ gcloud projects create mgbtbnfkkt1 --organization=\nCreate in progress for [https://cloudresourcemanager.googleapis.com/v1/projects/mgbtbnfkkt1].\nWaiting for [operations/cp.5950654100828535641] to finish...done.\nEnabling service [cloudapis.googleapis.com] on project [mgbtbnfkkt1]...\nOperation \"operations/acf.p2-672393700722-9443eda2-69db-46a9-8952-5cdaa3b6ed2f\" finished successfully.\n++ set +x\n...\nTotal SA json keys BEFORE running sa-gen = 0\nTotal SA json keys AFTER running sa-gen  = 300\nTotal SA jsons CREATED                   = 300\n</code></pre> </li> <li> <p>Download the <code>members.csv</code> file that sa-gen created next to the service account files to your local computer using sftp or whatever other means.</p> <p></p> </li> <li> <p>Open the Google Admin site: https://admin.google.com/ and login with your Google account.  Click on the groups heading:</p> <p></p> </li> <li> <p>Click on your group:</p> <p></p> </li> <li> <p>Click on \"BULK UPLOAD MEMBERS\":</p> <p></p> </li> <li> <p>Click on \"ATTACH CSV\", and find the <code>members.csv</code> you downloaded a moment ago:</p> <p></p> </li> <li> <p>Click \"UPLOAD\".  Status will appear in the upper right:</p> <p></p> </li> <li> <p>You're done.</p> </li> </ol> <p>If you are going through the manual rclone instructions, continue with the next step</p>","title":"Google Service Accounts"},{"location":"reference/google-shared-drives/","text":"<p>This guide will show you how to create default Saltbox Shared Drives and add your group of SAs to them.</p> <p>It's assuming you're working through the steps from here and have completed the following steps:</p> <ul> <li>verified account drive permissions</li> <li>created the required project</li> <li>created the required group</li> <li>installed the gcloud SDK tools</li> <li>created the expected projects and service accounts</li> </ul> <p>NOTE: This guide is assuming a Google Gsuite Business/Workspace account.</p> <ol> <li> <p>Retrieve the <code>sb-gd</code> code</p> <pre><code>cd /opt &amp;&amp; git clone https://github.com/chazlarson/sb_gd.git  &amp;&amp; cd sb_gd\n</code></pre> </li> <li> <p>Create and activate a virtual environment:</p> <pre><code>python3 -m venv sb_gd &amp;&amp; source sb_gd/bin/activate\n</code></pre> <p>If you see something like this: <pre><code>The virtual environment was not created successfully because ensurepip is not\navailable.  On Debian/Ubuntu systems, you need to install the python3-venv\npackage using the following command.\n\n    apt install python3.8-venv\n\nYou may need to use sudo with that command.  After installing the python3-venv\npackage, recreate your virtual environment.\n\nFailing command: ['/home/YOU/sb_gd/sb_gd/bin/python3', '-Im', 'ensurepip', '--upgrade', '--default-pip']\n</code></pre></p> <p>run the suggested command with <code>sudo</code>: <pre><code>sudo apt install python3.8-venv\n</code></pre></p> <p>Then try the virtual-environment command in step 2 again.</p> </li> <li> <p>Install script requirements:</p> <pre><code>python -m pip install -r requirements.txt\n</code></pre> </li> <li> <p>Edit the <code>config.py</code> script:</p> <pre><code>nano config.py\n</code></pre> <p>Edit as indicated by <code>&lt;&lt;&lt;&lt;</code> below:</p> <pre><code>prefix = 'akIhSwlKdf'                &lt;&lt;&lt;&lt; the prefix you generated previously\n\ngroup_email = \"all-sa@DOMAIN.com\"    &lt;&lt;&lt;&lt; the group you created previously\n\ndrive_data = {\n    'Movies':'/Media/Movies',\n    'Music':'/Media/Music',\n    'TV':'/Media/TV'\n}\n</code></pre> </li> <li> <p>Copy your credential JSON into this directory:</p> <pre><code>cp  /opt/sa/project-creds.json client_secrets.json\n</code></pre> </li> <li> <p>Run the <code>sb_sd.py</code> script:</p> <pre><code>python sb_sd.py\n</code></pre> <p>You will be asked to authenticate in the usual Google way.  Follow the prompts.</p> <p>This script will create three shared drives, add your group email as a manager, create mount files and ID folders on the root, build the folder structure as defined in the config, and create rclone remotes for the individual shared drives and a union rclone remote for use with Saltbox:</p> <pre><code>** Team Drive aZaSjsklaj-Movies created, ID: 123456789\n** user all-sa@domain.com created as organizer, ID: 123456789\n** Folder -- aZaSjsklaj-Movies Shared -- created, ID 123456789\n** bin file created on root, ID 123456789\n** Folder Media created, ID 123456789\n** Folder Movies created, ID 123456789\n--------------------\n[aZaSjsklaj-Movies]\ntype = drive\nscope = drive\nservice_account_file = /opt/sa/all/150.json\nteam_drive = 123456789\n--------------------\n0\n** Team Drive aZaSjsklaj-Music created, ID: 123456789\n** user all-sa@domain.com created as organizer, ID: 123456789\n** Folder -- aZaSjsklaj-Music Shared -- created, ID 123456789\n** bin file created on root, ID 123456789\n** Folder Media created, ID 123456789\n** Folder Music created, ID 123456789\n--------------------\n[aZaSjsklaj-Music]\ntype = drive\nscope = drive\nservice_account_file = /opt/sa/all/150.json\nteam_drive = 123456789\n--------------------\n0\n** Team Drive aZaSjsklaj-TV created, ID: 123456789\n** user all-sa@domain.com created as organizer, ID: 123456789\n** Folder -- aZaSjsklaj-TV Shared -- created, ID 123456789\n** bin file created on root, ID 123456789\n** Folder Media created, ID 123456789\n** Folder TV created, ID 123456789\n--------------------\n[aZaSjsklaj-TV]\ntype = drive\nscope = drive\nservice_account_file = /opt/sa/all/150.json\nteam_drive = 123456789\n--------------------\n0\n--------------------\n[google]\ntype = union\nupstreams = aZaSjsklaj-Movies: aZaSjsklaj-Music: aZaSjsklaj-TV:\n--------------------\n</code></pre> <p>Drive names and IDs will be written to <code>drive_create_log</code>.</p> <p> What are those directories and files for?  <p>This script creates an empty directory and a zero-byte file on the root of each shared drive.</p> <p>The file will be useful later on when you need \"is this disk mounted?\" flags for things like <code>plex_autoscan</code>.</p> <p>The directory is a belt-and-suspenders convenience you can use to see if your union remote and/or mergerfs config is including everything it should.  We create both a file and a dir so you will get this information whether you use <code>rclone ls REMOTE</code> or <code>rclone lsd REMOTE</code> or whatever other means:</p> <p><pre><code> $ rclone lsd google:\n      -1 2021-11-21 17:09:13        -1 -- aZaSjsklaj-Movies Shared --\n      -1 2021-11-21 17:11:50        -1 -- aZaSjsklaj-Music Shared --\n      -1 2021-11-21 17:12:09        -1 -- aZaSjsklaj-TV Shared --\n      -3 2021-11-21 17:12:11        -1 Media\n\n $ rclone ls google:\n        0 azasjsklaj-movies_mounted.bin\n        0 azasjsklaj-tv_mounted.bin\n        0 azasjsklaj-music_mounted.bin\n</code></pre> </p>  <li> <p>You're done.  Deactivate the virtual env used by this script.</p> <pre><code> deactivate\n</code></pre> </li>  <p>If you are going through the manual rclone instructions, continue with the next step</p>","title":"Google Shared Drives"},{"location":"reference/install/","text":"","title":"Install"},{"location":"reference/install/#install-saltbox","text":"SaltboxMediaboxFeederboxCore   <pre><code>sb install saltbox\n</code></pre>   <pre><code>sb install mediabox\n</code></pre>   <pre><code>sb install feederbox\n</code></pre>   <pre><code>sb install core\n</code></pre>    <p>TODO: INCORPORATE \"WHEN IS IT DONE\" ARTICLE</p>","title":"Install Saltbox"},{"location":"reference/local-storage/","text":"<p>Saltbox can be configured to forego the cloud storage requirements discussed here</p> <p>This article will discuss the simplest case.  THere are of course a bunch of ways you could possibly do this that you may want to choose based on performance or whatever other requirements, but this is the Simplest Thing That Could Possibly Work.</p> <p>I'm assuming you are using some local NAS for storage and running saltbox on a different machine.</p> <p>First, mount your NAS storage at <code>/mnt/local/Media</code>.  Make sure that the user running the saltbox containers has full access to read and write.</p> <p>Then leave the rclone remote entry in the settings blank:</p> <pre><code>rclone:\n  version: latest \n  remote: \n</code></pre> <p>Saltbox will not do any of the remote mount setup.</p> <p>Once everything is installed and configured, Sonarr/Radarr/etc will move your completed downloads to <code>/mnt/local/Media/WHATEVER</code>, which will be on the NAS.</p> <p>You'll probably need to come up with a strategy for managing seeding torrents; perhaps you want to movethose to the NAS as well.</p>","title":"Local Storage"},{"location":"reference/multiple-instances/","text":"<p>Apps that used to be supported by the \"ArrX\" system which allowed the user to define a set of instances of a given app [as opposed to installing multiple instances one at a time] are being transitioned to a new generalized, inventory-driven approach.</p> <p>The general idea is to move all the configuration into the <code>localhost.yml</code> along with other customizations.</p> <p>Sonarr, Radarr and Lidarr support this new method as of this writing.</p>","title":"Multiple App Instances"},{"location":"reference/multiple-instances/#overview","text":"<p>Define a list of all the instances of the all you want to create; if you don't want to customize them beyond that, this is all that's required.</p> <p>The standard app tag will now set up all those instances.</p> <p>For example, a SonarrX config might have looked like this:</p> <pre><code>sonarrx:\n  roles:\n    - \"\"\n    - bing\n    - bang\n    - boing\n</code></pre> <p>That would be set up in <code>settings.yml</code>.</p> <p>With this new method, that will be replaced with this in <code>localhost.yml</code>:</p> <pre><code>sonarr_instances: [\"sonarr\", \"sonarrbing\", \"sonarrbang\", \"sonarrboing\"]\n</code></pre> <p>Note a primary changepoint is that the entire name of the instance is specified.  The role will no longer prepend the name of the app.</p> <p>Given the config above, <code>sb install sonarr</code> would install:</p>    entry Container Config dir Subdomain     sonarr sonarr <code>/opt/sonarr</code> sonarr.YOURDOMAIN.TLD   sonarrbing sonarrbing <code>/opt/sonarrbing</code> sonarrbing.YOURDOMAIN.TLD   sonarrbang sonarrbang <code>/opt/sonarrbang</code> sonarrbang.YOURDOMAIN.TLD   sonarrboing sonarrboing <code>/opt/sonarrboing</code> sonarrboing.YOURDOMAIN.TLD    <p>Those names have to be unique across all of your containers, so it is suggested that you keep with the <code>rolename+suffix</code> pattern for these additional instances.</p>","title":"Overview"},{"location":"reference/multiple-instances/#per-instance-customization","text":"<p>Any instance defined can edit the following set of variables on a per instance basis in <code>localhost.yml</code>:</p>  <p>Note</p> <p>Replacing \"instance\" with the actual instance name, of course, i.e. sonarrbing_web_subdomain, etc.</p>  <pre><code>instance_web_subdomain\ninstance_web_domain\ninstance_web_port\ninstance_traefik_sso_middleware\ninstance_docker_image_repo\ninstance_docker_image_tag\ninstance_docker_ports_defaults\ninstance_docker_ports_ui\ninstance_docker_ports_custom\ninstance_themepark_enabled\ninstance_themepark_domain\ninstance_themepark_theme\ninstance_docker_envs_default\ninstance_docker_envs_custom\ninstance_docker_commands_default\ninstance_docker_docker_commands_custom\ninstance_docker_volumes_default\ninstance_docker_volumes_custom\ninstance_docker_volumes_theme\ninstance_docker_devices_default\ninstance_docker_devices_custom\ninstance_docker_hosts_default\ninstance_docker_hosts_custom\ninstance_docker_labels_default\ninstance_docker_labels_custom\ninstance_docker_networks_default\ninstance_docker_networks_custom\ninstance_docker_capabilities_default\ninstance_docker_capabilities_custom\ninstance_docker_security_opts_default\ninstance_docker_security_opts_custom\n</code></pre>","title":"Per-instance customization"},{"location":"reference/plex-autoscan-config/","text":"<p>The default Plex Autoscan [PAS] setup does not enable Google Drive Monitoring, and the config does not match the automated shared drive setup.</p> <p>To utilize Google Drive Monitoring [GDM], you'll need to make a few changes to the config to account for your own shared drives.</p> <p>If you don't want to enable GDM, you don't need to do this.</p>  <p>Info</p> <p>GDM is useful if you are planning to add content to your Google Drive directly, outside of Sonarr/Radarr.  It provides a mechanism for PAS to pick up those changes and tell Plex to scan them.  If all your content is coming through Sonarr/Radarr, there's no reason for GDM.</p>  <p>If you used the scripted rclone method, there is a script in the sb_gd repo that will make the required modifications to the stock Plex Autoscan config.</p> <p>This script is only useful if you have used the scripted rclone method.  It is expecting a stock plex autoscan config file as you will have when you have completed the install.</p> <p>You will have to have completed <code>sb install saltbox</code> before using this script.</p> <ol> <li> <p>Run the script</p> <pre><code>cd /opt/sb_gd\nsource sb_gd/bin/activate\npython sb_pas.py\n</code></pre> <p>If that doesn't work, update to the latest version of the files from the repo with <code>git pull</code> and try again.</p> </li> <li> <p>Next, you will need to authorize Google Drive. To do so, run the following command:</p> <pre><code>plex_autoscan authorize\n</code></pre> <p>If this doesn't work for you, update saltbox and rerun the plex_autoscan role:</p> <pre><code>sb update\nsb install plex_autoscan\n</code></pre> </li> <li> <p>Visit the link shown to get the authorization code and paste that in and hit <code>enter</code>.</p> <pre><code>Visit https://accounts.google.com/o/oauth2/v2/auth?scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&amp;redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&amp;response_type=code&amp;client_id=&amp;access_type=offline and authorize against the account you wish to use\nEnter authorization code:\n</code></pre> </li> <li> <p>When access token retrieval is successful, you'll see this:</p> <pre><code>2018-06-24 05:57:58,252 -     INFO -    GDRIVE [140007964366656]: Requesting access token for auth code '4/AAAfPHmX9H_kMkMasfdsdfE4r8ImXI_BddbLF-eoCOPsdfasdfHBBzffKto'\n2018-06-24 05:57:58,509 -     INFO -    GDRIVE [140007964366656]: Retrieved first access token!\n2018-06-24 05:57:58,511 -     INFO -  AUTOSCAN [140007964366656]: Access tokens were successfully retrieved!\n</code></pre> <p>Note: Ignore any <code>Segmentation fault</code> messages.</p> </li> <li> <p>Restart the Plex Autoscan service:</p> <pre><code>sudo systemctl restart plex_autoscan\n</code></pre> </li> </ol>","title":"Shared-Drive Plex Autoscan Setup"},{"location":"reference/plex-autoscan-extras/","text":"<p>Other options for Plex Autoscan.</p>","title":"Plex Autoscan Extras"},{"location":"reference/plex-autoscan-extras/#google-drive-monitoring","text":"<p>In addition to Plex Autoscan receiving scan requests from Sonarr/Radarr/Lidarr, it can also monitor Google Drive directly for updates. When a new file is detected, it is checked against the Plex database and if this file is missing, a new scan request is sent to Plex.</p> <p>Note: For details on setting up Teamdrives and/or Rclone-crypted remotes, visit https://github.com/l3uddz/plex_autoscan.</p> <p>If you used the scripted rclone method, there is a script in the sb_gd repo that will help with this setup.</p> <p>To set this up:</p> <ol> <li> <p>Edit the config file:</p> <p><code>`shell nano /opt/plex_autoscan/config/config.json</code>9</p> </li> <li> <p>Under the <code>GOOGLE</code> section of the config, enable Google Drive monitoring and fill in your Google Drive API Client ID and Secret [Step 15 of that process].</p> <pre><code>\"ENABLED\": true,\n\"CLIENT_ID\": \"yourclientid\",\n\"CLIENT_SECRET\": \"yourclientsecret\",\n</code></pre> </li> <li> <p>So that the entire section now looks like this (any order is fine):</p> <pre><code>\"GOOGLE\": {\n  \"ENABLED\": true,\n  \"CLIENT_ID\": \"abcdefgh\",\n  \"CLIENT_SECRET\": \"1234567\",\n  \"ALLOWED\": {\n    \"FILE_PATHS\": [\n      \"My Drive/Media/Movies\",\n      \"My Drive/Media/TV\",\n      \"My Drive/Media/Music\"\n    ],\n    \"FILE_EXTENSIONS\": true,\n    \"FILE_EXTENSIONS_LIST\": [\n      \"webm\",\"mkv\",\"flv\",\"vob\",\"ogv\",\"ogg\",\"drc\",\"gif\",\n      \"gifv\",\"mng\",\"avi\",\"mov\",\"qt\",\"wmv\",\"yuv\",\"rm\",\n      \"rmvb\",\"asf\",\"amv\",\"mp4\",\"m4p\",\"m4v\",\"mpg\",\"mp2\",\n      \"mpeg\",\"mpe\",\"mpv\",\"m2v\",\"m4v\",\"svi\",\"3gp\",\"3g2\",\n      \"mxf\",\"roq\",\"nsv\",\"f4v\",\"f4p\",\"f4a\",\"f4b\",\"mp3\",\n      \"flac\",\"ts\"\n    ],\n    \"MIME_TYPES\": true,\n    \"MIME_TYPES_LIST\": [\n      \"video\"\n    ]\n  },\n  \"TEAMDRIVE\": false,\n  \"TEAMDRIVES\": [],\n  \"POLL_INTERVAL\": 120,\n  \"SHOW_CACHE_LOGS\": false\n},\n</code></pre> </li> <li> <p>Google Drive paths (e.g. <code>\"My Drive/Media/Movies/\"</code>) go under <code>SERVER_PATH_MAPPINGS</code> and should look like this:</p> <p>Note: This is usually set pre-filled by default.</p> <pre><code>\"SERVER_PATH_MAPPINGS\": {\n  \"/data/Movies/\": [\n    \"/movies/\",\n    \"/mnt/unionfs/Media/Movies/\",\n    \"My Drive/Media/Movies/\"\n  ],\n  \"/data/TV/\": [\n    \"/tv/\",\n    \"/mnt/unionfs/Media/TV/\",\n    \"My Drive/Media/TV/\"\n  ],\n  \"/data/Music/\": [\n    \"/music/\",\n    \"/mnt/unionfs/Media/Music/\",\n    \"My Drive/Media/Music/\"\n  ]\n},\n</code></pre> <p>Note: If you are using [[Scenario 2 Custom Library Setup|Customizing Plex Libraries#scenario-2]], you will need to tweak this section of the config.</p> </li> <li> <p>Save and Exit.</p> </li> <li> <p>Next, you will need to authorize Google Drive. To do so, run the following command:</p> <pre><code>plex_autoscan authorize\n</code></pre> <p>If this doesn't work for you, update saltbox and rerun the plex_autoscan role:</p> <pre><code>sb update\nsb install plex_autoscan\n</code></pre> </li> <li> <p>Visit the link shown to get the authorization code and paste that in and hit <code>enter</code>.</p> <pre><code>Visit https://accounts.google.com/o/oauth2/v2/auth?scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&amp;redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&amp;response_type=code&amp;client_id=&amp;access_type=offline and authorize against the account you wish to use\nEnter authorization code:\n</code></pre> </li> <li> <p>When access token retrieval is successful, you'll see this:</p> <pre><code>2018-06-24 05:57:58,252 -     INFO -    GDRIVE [140007964366656]: Requesting access token for auth code '4/AAAfPHmX9H_kMkMasfdsdfE4r8ImXI_BddbLF-eoCOPsdfasdfHBBzffKto'\n2018-06-24 05:57:58,509 -     INFO -    GDRIVE [140007964366656]: Retrieved first access token!\n2018-06-24 05:57:58,511 -     INFO -  AUTOSCAN [140007964366656]: Access tokens were successfully retrieved!\n</code></pre> <p>Note: Ignore any <code>Segmentation fault</code> messages.</p> </li> <li> <p>Restart the service:</p> <pre><code>sudo systemctl restart plex_autoscan\n</code></pre> </li> <li> <p>Plex Autoscan will now start monitoring Google Drive.</p> </li> </ol>","title":"Google Drive Monitoring"},{"location":"reference/plex-autoscan-extras/#make-plex-scan-a-specific-file-or-folder","text":"","title":"Make Plex scan a specific file or folder"},{"location":"reference/plex-autoscan-extras/#web-app","text":"<p></p> <p>Setup instructions:</p> <ol> <li> <p>Enable <code>SERVER_ALLOW_MANUAL_SCAN</code> in your <code>/opt/plex_autoscan/config/config.json</code> file.</p> <pre><code>\"SERVER_ALLOW_MANUAL_SCAN\": true,\n</code></pre> </li> <li> <p>Visit your Plex Autoscan URL webpage.</p> </li> <li> <p>Enter in the path to scan.</p> <p>Note: The path can be in any form (e.g. <code>/data/Media/...</code>, <code>/mnt/unionfs/Media/...</code>, <code>My Drive/Media/....</code>). The 'Server Path Mappings' will redirect the scan to the correct location.</p> </li> <li> <p>The request will now show up under Plex Autoscan logs.</p> </li> </ol>","title":"Web app"},{"location":"reference/plex-autoscan-extras/#http","text":"<ol> <li> <p>Initiate a scan request via curl or equivalent tool:</p> <p>Note: The path can be in any form (e.g. <code>/data/Media/...</code>, <code>/mnt/unionfs/Media/...</code>, <code>My Drive/Media/....</code>). The 'Server Path Mappings' will redirect the scan to the correct location.</p> <p>Format: <pre><code>curl -d \"eventType=Manual&amp;filepath=&lt;PATH TO FILE/FOLDER&gt;\" &lt;YOUR PLEX AUTOSCAN URL&gt;\n</code></pre></p> </li> <li> <p>Examples:</p> <pre><code>curl -d \"eventType=Manual&amp;filepath=/mnt/unionfs/Media/Movies/Shut In (2016)/Shut In (2016) - Bluray-1080p.x264.DTS-GECKOS.mkv\" http://ipaddress:3468/0c1fa3c9867e48b1bb3aa055cb86`\n</code></pre> <pre><code>curl -d \"eventType=Manual&amp;filepath=/data/Movies/Shut In (2016)/Shut In (2016) - Bluray-1080p.x264.DTS-GECKOS.mkv\" http://ipaddress:3468/0c1fa3c9867e48b1bb3aa055cb86`\n</code></pre> </li> <li> <p>The request will now show up under Plex Autoscan logs.</p> </li> </ol> <p>For more details on both options, see [[here|https://github.com/l3uddz/plex_autoscan#misc]].</p>","title":"HTTP"},{"location":"reference/plex-autoscan-extras/#cli","text":"<p>Note 1: This is only done on the box where Plex is installed.</p> <p>Note 2: The path used here has to be exactly what Plex uses for its library.</p> <p>Note 3: This method does not use Plex Autoscan, and therefore, Plex will immediately start scanning the given paths.</p>","title":"CLI"},{"location":"reference/plex-autoscan-extras/#command","text":"<p>Note: Replace <code>&lt;section ID&gt;</code> ([[Plex Library Section IDs]]) and <code>&lt;plex library's movie/tv show path&gt;</code> with yours.</p> <pre><code>docker exec -u plex -i plex bash -c 'export LD_LIBRARY_PATH=/usr/lib/plexmediaserver/lib;/usr/lib/plexmediaserver/Plex\\ Media\\ Scanner --scan --refresh --section &lt;section ID&gt; --directory '\"'\"'&lt;movie or tv show path&gt;'\"'\"''\n</code></pre>","title":"Command"},{"location":"reference/plex-autoscan-extras/#examples","text":"<p>Movie (Section ID 1)</p> <pre><code>docker exec -u plex -i plex bash -c 'export LD_LIBRARY_PATH=/usr/lib/plexmediaserver/lib;/usr/lib/plexmediaserver/Plex\\ Media\\ Scanner --scan --refresh --section 1 --directory '\"'\"'/data/Movies/The Predator (2018)/'\"'\"''\n</code></pre> <p>TV Show (Section ID 2)</p> <pre><code>docker exec -u plex -i plex bash -c 'export LD_LIBRARY_PATH=/usr/lib/plexmediaserver/lib;/usr/lib/plexmediaserver/Plex\\ Media\\ Scanner --scan --refresh --section 2 --directory '\"'\"'/data/TV/The Walking Dead/'\"'\"''\n</code></pre> <p>TV Show with specific season scanned (Section ID 2)</p> <pre><code>docker exec -u plex -i plex bash -c 'export LD_LIBRARY_PATH=/usr/lib/plexmediaserver/lib;/usr/lib/plexmediaserver/Plex\\ Media\\ Scanner --scan --refresh --section 2 --directory '\"'\"'/data/TV/Marvels Daredevil/Season 03/'\"'\"''\n</code></pre>","title":"Examples"},{"location":"reference/plex/","text":"","title":"Plex or Emby Account"},{"location":"reference/plex/#plex","text":"<p>You'll need a free Plex account for the setup, if you don't already have one. </p> <p>It's easiest if you have a Plex account even if you're not planning to use Plex.  The default <code>saltbox</code> install assumes that you are using Plex, and without a Plex account in the settings, it will fail in various ways as it tries to install Plex and then things that depend on Plex.  This can be worked around[1] , and may change in the future, but for now the simplest route is to sign up for that free account, and then disable Plex after install if you don't want to use it.</p> <p>1 Basically, run the <code>core</code> tag instead of the <code>saltbox</code> tag, then run the tags for the apps you want individually. </p>","title":"Plex"},{"location":"reference/plex/#emby","text":"<p>You can use Emby in lieu of Plex [admonitions above about needing a Plex account for install still apply].</p> <p>Sign up for a free Emby Connect account at https://emby.media/connect.html, if you don't already have one.</p> <p>You'll need to install Emby manually after the initial install is complete.</p>","title":"Emby"},{"location":"reference/plex_auth_token/","text":"<p>Here are two ways of obtaining a Plex Access Token for your Plex account.</p>","title":"Plex Auth Token"},{"location":"reference/plex_auth_token/#saltbox-role","text":"<p>You will need your Plex credentials filled in <code>~/saltbox/accounts.yml</code>. If you already do, skip steps 2-4.</p> <ol> <li>Go to the Saltbox folder:</li> </ol> <pre><code>cd ~/saltbox/\n</code></pre> <ol> <li> <p>Open the file for editing:</p> </li> <li> <p>For encrypted <code>accounts.yml</code>:</p> <pre><code>ansible-vault edit accounts.yml\n</code></pre> </li> <li> <p>For plain text <code>accounts.yml</code>:</p> <pre><code>nano accounts.yml\n</code></pre> </li> <li> <p>Fill in your Plex credentials:</p> </li> </ol> <pre><code>plex:\n  user:\n  pass:\n</code></pre> <ol> <li> <p>Save and exit: Ctrl + X Y Enter.</p> </li> <li> <p>Run the following command:</p> </li> </ol> <pre><code>sb install plex_auth_token\n</code></pre> <ol> <li>You will be shown your Plex Access Token in the log:</li> </ol> <pre><code>TASK [plex_auth_token : Display Plex Auth Token] \n***********************************************************************************\nTuesday 29 January 2019  21:08:33 +0100 (0:00:00.104)       0:00:13.905 *******\nok: [localhost] =&gt; {\n    \"msg\": \"Your Plex Auth Token is: XXXXXXXXXXXXXXXX\"\n}\n</code></pre>","title":"Saltbox Role"},{"location":"reference/plex_auth_token/#script","text":"<ol> <li>On the server's shell, run the following command[1]:</li> </ol> <pre><code>/opt/scripts/plex/plex_token.sh\n</code></pre> <ol> <li>You will be prompted to enter your Plex login and then presented with the Plex Access Token (under <code>Your X_PLEX_TOKEN:</code>)</li> </ol>","title":"Script"},{"location":"reference/plex_auth_token/#_1","text":"<p> 1 Credit: https://github.com/wernight</p>","title":"Plex Auth Token"},{"location":"reference/ports/","text":"App Ports Notes     Emby     Jackett     Lidarr     Traefik 80, 443 Used by Saltbox apps when reverse-proxy is enabled.   NZBGet     NZBHydra     NZBHydra2     Ombi     Organizr     Plex (main) 32400 Not needed when using reverse proxy.   If 32400 needs to be open, set <code>plex_open_main_ports: true</code> using the inventory system.   Plex (extras) TCP: 3005, 8324, 32469   UDP: 1900, 5353, 8324, 32410, 32412, 32413, 32414 Non essential for remote servers. See here.  If ports need to be open, add the ones needed to <code>plex_docker_ports_custom: []</code> using the inventory system.   Plex Autoscan 3468 To disable this port in the FW and run it locally, see here.   Tautulli     Portainer     Radarr     Resilio Sync 55555    ruTorrent 6881 (UDP), 51413    Sonarr     Cloudplow     Watchtower     WebTools for Plex 33400, 33443","title":"Ports"},{"location":"reference/preinstall/","text":"","title":"Preinstall"},{"location":"reference/preinstall/#preinstall","text":"<p>Warning</p> <p>Make sure that you have setup the configuration correctly before proceeding.</p>  <p>This step will create the specified user account, add it to sudoers, update the kernel, edit GRUB configuration and install Rclone and reboot the server if needed.</p> <pre><code>sb install preinstall\n</code></pre>  <p>Info</p> <p>From this point you'll want to make sure you run commands as the user specified in the accounts.yml</p>  <p>If your server did not need to reboot you can run <code>su username</code> to switch user or reconnect to SSH as the newly created user. Everything after this point will assume you are running as the user entered in accounts.yml</p>","title":"Preinstall"},{"location":"reference/rclone-auto/","text":"","title":"Rclone [Auto]"},{"location":"reference/rclone-auto/#automated-rclone-setup","text":"<p>Ultimately, saltbox will have an automated rclone setup that does as much as possible for the user.</p> <p>This software is still under construction.</p> <p>Please follow the partially scripted version of this process.</p>","title":"Automated rclone setup"},{"location":"reference/rclone-manual/","text":"<p>Rclone (by Nick Craig-Wood) is \"rsync for the cloud\". Basically, it is used to transfer data to or from a variety of supported cloud storage providers (eg Google Drive).</p> <p>Rclone is used by Cloudplow and Backup to upload media and backup Saltbox, respectively.</p> <p>The guide below assumes you are using Google Drive.</p> <p>Rclone supports many cloud provider backends, but the only one routinely used by the Saltbox team is Google Drive.</p> <p>This process will use various scripts to do as much of this for you as possible, but there are some things that can't be scripted easily, like steps 1 and 2 below.</p>  What about `safire`? Can't it do all this automatically?     Sure, and the first version of this attempt at automation used safire to do everything from step 3 on with two runs of a script which asked a couple questions.  It always worked on the developer's machine, but failed half the time on not-the-developer's machine.  So this approach was built out to not use `safire`.    Eventually there will be an app or script that will take care of all this, but until that day, there is this.    If you have suggestions about how this can be made more clear, by all means open an issue.   <p>Here's what you are going to do as you work through the instructions below:</p> <p>[These are not the instructions, just an overview]</p> <ol> <li> <p>Create a Google project. [not scripted, you'll do this manually]</p> </li> <li> <p>Create a Google group. [not scripted, you'll do this manually]</p> </li> <li> <p>Install the Google SDK tools. [not scripted, you'll do this manually]</p> </li> <li> <p>Create a bunch of service accounts and put all the service accounts' JSON files into a subdirectory of <code>/opt</code>. [scripted with minor config edits]</p> </li> <li> <p>Add all those service accounts to the Google group you just created. [Starting here scripted with minor config edits to a single script]</p> </li> <li> <p>Create three new shared drives in the Google Drive UI. [Movies, Music, TV]</p> </li> <li> <p>Add your Google Group to each of those drives as a \"Manager\"</p> </li> <li> <p>Create rclone remotes pointing to each of those shared drives, authenticated using one of those service files.</p> </li> <li> <p>Create a union rclone remote called \"google\", with the components set to the three td remotes you just created.</p> </li> </ol> <p>If you already have Rclone configured, you can jump directly to the relevant section.</p>","title":"Rclone [Manual]"},{"location":"reference/rclone-manual/#new-rclone-setup","text":"<ol> <li> <p>Verify that the Shared Drive permissions are correct on your Google account:</p> <p>Instructions here</p> </li> <li> <p>Create a new project and generate a credential file:</p> <p>Instructions here</p> <p>Save that credential file on your server at <code>/opt/sa/project-creds.json</code></p> </li> <li> <p>Create a Google Group to hold service accounts:</p> <p>Instructions here</p> </li> <li> <p>Set up the GCloud SDK:</p> <p>Instructions here</p> </li> <li> <p>Generate a random prefix</p> <pre><code>prefix=$(head /dev/urandom | tr -dc a-z | head -c10 ;) &amp;&amp; echo $prefix\n</code></pre> <p>Make a note of that prefix; you will use it in the next two steps.</p> <p>This prefix is used for two purposes:</p> <ol> <li> <p>Project names need to be unique across all of Google; a random prefix helps ensure this [the error that results in this case is non-obvious].</p> </li> <li> <p>It helps these scripts unambiguously identify things that they have created.</p> </li> </ol> </li> <li> <p>generate some service accounts</p> <p>Instructions here</p> </li> <li> <p>Create some Shared Drives and related infrastructure</p> <p>Instructions here</p> </li> <li> <p>Verify that the union remote shows you the expected contents:</p> <pre><code>rclone tree google:/\n</code></pre> <p>This should display something like:</p> <pre><code>/\n\u251c\u2500\u2500 -- aZaSjsklaj-Movies Shared --\n\u251c\u2500\u2500 -- aZaSjsklaj-Music Shared --\n\u251c\u2500\u2500 -- aZaSjsklaj-TV Shared --\n\u251c\u2500\u2500 Media\n\u2502   \u251c\u2500\u2500 Movies\n\u2502   \u251c\u2500\u2500 Music\n\u2502   \u2514\u2500\u2500 TV\n\u251c\u2500\u2500 azasjsklaj-movies_mounted.bin\n\u251c\u2500\u2500 azasjsklaj-music_mounted.bin\n\u2514\u2500\u2500 azasjsklaj-tv_mounted.bin\n\n7 directories, 3 files\n</code></pre> </li> <li> <p>You now have three shared drives and union combining them; the saltbox install will merge this with your local drive and cloudplow will upload to the union mount, which will distribute media to the three shared drives by path.  You will still be limited to the 750GB/day Google upload limit until you configure cloudplow to upload directly to the individual shared drives.  Eventually this will be automated, but for now there is this guide.</p> </li> <li> <p>If you want to use Plex Autoscan's Google Drive Monitoring, there are some changes that will be required in the configuration. See this guide.</p> </li> </ol>","title":"New Rclone Setup"},{"location":"reference/rclone-manual/#existing-rclone-setup","text":"<p>The default remote specified in [[settings.yml|Install: settings.yml]] is <code>google</code> for Google Drive. If the Rclone remote in your config has the same name, then you are OK to skip this page and go on to the next.</p> <p>If you are using Google Drive and the Rclone remote in your config has a different name, then you will need to either:</p> <ul> <li>Rename your current Rclone remote to the default one (i.e. <code>google</code>). Instructions for this are below.</li> </ul> <p>Or</p> <ul> <li>Edit the Rclone remote entry in [[settings.yml|Install: settings.yml]] with yours.</li> </ul> <p>If you prefer to use another cloud storage provider, you can add the name of the Rclone remote in to [[settings.yml|Install: settings.yml]].</p>","title":"Existing Rclone Setup"},{"location":"reference/rclone-manual/#rename-existing-rclone-remote","text":"<p>To rename the Google Drive remote to <code>google</code>:</p> <ol> <li>Find and edit your Rclone configuration file.</li> </ol> <p><pre><code>nano $(rclone config file | tail -n 1)\n</code></pre> 1. Rename the Google Drive drive remote (name between the brackets) to <code>google</code>.</p> <ol> <li>It will now look like this:</li> </ol> <p><pre><code>[google]\ntype = drive\nclient_id = 1234567890123-mjffsmxvendscftuvnyngkhegapovgnv.apps.googleusercontent.com\nclient_secret = klflzftkrwuwuedesxzewsfz\ntoken = {\"access_token\":\"ya30.gelftvrymioiilvdtfegfvhfgallrhocewjckdnnvmxdjpjzbdhkmgulvqhgbafkdtpottzthhnyzysxwlpf-38ikRIxZvimyoxyKdse$\n</code></pre> 1. Save the file and exit: Ctrl + X Y Enter.</p> <ol> <li>Copy the config file to <code>~/.config/rclone/rclone.conf</code> (if it isn't there already):</li> </ol> <pre><code>cp -n $(rclone config file | tail -n 1) ~/.config/rclone/rclone.conf\n</code></pre> <ol> <li>Give it the proper ownership and permissions. Replace <code>user</code> and <code>group</code> to match yours' (see here):</li> </ol> <pre><code>sudo chown user:group ~/.config/rclone/rclone.conf\nsudo chmod 755 ~/.config/rclone/rclone.conf\n</code></pre>","title":"Rename Existing Rclone Remote"},{"location":"reference/rclone/","text":"","title":"Rclone"},{"location":"reference/rclone/#rclone","text":"<p>This step will take you through the configuration of Rclone.</p> <p>If you're migrating from Cloudbox you probably want the Cloudbox migration instructions</p>","title":"Rclone"},{"location":"reference/rclone/#overview","text":"<p>The steps that need to be done to set up rclone are:</p> <p>Note that this is a general overview of the things that have to happen, not a list of instructions  Paths and names referenced in this list are must examples.  Please refer to the actual instructions further down for specifics.</p> <ol> <li> <p>Create a Google project</p> </li> <li> <p>Create a Google group</p> </li> <li> <p>Create a bunch of service accounts</p> </li> <li> <p>Put all the service accounts JSON files into some directory where all relevant software can see them.</p> </li> <li> <p>Add all those service accounts to the Google group you just created.</p> </li> <li> <p>Create new shared drives in the Google Drive UI.</p> </li> <li> <p>Add your Google Group to each of those drives as a \"Manager\"</p> </li> <li> <p>Create rclone remotes pointing to each of those shared drives, authenticated using one of those service files.</p> </li> <li> <p>Create a <code>union</code> rclone remote called \"google\", with the components set to the shared drive remotes you just created.</p> </li> </ol>","title":"Overview"},{"location":"reference/rclone/#instructions","text":"<p>Automated.</p> <p>Partially scripted.</p>","title":"Instructions:"},{"location":"reference/safire/","text":"<p>Saltbox defaults to using service accounts for uploading to multiple teamdrives to allow for future growth.</p> <p>To make the setup more straightforward, this guide will leverage <code>safire</code> to generate as much infrastructure as possible.</p> <p>This will set up three Shared Drives and set up all the infrastructure you need for Saltbox to use them.</p> <p>If you're here, you probably want to go here instead.  <code>safire</code> has been acting inconsistently.</p>","title":"Safire"},{"location":"reference/safire/#this-script-is-a-work-in-progress-it-probably-has-rough-edges","text":"","title":"This script is a work in progress; it probably has rough edges."},{"location":"reference/safire/#assumptions-and-defaults","text":"<ol> <li> <p>You have rclone installed</p> </li> <li> <p>You are running python 3.8 and have run <code>sudo apt install python3.8-venv -y</code>    Probably other python3 works, the assumption is that the script can create a venv</p> </li> <li> <p>The script will generate a random prefix and use this for the shared drives, service accounts, and projects.</p> </li> <li> <p>Default is to generate three shared drives:</p> </li> </ol>    Drive media dir     [PREFIX]_Movies <code>/Media/Movies</code>   [PREFIX]_Music <code>/Media/Music</code>   [PREFIX]_TV <code>/Media/TV</code>    <p>This can be modified with a config file.  The first half of the script will display the details.</p> <ol> <li>Default is to generate three projects with 100 service accounts each.  This can be modified at the beginning of the script itself.</li> </ol> <p>There are a couple other user settings at the beginning of the script.</p>","title":"Assumptions and defaults:"},{"location":"reference/safire/#google-project-and-group-setup","text":"<p>There are two pieces that can't be scripted.</p> <ol> <li> <p>You will need to create a new project and generate a credential file:</p> <p>Instructions here</p> </li> <li> <p>You will need to create a Google Group to hold service accounts:</p> <p>Instructions here</p> </li> </ol>","title":"Google Project and Group Setup"},{"location":"reference/safire/#safire-setup","text":"<ol> <li> <p>SSH into your server, then copy-paste these commands one by one:</p> <pre><code>curl -fLvO https://raw.githubusercontent.com/chazlarson/sb_gd/main/sb_gd.sh\nchmod +x sb_gd.sh\n./sb_gd.sh\n</code></pre> </li> <li> <p>Copy the credential JSON you downloaded earlier to <code>~/safire/creds/creds.json</code> on your server</p> <p>You can do this in a variety of ways; if you are running a linux-like system locally</p> <pre><code>scp /LOCAL/PATH/TO/creds.json USER@DOMAIN.TLD:~/safire/creds/creds.json\n</code></pre> <p>For example:</p> <pre><code>scp /Users/nacl/Downloads/safire-credentials.json nacl@111.222.333.444:~/safire/creds/creds.json\n</code></pre> </li> <li> <p>Run the script again.</p> <p>You will be prompted to authenticate to google and copy-paste a token [this will happen twice].</p> <p>If you didn't enter your google group email address into the script, you will be asked for it.</p> <pre><code>./sb_gd.sh\n</code></pre> </li> <li> <p>You should now have three new shared drives ready for use with Saltbox.</p> </li> </ol>","title":"<code>safire</code> Setup:"},{"location":"reference/saltbox-tools/","text":"<ul> <li>Overview</li> <li>Details</li> </ul>","title":"Saltbox Tools"},{"location":"reference/saltbox-tools/#overview","text":"<p>Saltbox comes with some useful command line tools and scripts. Some are meant to be utilized by Saltbox, automatically (e.g. fail2ban, torrentcleanup.py, etc), and some are for your usage.</p>    <pre>                          </pre>  Name <pre>     </pre>  Type <pre>                                                                    </pre> Description <pre>                                     </pre> Invoked by <pre>                                                                  </pre> Homepage     htop application Interactive process viewer for Unix. <code>htop</code> http://hisham.hm/htop/   ctop application Top-like interface for container metrics. <code>ctop</code> https://ctop.sh/   iotop application Top like utility for disk I/O. <code>iotop</code> http://guichaz.free.fr/iotop/   nload application Monitor network traffic and bandwidth usage in real time. <code>nload</code> http://www.roland-riegel.de/nload/   vnstat application Network traffic monitor for that keeps a log of network traffic for the selected interface(s). <code>vnstat</code> http://humdi.net/vnstat/   nethogs application Small 'net top' tool that groups bandwidth by process. <code>nethogs</code> https://github.com/raboof/nethogs   ngrok application Secure tunnels to localhost. <code>ngrok</code> https://ngrok.com/   ufw application UFW, or Uncomplicated Firewall, is a front-end to iptables. <code>ufw</code> https://launchpad.net/ufw   fail2ban application Ban hosts that cause multiple authentication errors. <code>fail2ban</code> http://www.fail2ban.org   speedtest-cli application Command line interface for testing internet bandwidth using speedtest.net <code>speedtest</code> https://github.com/sivel/speedtest-cli   Rclone application \"rsync for cloud storage\". <code>rclone</code> https://rclone.org/   tree application Displays an indented directory tree, in color. <code>tree</code> http://mama.indstate.edu/users/ice/tree/   ncdu application Disk usage analyzer with an ncurses interface. <code>ncdu</code> https://dev.yorhel.nl/ncdu   GNU Midnight Commander application A visual file manager. <code>mc</code> https://midnight-commander.org/   hostess application Tool for tweaking local DNS by managing your /etc/hosts file. <code>hostess</code> https://github.com/cbednarski/hostess   logrotate application Utility is designed to simplify the administration of log files. <code>logrotate</code> https://fedorahosted.org/logrotate/   npm application Package manager for Node.js modules. <code>npm</code> https://www.npmjs.com/   frontail application Node.js application for streaming logs to the browser, like a tail -F with a UI. <code>frontail</code> https://github.com/mthenw/frontail   revoke_certs.sh script Revoke all of the SSL certifications for your domain <code>/opt/scripts/nginx/revoke_certs.sh</code> https://github.com/Cloudbox/Cloudbox/wiki/Revoking-SSL-Certificates ; Credit: https://github.com/desimaniac   certbot application Fetches and revokes certificates from Let\u2019s Encrypt. Used by revoke_certs.sh. <code>certbot</code> https://certbot.eff.org/   TorrentCleanup.py script Cleans up extracted media files in Rutorrent's downloads folder. Sonarr / Radarr Credit: https://github.com/l3uddz","title":"Overview"},{"location":"reference/saltbox-tools/#details","text":"<p>-Work in progress-</p>","title":"Details"},{"location":"reference/saltbox-tools/#torrent-cleanup-script","text":"<p>TorrentCleanup.py has been explained in the Sonarr section, but in a nutshell, sonarr/radarr launches this script if you set it up, and it will scan the folder of the file that was imported, if rars exist, delete the file that was imported. this is useful for torrent sites that allow rars, as it will only leave you with the imported file (before its uploaded to google) and just the rars for seeding, instead of also leaving the extracted file.</p>","title":"Torrent Cleanup Script"},{"location":"reference/saltbox-tools/#ncdu","text":"<p>( <code>cd / &amp;&amp; sudo ncdu -x</code>)</p>","title":"NCDU"},{"location":"reference/saltbox-tools/#frontail-view-logs-over-http","text":"<p>[[frontail|https://github.com/mthenw/frontail]] is a Node.js application for streaming logs to the browser (basically a tail -F with an UI).</p> <p>This is useful in cases you need help and need to show someone from slack support channels your logs. You can mask your IP using ngrok (more on that later).</p> <p>Steps to do so are as follows:</p>","title":"Frontail - view logs over http"},{"location":"reference/saltbox-tools/#base-command","text":"<pre><code>frontail --ui-highlight --ui-highlight-preset /opt/scripts/frontail/frontail_custom_preset.json --theme dark --user seed --password seed &lt;path of log file&gt; &amp;\n</code></pre> <ul> <li> <p>You may change the user and password.</p> </li> <li> <p>The <code>&amp;</code> at the end sends it to the background.</p> </li> <li> <p>You can now see this log at http://serveripaddress:9001.</p> </li> <li> <p>To specify another port, just add: <code>--port &lt;port&gt;</code></p> </li> </ul>","title":"Base command"},{"location":"reference/saltbox-tools/#to-create-an-alias-for-this","text":"<p>Edit ~/.bashrc file and add the following (you may change the user and password): <pre><code>## custom aliases\nalias ftail='frontail --ui-highlight --ui-highlight-preset /opt/scripts/frontail/frontail_custom_preset.json --theme dark --user seed --password seed '\n</code></pre></p> <p>You can now use:</p> <pre><code>ftail --port &lt;port number&gt; &lt;log path&gt; &amp;\n</code></pre>","title":"To create an alias for this:"},{"location":"reference/saltbox-tools/#to-quit-the-frontail","text":"<pre><code>pkill -f frontail\n</code></pre>","title":"To quit the frontail"},{"location":"reference/saltbox-tools/#examples","text":"","title":"Examples:"},{"location":"reference/saltbox-tools/#plex-autoscan","text":"<pre><code>frontail --port 9001 --ui-highlight --ui-highlight-preset /opt/scripts/frontail/frontail_custom_preset.json --theme dark --user seed --password seed /opt/plex_autoscan/plex_autoscan.log &amp;\n</code></pre> <p>or via alias...</p> <pre><code>ftail --port 9001 /opt/plex_autoscan/plex_autoscan.log &amp;\n</code></pre> <p>or via docker...</p> <pre><code>docker run --restart=always --name \"frontail_plex_autoscan\" -d -p 9001:9001 -v /opt/plex_autoscan:/logs -v /opt/scripts/frontail/frontail_custom_preset.json:/preset/custom.json mthenw/frontail --ui-highlight  --ui-highlight-preset /preset/custom.json --theme dark --user &lt;user&gt; --password &lt;pass&gt; /logs/plex_autoscan.log\n</code></pre> <p>Log: http://serveripaddress:9001</p>","title":"Plex Autoscan"},{"location":"reference/saltbox-tools/#cloudplow-log","text":"<pre><code>frontail --ui-highlight --port 9002 --ui-highlight-preset /opt/scripts/frontail/frontail_custom_preset.json --theme dark --user seed --password seed /opt/cloudplow/cloudplow.log &amp;\n</code></pre> <p>Log: http://serveripaddress:9002</p> <p>or via alias...</p> <pre><code>ftail --port 9002  /opt/cloudplow/cloudplow.log &amp;\n</code></pre> <p>or via docker...</p> <pre><code>docker run --restart=always --name \"frontail_cloudplow\" -d -p 9002:9001 -v /opt/cloudplow:/logs -v /opt/scripts/frontail/frontail_custom_preset.json:/preset/custom.json mthenw/frontail --ui-highlight  --ui-highlight-preset /preset/custom.json --theme dark --user &lt;user&gt; --password &lt;pass&gt; /logs/cloudplow.log\n</code></pre> <p>Log: http://serveripaddress:9002</p>","title":"Cloudplow log"},{"location":"reference/saltbox-tools/#use-ngrok-to-hide-your-ip","text":"<p>If you want to share your log with someone (forums, slack, etc), but don't want to reveal your IP address, you can use ngrok to hide your IP address.</p> <pre><code>ngrok http &lt;port&gt;\n</code></pre> <p>It will show you something like this...</p> <p></p> <p>You can now use the <code>http://XXXXXXXX.ngrok.io</code> address to share your log. This will be active as long as ngrok is running. To cancel, <code>ctrl-c</code>.</p>","title":"Use ngrok to hide your IP"},{"location":"reference/server/","text":"","title":"Server"},{"location":"reference/server/#server","text":"","title":"Server"},{"location":"reference/server/#getting-a-server","text":"<p>About the requirements:</p> <p>You will need a dedicated server, from a server provider (e.g. Hetzner, kimsufi, OVH, etc), installed with Ubuntu Server 20.04.</p> <p>Typically this server is remote to you; you can install on a home server, keeping in mind some home server considerations</p> <p>Best results are seen with an actual dedicated server, not a VPS like those available from Linode, Vultr, or the like.  Linodes, Vultr \"Cloud Compute\", Hetzner \"Cloud Servers\", and probably others like them, in particular, are known to not work in at least one significant way; NZBGet reports 0 available disk space while Sonarr, Radarr, and tools like <code>df</code> and <code>du</code> report disk space as expected.</p> <p>A commonly-asked question is \"can I run saltbox on this server?\"</p> <p>You will need root access to install Saltbox.</p> <p>The server should be a completely fresh OS install. Do not try to install any dependencies on your own, Saltbox will do that for you. </p> <p>Saltbox only supports x64 (i.e. Intel or AMD 64) machines. ARM based hardware [such as the Raspberry Pi] is not supported.</p> <p>Get a server with at least 100GB+ of hard disk space. Even though media is uploaded to the cloud, there is still a need local storage for things like app data and backups. </p> <p>Practically, you should have more like 500GB of space available at a minimum.</p> <p>Cloudplow's default folder size threshold, to upload media to the cloud, is set at 200GB. If you want to lower that, you can find details here</p> <p>If you are planning to use Usenet, SSD should be considered required, and NVME highly recommended.  Usenet is extremely disk I/O intensive.</p> <p>If you are planning to use torrents, you should have much more disk space than that available for seeding.  Your seeding torrents will not be moved to your cloud storage; they will consume local disk space as long as they are seeding. </p> <p>If you are installing as a Feederbox/Mediabox setup rather than the all-in-one Saltbox, the disk requirements change a bit. Downloading drives disk requirements on the Feederbox [as discussed above] and primarily the Plex/Emby metadata drives the disk requirements on the Mediabox.  Depending on the size of your library, that metadata can be quite large.</p>","title":"Getting a Server"},{"location":"reference/server/#home-server-considerations","text":"<p>If you are setting this up on a home server, verify, before installing Saltbox:</p> <ol> <li>Make sure your ISP doesn't block ports 80 and 443 [if your ISP blocks these ports, it won't work.]</li> <li>Make sure that your router supports hairpin NAT [if this isn't supported, you won't be able to access apps via subdomain from inside your network]</li> <li>Open the relevant ports (eg <code>80</code>, <code>443</code>, etc) in your router/firewall and forward them to the IP of the box on which you want to install Saltbox, before installing Saltbox.</li> <li>Point your domain at your home IP and configure some dynamic DNS software to keep it updated.  Saltbox has a dynamic dns client available [it's not installed by default], but there are many ways to set this up.  Make sure that DNS has propagated and your domain returns your home IP via <code>ping</code> or something like it, before installing Saltbox.</li> <li>Review the notes about local storage if you're not planning to use cloud storage.</li> </ol>","title":"Home Server considerations"},{"location":"reference/server/#tips","text":"","title":"Tips"},{"location":"reference/server/#ubuntu-2004","text":"<ul> <li>If you get an option like below, select choose <code>ubuntu-2004-focal-64-minimal</code>.</li> </ul> <p></p> <ul> <li>Install OpenSSH server if asked. </li> </ul>","title":"Ubuntu 20.04"},{"location":"reference/server/#partitioning","text":"<ul> <li> <p>If you have multiple hard drives on the server (eg. 2 x 4 TB), put them in RAID 0 to maximize space and speed (you don't need redundancy as you can schedule backups of Saltbox).</p> </li> <li> <p>Set all available space to <code>/</code> (remove <code>/home</code> and <code>/data</code> partitions).</p> </li> <li> <p>Leave ample space in <code>/boot</code> (e.g. 2+ GB).</p> </li> <li> <p>putting the <code>/opt</code> directory on a <code>btrfs</code> partition can dramatically reduce the amount of time your containers are down during backup.</p> </li> </ul> <p>Examples:</p> Online.netOVHHetzner   <p></p>   <p></p> <p></p>   <ul> <li> <p>Hetzner installimage      <pre><code># Hetzner Online GmbH - installimage\n#\n# This file contains the configuration used to install this\n# system via installimage script. Comments have been removed.\n#\n# More information about the installimage script and\n# automatic installations can be found in our wiki:\n#\n# http://wiki.hetzner.de/index.php/Installimage\n#\n\nDRIVE1 /dev/nvme0n1\nDRIVE2 /dev/nvme1n1\nSWRAID 1\nSWRAIDLEVEL 0\nHOSTNAME sb.domain.com\nPART /boot  ext4     512M\nPART lvm    vg0       all\nLV vg0   swap   swap      swap         8G\nLV vg0   root    /     ext4      all\nIMAGE /root/.oldroot/nfs/install/../images/Ubuntu-2004-focal-64-minimal.tar.gz\n</code></pre></p> </li> <li> <p>Hetzner installimage (with a separate 250G partition for <code>/opt</code> utilizing BTRFS for snapshot backups)</p> <pre><code># Hetzner Online GmbH - installimage\n#\n# This file contains the configuration used to install this\n# system via installimage script. Comments have been removed.\n#\n# More information about the installimage script and\n# automatic installations can be found in our wiki:\n#\n# http://wiki.hetzner.de/index.php/Installimage\n#\n\nDRIVE1 /dev/nvme0n1\nDRIVE2 /dev/nvme1n1\nSWRAID 1\nSWRAIDLEVEL 0\nHOSTNAME sb.domain.com\nPART /boot  ext4     512M\nPART lvm    vg0       all\nLV vg0   swap   swap      swap         8G\nLV vg0   opt   /opt     btrfs         250G\nLV vg0   root    /     ext4      all\nIMAGE /root/.oldroot/nfs/install/../images/Ubuntu-2004-focal-64-minimal.tar.gz\n</code></pre> </li> </ul>","title":"Partitioning:"},{"location":"reference/subdomain/","text":"<p>Setup instructions are separated based on the DNS Provider you use. </p>","title":"Subdomains"},{"location":"reference/subdomain/#cloudflare","text":"<p>Saltbox will automatically add subdomain on Cloudflare and point it to the correct IP address. </p> <p>Note 1: Make sure the Cloudflare API Key is filled in [[settings.yml|Install: Settings]]) and the e-mail address matches the one you have in your account profile. </p> <p>Note 2: There may be some subdomains that you have to add in yourself if Saltbox doesn\u2019t so it for you, such as the Saltbox type ones (eg <code>saltbox</code>, <code>feederbox</code>, <code>mediabox</code>). </p>","title":"Cloudflare"},{"location":"reference/subdomain/#other-domain-hosting-sites","text":"","title":"Other Domain Hosting Sites"},{"location":"reference/subdomain/#saltbox-install-type","text":"","title":"Saltbox Install Type"},{"location":"reference/subdomain/#allows-wildcards","text":"<p>You don't need to do anything.</p>","title":"Allows Wildcards"},{"location":"reference/subdomain/#does-not-allow-wilcards","text":"<p>You will need to add the subdomain via your domain's DNS provider's website.</p>","title":"Does Not Allow Wilcards"},{"location":"reference/subdomain/#mediabox-feederbox-install-type","text":"<p>You will need to add the subdomain via your domain's DNS provider's website.</p> <p>Make sure you use the correct IP address (Mediabox IP or Feederbox IP).</p>","title":"Mediabox / Feederbox Install Type"},{"location":"reference/usenet-torrent/","text":"<p>Probably, you're setting this up because you're planning to download media.</p> <p>To do this, there are requirements dependings on which method[s] you choose to download your media. It can either be Usenet, Torrents, or both.</p>","title":"Usenet vs Bittorrent"},{"location":"reference/usenet-torrent/#i-usenet","text":"<p>If you plan on using Usenet (i.e. Newsgroups) with Saltbox, you'll need 2 things: a Usenet provider and a Usenet indexer. We recommend you have multiple indexers (and even multiple providers) to better your chances of finding/downloading media.</p>","title":"i. Usenet"},{"location":"reference/usenet-torrent/#ii-bittorrent","text":"<p>If you plan on using torrents with Saltbox, we recommend you have access to a private torrent tracker as most servers don't allow public ones. However, if you still want to use public torrent trackers with Saltbox, you are free to do so.  You will need to make some changes to the configuration TODO ADD LINK TO FAQ to allow access to public trackers, as they are blocked by default.</p>","title":"ii. BitTorrent"},{"location":"saltbox/backup/backup/","text":"<p>With Saltbox you can either run a backup task manually or schedule it to run automatically.</p>","title":"Backup"},{"location":"saltbox/backup/backup/#manual-backup","text":"<p>Info</p> <p>This step assumes you have completed the configuration of the <code>backup_config.yml</code> in the configuration step.</p>  Without ScreenWith Screen   <pre><code>sb install backup\n</code></pre>   <pre><code>screen -dmS saltbox-backup sb install backup\n</code></pre> <pre><code>screen -r\n</code></pre> <pre><code>CTRL A + D\n</code></pre>","title":"Manual Backup"},{"location":"saltbox/backup/backup/#scheduled-backup","text":"<p>Info</p> <p>This step assumes you have completed the configuration of the <code>backup_config.yml</code> in the configuration step.</p>  Have Saltbox configure cronConfigure cron manually   <pre><code>sb install set-backup\n</code></pre>   <pre><code>crontab -e\n</code></pre> <pre><code>0 4 * * * sudo PATH='/usr/bin:/bin:/usr/local/bin' env ANSIBLE_CONFIG='/srv/git/saltbox/ansible.cfg' '/usr/local/bin/ansible-playbook' '/srv/git/saltbox/backup.yml' &gt;&gt; '/home/seed/logs/saltbox_backup.log' 2&gt;&amp;1\n</code></pre> <p>Remember to edit the seed username if you changed the Saltbox user in the <code>accounts.yml</code>.</p> <p>Visit crontab.guru for help with the scheduling format.</p>","title":"Scheduled Backup"},{"location":"saltbox/backup/restore/","text":"","title":"Restore"},{"location":"saltbox/backup/restore/#dependencies","text":"<p>Start by installing dependencies.</p> curlwgetcurl (verbose)wget (verbose)   <pre><code>curl -sL https://install.saltbox.dev | sudo -H bash; cd /srv/git/saltbox\n</code></pre>   <pre><code>wget -qO- https://install.saltbox.dev | sudo -H bash; cd /srv/git/saltbox\n</code></pre>   <pre><code>curl -sL https://install.saltbox.dev | sudo -H bash -s -- -v; cd /srv/git/saltbox\n</code></pre>   <pre><code>wget -qO- https://install.saltbox.dev | sudo -H bash -s -- -v; cd /srv/git/saltbox\n</code></pre>    <p>Then retrieve the configuration files from a backup.</p>","title":"Dependencies"},{"location":"saltbox/backup/restore/#using-restore-service","text":"curlwget   <pre><code>curl -sL https://restore.saltbox.dev | bash -s 'USERNAME' 'PASSWORD' # (1)\n</code></pre> <ol> <li> <p>Use the username and password defined for the service when last backup was executed.</p> <p>Must wrap the username and password in quotes.</p> </li> </ol>   <pre><code>wget -qO- https://restore.saltbox.dev | bash -s 'USERNAME' 'PASSWORD' # (1)\n</code></pre> <ol> <li> <p>Use the username and password defined for the service when last backup was executed.</p> <p>Must wrap the username and password in quotes.</p> </li> </ol>    <p>Then run <code>preinstall</code> which will setup the user account and a few other dependencies for the restore.</p> <pre><code>sb install preinstall\n</code></pre>  <p>Info</p> <p>From this point you'll want to make sure you run commands as the user specified in the accounts.yml</p>  <p>Start the restore process.</p> <pre><code>sb install restore\n</code></pre> <p>Once succesfully completed you can now follow the installation guide from this step.</p>","title":"Using Restore Service"},{"location":"saltbox/backup/restore/#without-restore-service","text":"<p>Retrieve the following configuration files from your backup manually and place them in <code>/srv/git/saltbox</code>:</p> <ul> <li>accounts.yml</li> <li>settings.yml</li> <li>adv_settings.yml</li> <li>backup_config.yml</li> <li>rclone.conf</li> <li>localhost.yml (if present)</li> </ul> <p>Then run <code>preinstall</code> which will setup the user account and a few other dependencies for the restore.</p> <pre><code>sb install preinstall\n</code></pre>  <p>Info</p> <p>From this point you'll want to make sure you run commands as the user specified in the accounts.yml</p>  <p>Start the restore process.</p> <pre><code>sb install restore\n</code></pre> <p>Once succesfully completed you can now follow the installation guide from this step.</p>","title":"Without Restore Service"},{"location":"saltbox/backup/settings/","text":"<p>The configuration file for backup/restore is called <code>backup_config.yml</code> and is located in <code>/srv/git/saltbox</code></p> <pre><code>---\nbackup:\n  local:\n    enable: true # (1)\n    destination: /mnt/local/Backups/Saltbox # (2)\n  rclone:\n    enable: true # (3)\n    destination: google:/Backups/Saltbox # (4)\n  rsync:\n    enable: false # (5)\n    destination: rsync://somehost.com/Backups/Saltbox # (6)\n    port: 22 # (7)\n  cron:\n    cron_time: weekly # (8)\n    enable: no # (9)\n  restore_service:\n    user: # (10)\n    pass: # (11)\n  misc:\n    snapshot: true # (12)\n</code></pre> <ol> <li> <p>Toggle for keeping a local copy of the backup.</p> <p>Options are: <code>true</code> or <code>false</code></p> </li> <li> <p>Path used for the local backups.</p> </li> <li> <p>Toggle for using Rclone remote backup storage.</p> <p>Options are: <code>true</code> or <code>false</code></p> </li> <li> <p>Path used for the Rclone remote. Backups outside of the most recent one will be located in the <code>archived</code> folder.</p> <p>Make sure that this path is unique if you run multiple instances of Saltbox.</p> </li> <li> <p>Toggle for using Rsync backups.</p> <p>Options are: <code>true</code> or <code>false</code></p> </li> <li> <p>Path used for the Rsync backups.</p> </li> <li> <p>Port used by rsync on the target server.</p> </li> <li> <p>Schedule for when the backup task will be executed.</p> <p>Options are: <code>reboot</code>, <code>yearly</code>, <code>annually</code>, <code>monthly</code>, <code>weekly</code>, <code>daily</code>, <code>hourly</code>.</p> <p>Should you desire more granular control over the schedule you can edit the crontab for the Saltbox user once setup.</p> </li> <li> <p>Toggle for enabling automatic backups.</p> <p>Options are: <code>no</code> or <code>yes</code></p> <p>Depending on the option set here the cron entry created by Saltbox will be added, removed or modified.</p> </li> <li> <p>Username used for the restore service.</p> <p>Has to be unique across all users of the service. Try sticking with a url for the server <code>box.domain.tld</code> unique to each server for something easily remembered.</p> <p>Usernames are hashed before requests are sent to the restore service.</p> </li> <li> <p>Password used encrypt/decrypt the configuration files. </p> <p>Only used on the client side in scripts.</p> </li> <li> <p>Toggle for BTRFS snaphots.</p> <p>Options are: <code>true</code> or <code>false</code></p> <p>Requires BTRFS on <code>/</code> or <code>/opt</code></p> </li> </ol> <p>IMPORTANT:</p> <p>These values:</p> <p><code>yml   restore_service:     user: #      pass: #</code></p> <p>SHOULD NOT BE YOUR SERVER ACCOUNT CREDENTIALS.</p> <p>These are an arbitrary username/password that you make up which are used ONLY with this backup/restore service.  They are used to encrypt your config files before they are placed on the saltbox restore server, and then in the restore command that retrieves the backup for decryption.  They are not sent or stored anywhere else.  If they are not filled in, then your config files will not be sent to the saltbox restore service.</p>","title":"Configuration"},{"location":"saltbox/basics/accessing_apps/","text":"<p>Note 1: After the initial setup, it will take a a while for the SSL certificates to propagate. A side effect of this will be that certain domains were redirect to other apps (e.g. sonarr.yourdomain.com -&gt; nzbget.yourdomain.com). Just give it a bit of time and this will correct itself.</p> <p>Note 2: If pages don't load at all, make sure you've set up your domain properly and also checkout the FAQ.</p>","title":"Accessing Saltbox Apps"},{"location":"saltbox/basics/accessing_apps/#default-apps","text":"<p>Saltbox apps will be accessed via appname.yourdomain.com (see table below).</p>    App  Name with domain without domain     Jackett https://jackett.yourdomain.com http://server_ip:9117   Lidarr https://lidarr.yourdomain.com http://server_ip:8686   NZBGet https://nzbget.yourdomain.com http://server_ip:6789   NZBHydra2 https://nzbhydra2.yourdomain.com http://server_ip:5076   Organizr https://organizr.yourdomain.com http://server_ip:port   Overseerr https://overseerr.yourdomain.com http://server_ip:5055   Plex https://plex.yourdomain.com http://server_ip:32400   WebTools for Plex https://plex-webtools.yourdomain.com http://server_ip:33400   Portainer https://portainer.yourdomain.com http://server_ip:9000   Radarr https://radarr.yourdomain.com http://server_ip:7878   ruTorrent https://rutorrent.yourdomain.com http://server_ip:port   Sonarr https://sonarr.yourdomain.com http://server_ip:8989   Tautulli https://tautulli.yourdomain.com http://server_ip:8181","title":"Default Apps"},{"location":"saltbox/basics/accessing_apps/#additional-apps","text":"<p>Coming soon.</p> <p>Next, let's discuss Saltbox' default paths.</p>","title":"Additional Apps"},{"location":"saltbox/basics/basics/","text":"","title":"Basics"},{"location":"saltbox/basics/basics/#what-is-saltbox","text":"<ul> <li> <p>Saltbox is an Ansible and docker based solution for rapidly deploying a cloud media server on any x64 Ubuntu Server.</p> </li> <li> <p>Primary functions are: the automatic acquisition of media, storing that media on the cloud, and being able to  play it back from anywhere and from any device.</p> </li> <li> <p>NOTE: Saltbox does not have a dashboard or GUI of its own. All Saltbox-specific setup and commands are done on the linux command-line.</p> </li> </ul>","title":"What is Saltbox?"},{"location":"saltbox/basics/basics/#why-use-saltbox","text":"","title":"Why use Saltbox?"},{"location":"saltbox/basics/basics/#custom-domains","text":"<ul> <li>Have your server setup behind your own domain, securely (e.g. https://apps.yourdomain.com).</li> </ul>","title":"Custom Domains"},{"location":"saltbox/basics/basics/#fast-deployment","text":"<ul> <li>Have a system running in minutes with minimal input (a full server setup from scratch within minutes.</li> </ul>","title":"Fast Deployment"},{"location":"saltbox/basics/basics/#docker-based-applications","text":"<ul> <li> <p>Docker containers keep your apps isolated from each other - no more conflicts between apps.</p> </li> <li> <p>Docker containers keep your system tidy since none of the apps' files (executables and dependencies) are stored outside of the container.</p> </li> <li> <p>Quickly install and uninstall apps.</p> </li> </ul>","title":"Docker-Based Applications"},{"location":"saltbox/basics/basics/#cloud-storage","text":"<ul> <li>Store media on cloud storage to save on local drive space.</li> </ul>","title":"Cloud Storage"},{"location":"saltbox/basics/basics/#can-choose-your-preferred-media-server-application","text":"<ul> <li>You can decide whether to use Plex or Emby.</li> </ul>","title":"Can Choose Your Preferred Media Server Application"},{"location":"saltbox/basics/basics/#custom-server-deployment","text":"<ul> <li>You can deploy Saltbox on an all-in-one server, for downloading and streaming.</li> </ul> <p>or</p> <ul> <li>You can deploy Saltbox between two servers: a Mediabox, as streaming server, and a Feederbox, as a downloading server.</li> </ul>","title":"Custom Server Deployment"},{"location":"saltbox/basics/basics/#secure","text":"<ul> <li>Saltbox uses secure HTTPS provided by Let's Encrypt SSL certificates or ZeroSSL.</li> </ul>","title":"Secure"},{"location":"saltbox/basics/basics/#easy-backup-and-restore","text":"<ul> <li>Configuration and data files for all key applications are conveniently stored in /opt, which makes backup so easy. Easily pack up your server and move to another one with Saltbox's built-in Backup.</li> </ul>","title":"Easy Backup and Restore"},{"location":"saltbox/basics/basics/#how-does-saltbox-function","text":"<p>Sonarr manages downloading your favorite TV Shows and Radarr manages downloading your favorite movies. Both use either Usenet (via NZBGet) and/or Torrents (via ruTorrent) to do this.[1] [2]</p> <p>Once the downloads are complete, Sonarr &amp; Radarr will move [or copy in the case of torrents] these downloads to your server's <code>/mnt/local/Media/</code> folder[3]  and send a notification to Plex Autoscan.</p> <p>Plex AutoScan will, in turn, tell Plex to scan for the newly downloaded TV Show or Movie, by only scanning the specific season or movie folder. This will</p> <ul> <li>make the media appear in Plex sooner than what a full library scan would have been able to do, and</li> <li>reduce the chances of Cloud Storage API bans for excessive activity.</li> </ul> <p>Cloudplow will eventually[4]  move everything[5]  from <code>/mnt/local/Media/</code> to a folder named <code>Media</code> on the remote cloud storage, thereby reducing the storage used on the (local) server.</p> <p>During this migration, the media files will continue to be accessible to Media Servers (e.g. Plex) because the remote cloud storage (e.g. Google Drive) will be mounted on to the server as if it were a local drive. This is accomplished with an Rclone VFS mount pointing to the cloud storage, and a union of that mount with the server\u2019s own local storage (accomplished via <code>mergerfs</code>).</p> <p></p>  <p>1 Some of the applications above can be replaced with similar apps. </p> <p>2 If you want to use Torrents, it is recommended to be a member of a private tracker vs using public ones. If you want to to use Usenet, you will need to purchase Usenet provider service (or multiple services) and also be a member of one or more Usenet indexers. </p> <p>3 The move to <code>/mnt/local/Media</code> is indirect; Radarr/Sonarr are using <code>/mnt/unionfs/Media</code>, and they move the file there, however,  <code>/mnt/local</code> is the only writeable part of the mergerfs [for the purpose of  creating new files], so the newly-written files will be placed in <code>/mnt/local</code>. </p> <p>4 By default, Cloudplow will check every half hour to see if there is 200GB of data staged in <code>/mnt/local</code>; if there is, all that data is pushed to your Google Drive.  This threshold can be adjusted as needed in the Cloudplow config. </p> <p>5 There is presently a 750GB/day upload limitation on Google accounts.  The standard Saltbox setup will describe setting up a Google Drive remote pointed at your My Drive.  This limit can be eliminated by cycling through a set of service accounts [each of which can upload 750GB] to upload to one or more Shared Drives [aka Teamdrives].  See Tip44 Doc for details.  </p> <p>Next, let's discuss the Prerequisites for Saltbox installation.</p>","title":"How does Saltbox function ?"},{"location":"saltbox/basics/install_types/","text":"<p>Saltbox consists of a \"Core\" with various extra components added onto that core.  At a minimum, you need to install \"core\" to do anything further with the Saltbox infrastructure.</p>     <code>core</code> <code>saltbox</code> <code>mediabox</code> <code>feederbox</code>     System Tweaks       Saltbox MOTD       Common Tools and Tasks       Docker       Rclone       Mounts: MergerFS       Mounts: Rclone VFS       Scripts       Traefik (Docker)       Authelia (Docker)       Plex (Docker)       Tautulli (Docker)       Overseerr  (Docker)       Plex Autoscan (Media Scanner Helper Script)       Portainer (Docker)       Organizr (Docker)       Cloudplow (Media Uploader)       NZBGet (Docker)       rTorrent / ruTorrent (Docker)       Jackett (Docker)       NZBHydra 2 (Docker)       Sonarr (Docker)       Radarr (Docker)       Lidarr (Docker)        <p>Next, let's move on to Installing Saltbox.</p>","title":"Saltbox Install Types"},{"location":"saltbox/basics/paths/","text":"","title":"Saltbox Paths"},{"location":"saltbox/basics/paths/#general-info","text":"<p>It is recommended to assign all your disk space to <code>/</code>, as all of your imported media and app data will be saved to <code>/mnt/local/</code> and <code>/opt/</code>,  respectively.  This allows your application metadata and your staged media to  make the most use of your available disk space without worrying about partitioning.</p> <p>Note 1: ALL folders/paths mentioned below, and elsewhere on the wiki, are CASE SENSITIVE (e.g. Google Drive: <code>Media</code> not <code>media</code>, <code>Movies</code> not <code>movies</code>, <code>TV</code> not <code>tv</code>; Plex Requests: <code>/logs</code> not <code>/Logs</code>, etc). This is important, or else apps like Plex, Sonarr, and Radarr will not be able find your media.</p> <p>Note 2: This wiki uses <code>~/</code> interchangeably with <code>/home/&lt;username&gt;/</code>, which is defined as <code>/home/{{user}}/</code> in Ansible syntax (as used in settings.yml). So if your user name was <code>seed</code>, your <code>~/</code> path would be <code>/home/seed/</code>.</p> <p>For this reason it is important that you run commands as the appropriate user as you go through the wiki.</p>","title":"General Info"},{"location":"saltbox/basics/paths/#google-drive-paths","text":"<pre><code>Media\n\u251c\u2500\u2500 Movies\n\u251c\u2500\u2500 Music\n\u2514\u2500\u2500 TV\n</code></pre> <p></p>    Path  <pre>                 </pre> Description  <pre>                                                                                              </pre>     <code>/Media/</code> Location of all your media folders.   <code>/Media/Movies/</code> Location of all your movies (folder format: <code>/Media/Movies/Movie Name (year)/movie file.ext</code>).   <code>/Media/Music/</code> Location of all your music.   <code>/Media/TV/</code> Location of all your TV shows (folder format: <code>/Media/TV/TV Show Name/Season 00/episode file.ext</code>).    <p>Note: If you would like to customize your Plex libraries differently, see Customizing Plex Libraries.</p>","title":"Google Drive Paths"},{"location":"saltbox/basics/paths/#local-paths","text":"<pre><code>mnt\n\u251c\u2500\u2500local\n|  \u2514\u2500\u2500 Media\n\u251c\u2500\u2500remote\n|  \u2514\u2500\u2500 Media\n\u2514\u2500\u2500unionfs\n   \u2514\u2500\u2500 Media\n</code></pre>","title":"Local Paths"},{"location":"saltbox/basics/paths/#media","text":"<pre>                 </pre> Path <pre>                                                                                                 </pre> Description     <code>/mnt/local/Media/</code> Location of media stored on the server.  This is the local part of <code>/mnt/unionfs/Media/</code>.   <code>/mnt/remote/Media/</code> Location of media stored on Google Drive (mounted by rclone).   <code>/mnt/unionfs/Media/</code> Combined folder of local media (<code>/mnt/local/Media/</code>) and online media (<code>/mnt/remote/Media/</code>).  This is the folder that Plex, Sonarr, and Radarr read when scanning for media.    <p>Note: Make sure <code>/mnt/local/</code> has enough space to store the imported media (before cloudplow is able to move it to Google Drive).</p>","title":"Media"},{"location":"saltbox/basics/paths/#cloudplow","text":"Path<pre>                 </pre> Description <pre>                 </pre>     <code>/mnt/local/Media/</code> Location of media stored on the server.  Size of this path is checked periodically (default 30 min). When the folder size reaches its target (default 200GB), media files are moved off/uploaded to the cloud, freeing up local disk space.    <p>Note: For more info, see the Cloudplow page.</p>","title":"Cloudplow"},{"location":"saltbox/basics/paths/#docker-paths","text":"<p>The Dockerized app (e.g. Plex) will \"see\" the Docker Path, but that path will actually be the Host Path on the server.</p> <p>By default, NZB and Torrent downloads are stored in <code>/mnt/local/downloads/nzbs/</code> and <code>/mnt/local/downloads/torrents/</code>, respectively. However, this can be changed to point elsewhere (e.g. a second hard drive) by editing the settings.yml file. But regardless of the download location chosen, the Docker Path will always be the same.</p> <p>Note: It is advised to leave at least 100GB free on <code>/opt</code> for the storage of Docker data.</p>","title":"Docker Paths"},{"location":"saltbox/basics/paths/#any-container-that-requires-disk-access","text":"Docker Path <pre>                 </pre> Host Path <pre>                 </pre> Description <pre>                 </pre>     <code>/mnt</code> <code>/mnt</code> Provides access to all standard mounted storage.    <p>Every container sees any path inside <code>/mnt</code> the same as the host and same as any other container.</p> <p>That means that no path translation is required from context to context.  If nzbget reports a download at <code>/mnt/unionfs/downloads/...</code> then Radarr will see it in the same place; when Radarr tells Plex-Autoscan [PAS] about it, PAS sees it in that same place; when PAS tells Plex about it, Plex sees it in that same place.</p>","title":"Any container that requires disk access"},{"location":"saltbox/basics/paths/#plex","text":"Docker Path <pre>                 </pre> Host Path <pre>                 </pre> Description <pre>                 </pre>     <code>/mnt/unionfs/Media/Movies/</code> <code>/mnt/unionfs/Media/Movies/</code> Plex reads this for Movies.   <code>/mnt/unionfs/Media/TV/</code> <code>/mnt/unionfs/Media/TV/</code> Plex reads this for TV Shows.   <code>/mnt/unionfs/Media/Music/</code> <code>/mnt/unionfs/Media/Music/</code> Plex reads this for Music.","title":"Plex"},{"location":"saltbox/basics/paths/#sonarr","text":"Docker Path  <pre>                 </pre> Host Path <pre>                                     </pre> Description <pre>                                                                                                                                                             </pre>     <code>/mnt/unionfs/Media/TV/</code> <code>/mnt/unionfs/Media/TV/</code> Sonarr will import to <code>/tv/</code>, which is actually <code>/mnt/unionfs/Media/TV/</code> on host system.   <code>/mnt/unionfs/downloads/nzbs/</code> <code>/mnt/local/downloads/nzbs/</code> (default) NZB downloads folder as set in settings.yml).    For example, when using NZBGet, Sonarr will import from <code>/mnt/unionfs/downloads/nzbs/nzbget/</code>, which is essentially <code>/mnt/local/downloads/nzbs/nzbget/</code> on host system.   <code>/mnt/unionfs/downloads/torrents/</code> <code>/mnt/local/downloads/torrents/</code> (default) Torrent downloads folder as set in settings.yml).    For example, when using ruTorrent, Sonarr will import from <code>/mnt/unionfs/downloads/torrents/rutorrent/</code>, which is essentially <code>/mnt/local/downloads/torrents/rutorrent/</code> on host system.","title":"Sonarr"},{"location":"saltbox/basics/paths/#radarr","text":"Docker Path  <pre>                 </pre> Host Path <pre>                                     </pre> Description <pre>                                                                                                                                                             </pre>     <code>/mnt/unionfs/Media/movies/</code> <code>/mnt/unionfs/Media/Movies/</code> Radarr will import to <code>/movies/</code>, which is actually <code>/mnt/unionfs/Media/Movies/</code> on host system.   <code>/mnt/unionfs/downloads/nzbs/</code> <code>/mnt/local/downloads/nzbs/</code> (default) NZB downloads folder as set in settings.yml).    For example, when using NZBGet, Radarr will import from <code>/mnt/unionfs/downloads/nzbs/nzbget/</code>, which is essentially <code>/mnt/local/downloads/nzbs/nzbget/</code> on host system.   <code>/mnt/unionfs/downloads/torrents/</code> <code>/mnt/local/downloads/torrents/</code> (default) Torrent downloads folder as set in settings.yml).    For example, when using ruTorrent, Radarr will import from <code>/mnt/unionfs/downloads/torrents/rutorrent/</code>, which is essentially <code>/mnt/local/downloads/torrents/rutorrent/</code> on host system.","title":"Radarr"},{"location":"saltbox/basics/paths/#lidarr","text":"Docker Path  <pre>                 </pre> Host Path <pre>                                     </pre> Description <pre>                                                                                                                                                             </pre>     <code>/mnt/unionfs/Media/Music/</code> <code>/mnt/unionfs/Media/Music/</code> Lidarr will import to <code>/music/</code>, which is actually <code>/mnt/unionfs/Media/Music/</code> on host system.   <code>/mnt/unionfs/downloads/nzbs/</code> <code>/mnt/local/downloads/nzbs/</code> (default) NZB downloads folder as set in settings.yml).    For example, when using NZBGet, Lidarr will import from <code>/mnt/unionfs/downloads/nzbs/nzbget/</code>, which is essentially <code>/mnt/local/downloads/nzbs/nzbget/</code> on host system.   <code>/mnt/unionfs/downloads/torrents/</code> <code>/mnt/local/downloads/torrents/</code> (default) Torrent downloads folder as set in settings.yml).    For example, when using ruTorrent, Lidarr will import from <code>/mnt/unionfs/downloads/torrents/rutorrent/</code>, which is essentially <code>/mnt/local/downloads/torrents/rutorrent/</code> on host system.","title":"Lidarr"},{"location":"saltbox/basics/paths/#tautulli","text":"Docker Path  <pre>                 </pre> Host Path <pre>                                                            </pre> Description <pre>                                     </pre>     <code>/logs/</code> <code>/opt/plex/Library/Application Support/Plex Media Server/Logs/</code> Location of the Plex logs used by Tautulli.     <p>Next, let's discuss the inventory system for customization.</p>","title":"Tautulli"},{"location":"saltbox/basics/update/","text":"","title":"Update"},{"location":"saltbox/basics/update/#updating-saltbox","text":"<p>To update Saltbox run:</p> <pre><code>sb update\n</code></pre> <p>This will also upgrade Ansible as needed and migrate the configuration files as additional options are added over time.</p> <p>This updates the saltbox files only;  It does not update your containers.</p> <p>For example, if a new feature is added to saltbox, <code>sb update</code> will get that new feature.  If a new version of Radarr is available, <code>sb update</code> will not update your Radarr to that new version.</p>","title":"Updating Saltbox"},{"location":"saltbox/basics/update/#updating-apps","text":"<p>Generally, to update individual applications, run the tag for that application.  For example,</p> <pre><code>sb install radarr\n</code></pre> <p>This will retrieve the current version of the radarr image and recreate the container, which will update the application version.</p> <p>The same thing happens if you run one of the top-level tags:</p> <pre><code>sb install saltbox\n</code></pre> <p>This will do as above for all the containers installed by the <code>saltbox</code> tag.</p> <p>Next, let's discuss how you will access the applications.</p>","title":"Updating apps"},{"location":"saltbox/install/after/","text":"<p>All the apps are installed and configured, but here are some things you want to set up or do that aren't done automatically:</p> <ol> <li> <p>Harden your SSH server.  There are some tips here, but three simple actions to take are:</p> <ol> <li> <p>Change the default SSH port from 22 to something else.</p> </li> <li> <p>Disable password login and use only SSH keys to authenticate.</p> </li> <li> <p>Disable root login.</p> </li> </ol> </li> <li> <p>Set up scheduled backups. There is no backup enabled automatically, so unless you explicitly set them up, you will be disappointed to find that you don't have a backup when something goes wrong.</p> </li> <li> <p>Take some time to verify disk space usage for the apps.</p> <p>You need local disk space for stuff between download completion and cloudplow moving things into the cloud.  If you don't, for example, set cloudplow's upload thresholds and Nzbget's \"stop downloading\" disk space threshold to meaningful values for your situation, you can get into a situation where cloudplow's not uploading because that threshold hasn't been met and nzbget has stopped because its threshold has been met and everything grinds to a halt.  Alternatively, nzbget just keeps going and runs your disk out of space.</p> <p>You also need a bunch of disk space for the scheduled backups that you just set up to succeed, so be sure to take that into account.</p> <p>Another common \"hidden\" disk space consumer is unfinished or unimported downloads.  If NZBGet downloads something and Radarr can't tell what movie it is, it will just sit consuming disk space.  There is a script you can set up to keep this stuff cleaned up in the user crontab examples.</p> </li> <li> <p>Spend some time working with the system before you start customizing.  A lot of problems are seen when new users rush ahead to install All The Things and customize the system without understanding how things work.  Slow down.  Learn how the thing works, and then make changes in a controlled manner.</p> <p>None of these apps or scripts are sentient, so if they are not doing what you expect, it's almost certainly a configuration problem.</p> </li> <li> <p>Take time to go through some Youtube or other tutorials about:</p> <ol> <li> <p>JSON</p> <p>Many config files are written in JSON, so you need to have a grounding in how JSON works before editing them.  You should know how to edit within the structure of a JSON file, and how to validate a JSON file to figure out how you've broken it.</p> <ol> <li> <p>first \"json tutorial\" result; no endorsement</p> </li> <li> <p>online JSON validator</p> </li> </ol> </li> <li> <p>YAML</p> <p>Many config files are written in YAML, so you need to have a grounding in how YAML works before editing them.</p> <ol> <li> <p>first \"yaml tutorial\" result; no endorsement</p> </li> <li> <p>online YAML validator</p> </li> </ol> </li> <li> <p>Docker</p> <p>Nearly everything is running as a Docker container, so it's helpful to have at least a nodding familiarity with how that works.</p> <ol> <li>first \"docker tutorial\" result; no endorsement</li> </ol> </li> </ol> </li> </ol> <p>Next, let's discuss how updates are done.</p>","title":"After-Install"},{"location":"saltbox/install/install/","text":"<p>If you're migrating from Cloudbox you probably want the Cloudbox migrations instructions</p> <p>If you're migrating from PlexGuide there are some rudimentary notes provided by a user here.  Expansions to those notes would be welcome.</p> <p>Please read through these steps prior to executing any of them, just to get a grounding in what is going to happen through out the process.  It could be that things in later steps inform your decisions in earlier steps.</p> <p>Broadly, the base install consists of six steps:</p> <ol> <li>Installing dependencies</li> <li>Preparing your configuration file(s)</li> <li>Running a pre-install script</li> <li>Configuring your cloud storage</li> <li>Running the install script</li> <li>Configuring installed applications</li> </ol>","title":"Install"},{"location":"saltbox/install/install/#dependencies","text":"curlwgetcurl (verbose)wget (verbose)   <pre><code>curl -sL https://install.saltbox.dev | sudo -H bash; cd /srv/git/saltbox\n</code></pre>   <pre><code>wget -qO- https://install.saltbox.dev | sudo -H bash; cd /srv/git/saltbox\n</code></pre>   <pre><code>curl -sL https://install.saltbox.dev | sudo -H bash -s -- -v; cd /srv/git/saltbox\n</code></pre>   <pre><code>wget -qO- https://install.saltbox.dev | sudo -H bash -s -- -v; cd /srv/git/saltbox\n</code></pre>     <p>Info</p> <p>See here for more information about the dependencies.</p>","title":"Dependencies"},{"location":"saltbox/install/install/#configuration","text":"<p>Make sure you fill out the following configuration files before proceeding. Each file will be located in <code>/srv/git/saltbox</code></p> <p><code>accounts.yml</code></p> <p>To edit [assuming you are still logged in as <code>root</code>]:</p> <pre><code>nano /srv/git/saltbox/accounts.yml\n</code></pre> <p>Contents:</p> <pre><code>---\nuser:\n  name: seed # (1)\n  pass: password123 # (2)\n  domain: testsaltbox.ml # (3)\n  email: your@email.com # (4)\ncloudflare:\n  email: # (5)\n  api: # (6)\nplex:\n  user: # (7)\n  pass: # (8)\n  tfa: no # (9)\ndockerhub:\n  user: # (10)\n  token: # (11)\napprise: # (12)\n</code></pre> <ol> <li> <p>Username that will be created (if it doesn't exist) during the installation and apps that have automatic user configuration.</p> <p>Do not use root.</p> <p>Required.</p> </li> <li> <p>Password used for username account during the installation and apps that have automatic user configuration.</p> <p>Required.</p> </li> <li> <p>Domain that you want to use for the server.</p> <p>If this is left blank, applications will be accessible at IP:PORT instead of via subdomains.</p> </li> <li> <p>Email address used for Let's Encrypt SSL certificates.</p> <p>Required.</p> </li> <li> <p>Email used for the Cloudflare account.</p> </li> <li> <p>Cloudflare Global API Key.</p> </li> <li> <p>Plex.tv username or email address on the account.</p> </li> <li> <p>Plex.tv password for the account.</p> </li> <li> <p>Enable if you want to use the Two Factor Authentication [TFA] compatible Plex account login.</p> </li> <li> <p>Docker Hub account name. Entering these credentials will at least double your image pull capacity from 100 every 6 hours to 200. https://www.docker.com/blog/checking-your-current-docker-pull-rate-limits-and-status/</p> </li> <li> <p>Docker Hub account token</p> </li> <li> <p>apprise url. See https://github.com/caronc/apprise#popular-notification-services for more information.</p> </li> </ol> <p><code>settings.yml</code></p> <p>To edit [assuming you are still logged in as <code>root</code>]:</p> <pre><code>nano /srv/git/saltbox/settings.yml\n</code></pre> <p>Contents:</p> <pre><code>---\ndownloads:\n  nzbs: /mnt/unionfs/downloads/nzbs # (1)\n  torrents: /mnt/unionfs/downloads/torrents # (2)\ntranscodes: /mnt/local/transcodes # (3)\nrclone:\n  version: latest # (4)\n  remote: google # (5)\nshell: bash # (6)\nauthelia:\n  master: yes # (7)\n  subdomain: login # (8)\n</code></pre> <ol> <li> <p>Folder used for usenet downloads.</p> </li> <li> <p>Folder used for torrent downloads.</p> </li> <li> <p>Folder used for temporary transcode files.</p> </li> <li> <p>Rclone version that Saltbox will install.</p> <p>Valid options are latest, beta or a specific version (1.55).</p> </li> <li> <p>Name of the rclone remote that Saltbox will mount by default and use in any automated configuration.</p> <p>Optional - Leave empty to avoid remote mount setup.</p> </li> <li> <p>Shell used by the system. Valid options are bash or zsh.</p> </li> <li> <p>If the current server should have Authelia installed or use one installed elsewhere.</p> </li> <li> <p>Subdomain used for Authelia.</p> <p>Use different values here when using a Mediabox + Feederbox setup if deploying multiple Authelia instances.</p> <p>On a Feederbox where you want to use Authelia on the Mediabox just put in the same subdomain the Mediabox uses for Authelia (master having been set to no on the Feederbox).</p> </li> </ol>  <p>Info</p> <p>See here for more information about these settings.</p>","title":"Configuration"},{"location":"saltbox/install/install/#preinstall","text":"<p>Warning</p> <p>Make sure that you have set up the configuration correctly before proceeding.</p>  <p>This step will create the user account specified in <code>accounts.yml</code>, add it to sudoers, update the kernel, edit GRUB configuration, install Rclone, and reboot the server if needed.</p> <pre><code>sb install preinstall\n</code></pre>  <p>Warning</p> <p>From this point you'll want to make sure you run commands as the user specified in the accounts.yml</p>  <p>If your server did not need to reboot you can run <code>su username</code> to switch user or reconnect to SSH as the newly created user. Everything after this point will assume you are running as the user entered in accounts.yml</p>  <p>Info</p> <p>See here for more information about the preinstall.</p>","title":"Preinstall"},{"location":"saltbox/install/install/#rclone","text":"<p>Saltbox assumes an rclone remote pointed at your google storage named <code>google</code> [as shown in the settings.yml above].</p> <p>You may already have this remote configured or know how to do it if you are coming from a similar setup like Cloudbox or PlexGuide.</p> <p>If not, the process is documented here.</p>","title":"Rclone"},{"location":"saltbox/install/install/#install-saltbox","text":"<p>If you are installing a Feederbox/Mediabox setup, set up the Feederbox first, then add the feeder mount to the mediabox prior to install.</p> SaltboxMediaboxFeederboxCore   <pre><code>sb install saltbox\n</code></pre>   <pre><code>sb install mediabox\n</code></pre>   <pre><code>sb install feederbox\n</code></pre>   <pre><code>sb install core\n</code></pre>     <p>Info</p> <p>See here for more information about the install.</p>","title":"Install Saltbox"},{"location":"saltbox/install/install/#reboot","text":"<p>You're now ready to go through the basic setup for the apps. After rebooting!</p>","title":"Reboot"},{"location":"saltbox/install/install/#app-setup","text":"<p>Go through these one at a time; some of the setups depend on previous setups.</p> <ol> <li>NZBGet</li> <li>ruTorrent</li> <li>NZBHydra2</li> <li>Jackett</li> <li>Plex Media Server</li> <li>Plex Autoscan</li> <li>Sonarr</li> <li>Radarr</li> <li>Lidarr</li> <li>Tautulli</li> <li>Overseerr</li> <li>Portainer</li> <li>Organizr</li> </ol> <p>Next, some tasks to perform after installation is complete.</p>","title":"App Setup:"},{"location":"saltbox/inventory/","text":"<p>Advanced use cases that would normally require editing roles can now be handled through the inventory system instead. </p> <p>Any variables defined in <code>/srv/git/saltbox/roles/&lt;role_name&gt;/defaults/main.yml</code> are available to be overridden by the user in: </p> <p><code>/srv/git/saltbox/inventories/host_vars/localhost.yml</code></p> <p>This implementation avoids git merge conflicts when updating Saltbox.</p> <p>Should you require additional functionality then by all means create an issue on the main repository and we'll look at accommodating it.</p> <p>For example, an excerpt from <code>/srv/git/saltbox/roles/sonarr/defaults/main.yml</code>:</p> <pre><code>################################\n# Basics\n################################\n\nsonarr_name: sonarr\n\n################################\n# Paths\n################################\n\nsonarr_paths_folder: \"{{ sonarr_name }}\"\nsonarr_paths_location: \"{{ server_appdata_path }}/{{ sonarr_paths_folder }}\"\nsonarr_paths_folders_list:\n  - \"{{ sonarr_paths_location }}\"\nsonarr_paths_config_location: \"{{ sonarr_paths_location }}/config.xml\"\n...\n</code></pre> <p>We can see there that Sonarr gets the name \"sonarr\", and that name then flows through to those next four settings.</p> <p>If you wanted to change the name of the Sonarr app to BingBangBoing, you'd add this to <code>/srv/git/saltbox/inventories/host_vars/localhost.yml</code>:</p> <pre><code>sonarr_name: BingBangBoing\n</code></pre> <p>When you next run the <code>sonarr</code> tag, everything that's based off that name will change:</p> <ul> <li>docker container name =&gt; BingBangBoing</li> <li>subdomain =&gt; BingBangBoing.DOMAIN.TLD</li> <li>app data folder =&gt; /opt/BingBangBoing</li> <li>and so on.</li> </ul> <p>A common use for these overrides will be specifying the version of the docker image to be used, so let's see how that's done by looking further down in the defaults file:</p> <pre><code>################################\n# Docker\n################################\n\n# Container\nsonarr_docker_container: \"{{ sonarr_name }}\"\n\n# Image\nsonarr_docker_image_pull: true\nsonarr_docker_image_tag: \"release\"\nsonarr_docker_image: \"hotio/sonarr:{{ sonarr_docker_image_tag }}\"\n</code></pre> <p>We see again the name flowing through down here, but look at <code>sonarr_docker_image_tag: \"release\"</code></p> <p>For Example, for Sonarr, Saltbox will use the docker image <code>hotio/sonarr:release</code> by default.</p> <p>If you wanted to change that to \"nightly\", you'd add this line to <code>/srv/git/saltbox/inventories/host_vars/localhost.yml</code>:</p> <pre><code>sonarr_docker_image_tag: \"nightly\"\n</code></pre> <p>Which would override the default and result in Saltbox using <code>hotio/sonarr:nightly</code> docker image instead.</p>","title":"Inventory"},{"location":"saltbox/inventory/#additional-examples","text":"<pre><code>### Open Specified Ports for the specified container ###\n##### Plex Ports for local access#####\nplex_docker_ports:\n  - \"32400:32400/tcp\"\n  - \"3005:3005/tcp\"\n  - \"8324:8324/tcp\"\n  - \"33400:33400/tcp\"\n  - \"33443:33443/tcp\"\n\n##### Plex Container Variables ####\nplex_docker_image_tag: beta\nplex_open_main_ports: true\nplex_db_cache_size: 30000000\n\n#### Examples of specified container images: ####\nradarr_docker_image_tag: nightly\nsonarr_docker_image_tag: nightly\npetio_docker_image_tag: nightly\n\n#### BW Limiting speeds ####\ntransfer_docker_envs_custom:\n  MAX_UPLOAD_SIZE: \"104857546\"\n\n#### Docker Service Variable ####\ndocker_service_sleep: 0\n</code></pre>","title":"Additional Examples:"},{"location":"saltbox/prerequisites/prerequisites/","text":"","title":"Prerequisites"},{"location":"saltbox/prerequisites/prerequisites/#presumptions","text":"<p>Saltbox presumes you have a basic understanding of Linux, Docker containers, BitTorrent, and Usenet, and are also familiar with Sonarr, Radarr, NZBGet, rTorrent/ruTorrent, and Plex/Emby.</p> <p>The Saltbox setup is all done on the command line in the linux shell.  There is no GUI and there are no plans to add one.  If you want to run Saltbox, you will need to be familiar with Linux.</p> <p>The guides in this wiki are only meant to setup Saltbox specific settings into the various apps that are installed with Saltbox (e.g. Sonarr, Radarr, Plex, etc) and are not meant to be a full setup for, or an introduction to, the workings of these apps. However, you may pick up a few things as you go thru the guides.</p> <p>If you wish to learn more about them in detail, you can easily find a ton of guides for them online (e.g. HTPC Guides, YouTube, etc).</p> <p>There are, broadly, 4 prerequisites to installing Saltbox:</p>  <ul> <li>A Server</li> <li>A Domain Name</li> <li>Cloud Storage</li> <li>A Plex Account</li> <li>Usenet or Bittorrent sources</li> </ul>","title":"Presumptions"},{"location":"saltbox/prerequisites/prerequisites/#server","text":"<p>For best results, the assumed server environment for Saltbox is:</p> <ul> <li>a dedicated remote x64 [Intel or AMD] server [not a VPS],</li> <li>from a server provider like Hetzner, OVH, kimsufi, etc.,</li> <li>freshly installed with Ubuntu Server 20.04,</li> <li>with at least 500GB of disk space, and</li> <li>allowing root access</li> </ul> <p>See here for more information about server requirements.</p>","title":"Server"},{"location":"saltbox/prerequisites/prerequisites/#domain","text":"<p>You will need a domain name as Saltbox apps are only accessed via https://appname.yourdomain.com (see Accessing Apps).</p> <p>Ports are [for the most part] bound only to the internal <code>saltbox</code> docker network, which means they are not visible on the host; you won't be able to connect externally to the apps using <code>IP:PORT</code>.</p> <p>See here for more information about setting up a domain and DNS settings for use with Saltbox.</p> <p>Note: there is planned support for running without a domain, but it is not complete and is not well-tested.</p>","title":"Domain"},{"location":"saltbox/prerequisites/prerequisites/#cloud-storage","text":"<p>A base assumption in Saltbox is that you are storing your media on cloud storage.  Saltbox can be set up to use any cloud storage provider that Rclone supports. However, Google Drive via G-Suite Business is the preferred choice among users.  Some of the components are designed expressly for Google Drive, like the Google Drive monitoring in plex-autoscan and the service-account rotation in cloudplow.</p> <p>See here for more information about Cloud Storage requirements and running Saltbox without it.</p>","title":"Cloud Storage"},{"location":"saltbox/prerequisites/prerequisites/#plex-account","text":"<p>You'll need a Plex account, if you don't already have one, for purposes of the install, even if you're not planning to use Plex.</p> <p>This may change in the future, but for now it's a requirement for the simplest Happy Path install described here.</p> <p>See here for more information about Plex account requirements.</p>","title":"Plex Account"},{"location":"saltbox/prerequisites/prerequisites/#usenet-or-bittorrent-sources","text":"<p>If you are planning to set up a standard Saltbox or a feederbox, you will need a source of media; Usenet, Torrents, or both</p> <p>You won't need these particular [media source] details for the initial install, but you will need them for application setup.</p> <p>See here for more information about media source requirements.</p> <p>Next, let's discuss Saltbox' Install types.</p>","title":"Usenet or Bittorrent sources"},{"location":"sandbox/","text":"<ul> <li>adguardhome  - tag - <code>sandbox-adguardhome</code></li> <li>airdcpp  - tag - <code>sandbox-airdcpp</code></li> <li>airsonic  - tag - <code>sandbox-airsonic</code></li> <li>alltube  - tag - <code>sandbox-alltube</code></li> <li>alternatrr  - tag - <code>sandbox-alternatrr</code></li> <li>alternatrrx  - tag - <code>sandbox-alternatrrx</code></li> <li>apprise  - tag - <code>sandbox-apprise</code></li> <li>archivebox  - tag - <code>sandbox-archivebox</code></li> <li>beets  - tag - <code>sandbox-beets</code></li> <li>booksonic  - tag - <code>sandbox-booksonic</code></li> <li>bookstack  - tag - <code>sandbox-bookstack</code></li> <li>calibre  - tag - <code>sandbox-calibre</code></li> <li>calibre_web  - tag - <code>sandbox-calibre-web</code></li> <li>coder  - tag - <code>sandbox-coder</code></li> <li>comicstreamer  - tag - <code>sandbox-comicstreamer</code></li> <li>comixed  - tag - <code>sandbox-comixed</code></li> <li>deemix  - tag - <code>sandbox-deemix</code></li> <li>delugevpn  - tag - <code>sandbox-delugevpn</code></li> <li>embystat  - tag - <code>sandbox-embystat</code></li> <li>epms  - tag - <code>sandbox-epms</code></li> <li>filebot  - tag - <code>sandbox-filebot</code></li> <li>filebrowser  - tag - <code>sandbox-filebrowser</code></li> <li>filezilla  - tag - <code>sandbox-filezilla</code></li> <li>flaresolverr  - tag - <code>sandbox-flaresolverr</code></li> <li>funkwhale  - tag - <code>sandbox-funkwhale</code></li> <li>gitea  - tag - <code>sandbox-gitea</code></li> <li>glances_web  - tag - <code>sandbox-glances-web</code></li> <li>goplaxt  - tag - <code>sandbox-goplaxt</code></li> <li>gotify  - tag - <code>sandbox-gotify</code></li> <li>guacamole  - tag - <code>sandbox-guacamole</code></li> <li>handbrake  - tag - <code>sandbox-handbrake</code></li> <li>heimdall  - tag - <code>sandbox-heimdall</code></li> <li>jdownloader2  - tag - <code>sandbox-jdownloader2</code></li> <li>jirafeau  - tag - <code>sandbox-jirafeau</code></li> <li>kavita  - tag - <code>sandbox-kavita</code></li> <li>kcptun_client  - tag - <code>sandbox-kcptun-client</code></li> <li>kcptun_server  - tag - <code>sandbox-kcptun-server</code></li> <li>kitana  - tag - <code>sandbox-kitana</code></li> <li>komga  - tag - <code>sandbox-komga</code></li> <li>lazylibrarian  - tag - <code>sandbox-lazylibrarian</code></li> <li>logarr  - tag - <code>sandbox-logarr</code></li> <li>medusa  - tag - <code>sandbox-medusa</code></li> <li>mkvtoolnix  - tag - <code>sandbox-mkvtoolnix</code></li> <li>monitorr  - tag - <code>sandbox-monitorr</code></li> <li>moviematch  - tag - <code>sandbox-moviematch</code></li> <li>mylar3  - tag - <code>sandbox-mylar3</code></li> <li>nabarr  - tag - <code>sandbox-nabarr</code></li> <li>navidrome  - tag - <code>sandbox-navidrome</code></li> <li>nextcloud  - tag - <code>sandbox-nextcloud</code></li> <li>notifiarr  - tag - <code>sandbox-notifiarr</code></li> <li>ouroboros  - tag - <code>sandbox-ouroboros</code></li> <li>plex-meta-manager  - tag - <code>sandbox-plex-meta-manager</code></li> <li>qbit_manage  - tag - <code>sandbox-qbit_manage</code></li> <li>speedtest  - tag - <code>sandbox-speedtest</code></li> <li>sshwifty  - tag - <code>sandbox-sshwifty</code></li> <li>stash  - tag - <code>sandbox-stash</code></li> <li>thelounge  - tag - <code>sandbox-thelounge</code></li> <li>unmanic  - tag - <code>sandbox-unmanic</code></li> <li>vaultwarden  - tag - <code>sandbox-vaultwarden</code></li> <li>watchtower  - tag - <code>sandbox-watchtower</code></li> <li>wordpress  - tag - <code>sandbox-wordpress</code></li> <li>wrapperr  - tag - <code>sandbox-wrapperr</code></li> <li>xteve  - tag - <code>sandbox-xteve</code></li> <li>znc  - tag - <code>sandbox-znc</code></li> </ul>","title":"Sandbox - All Apps Index"},{"location":"sandbox/basics/","text":"<p>The Saltbox Sandbox repository is installed with Saltbox as part of a standard install. The Saltbox Sandbox application installers are provided and maintained by the community but are subject to approval. The applications are not part of a standard Saltbox install, but they should all be compatible with the Saltbox ecosystem. Sandbox is not a free-for-all no-rules repository but what will be accepted is a much broader range of applications which may not necessarily have anything to do with running a media server. Applications that are newly submitted or need testing will primarily land in the Sandbox repo and if relevant, stable, and maintained may end up in the Saltbox Community repo.</p> <p>Saltbox documentation is written by community members to help others make the most of their systems.</p> <p>Providing documentation for Sandbox applications is encouraged but not required.</p> <p>All Saltbox Community applications must have documentation</p>","title":"Basics"},{"location":"sandbox/basics/#install","text":"<pre><code>sb install sandbox\n</code></pre>","title":"Install"},{"location":"sandbox/basics/#update","text":"<p>To update Saltbox Sandbox run a standard saltbox update and Sandbox, Community, and Saltbox will all be updated</p> <pre><code>sb update\n</code></pre>","title":"Update"},{"location":"sandbox/basics/#how-to-install-sandbox-apps","text":"<p>For most apps it is as simple as running the <code>sb install</code> command in a shell with a <code>sandbox-</code> prefix followed by the name of the role.</p> <pre><code>sb install sandbox-rolename\n</code></pre> <p>For example, to install mkvtoolnix you would run the mkvtoolnix role:-</p> <p><pre><code>sb install sandbox-mkvtoolnix\n</code></pre> Before running any role you should first carefully read through any docs to see if there are any additional steps or pre configuration settings required.</p> <p>A list of all roles available to Saltbox including Community and Sandbox can be called from the terminal via:-</p> <pre><code>sb list\n</code></pre>  <p>Tip</p> <p>Where possible the configured username/password are taken from your Saltbox <code>accounts.yml</code> file located in <code>/srv/git/saltbox/accounts.yml</code> and used to create a default user an password for logging in.</p>","title":"How to Install Sandbox Apps"},{"location":"sandbox/basics/#contributing-to-sandbox-apps","text":"<p>Note: If you just want to install a container into the Saltbox system without creating a role, see this article.</p> <p>That work will also help you determine what you will need to do in a Community role, so starting there would not be wasted effort.</p> <p>If you want to create a Community role to allow others to install your role, keep reading.</p>","title":"Contributing to Sandbox Apps"},{"location":"sandbox/basics/#editing-an-existing-role","text":"<p>If you want to make a change to an existing role [for example, changing the docker image it uses], you don't have [or want to] to create a new role. You make changes like this for either core or community roles using the inventory system</p>","title":"Editing an existing role:"},{"location":"sandbox/basics/#preparatory-work","text":"<p>Start by making your own fork of the Sandbox repo by clicking on the \"Fork\" button up and to the right.</p> <p>This will take you to your own copy of the Sandbox repo.</p> <p>On your development machine [which should probably be a machine running saltbox, as it makes things easier with regard to testing]:</p> <p>clone your Sandbox fork:</p> <pre><code>git clone https://github.com/YOURNAMEHERE/Sandbox.git sandbox\n</code></pre> <p>go into that local sandbox dir:</p> <pre><code>cd sandbox\n</code></pre> <p>make sure your local repo is up-to-date:</p> <pre><code>git pull\n</code></pre> <p>create your feature branch:</p> <pre><code>git checkout -b my-cool-role\n</code></pre>","title":"Preparatory work:"},{"location":"sandbox/basics/#creating-a-role","text":"<p>Now you're ready to start work on your new role.</p> <p>A good starting point is to find a role that is similar to the one you want to add and use it as a starting point. For example, if your container requires mariadb and you want to create a database during setup, bookstack does that.</p> <p>copy the \"starting point\" role to your role:</p> <pre><code>cp -R roles/bookstack roles/my-cool-role\n</code></pre> <p>[of course, substitute whatever role you're using as your prototype for \"bookstack\"]</p> <p>Next step is to create the role. At a minimum, you will need to modify:</p> <pre><code>roles\n\u2514\u2500\u2500 my-cool-role\n \u00a0\u00a0 \u251c\u2500\u2500 defaults\n \u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 main.yml\n \u00a0\u00a0 \u2514\u2500\u2500 tasks\n \u00a0\u00a0     \u2514\u2500\u2500 main.yml\nsandbox.yml\n</code></pre> <p>There may be other things required; there may be templates or sub-tasks or what have you. Those three files are the absolute bare minimum that would need to be created to add a new role.</p> <p>What are those things?</p> <pre><code>roles/my-cool-role/defaults/main.yml\n</code></pre> <p>This file contains various details for your role; the docker image, the name, subdomain, that sort of thing. The stuff in there should be self-explanatory or understandable with comparisons to existing roles; if it's not, then with all respect you probably shouldn't be creating a role right now.</p> <pre><code>roles/my-cool-role/tasks/main.yml\n</code></pre> <p>This file drives the install of your role. The stuff in there should be self-explanatory or understandable with comparisons to existing roles; if it's not, then again, with all respect you probably shouldn't be creating a role right now.</p> <p>There is a wiki article on adding new containers here; this may be of some use.</p> <p>Don't forget the header in both these files:</p> <pre><code>#########################################################################\n# Title:            Sandbox: my-cool-role                               #\n# Author(s):        some-guy, salty                                     #\n# URL:              https://github.com/saltyorg/Sandbox                 #\n# --                                                                    #\n#########################################################################\n#                   GNU General Public License v3.0                     #\n#########################################################################\n---\n</code></pre> <p>Be sure you edit this to reflect your role, name, and such depending on what's there in your prototype</p> <p><pre><code>sandbox.yml\n</code></pre> This file drives the ansible install system by providing the valid tags that you can use with:</p> <pre><code>sb install sandbox-TAG\n</code></pre> <p>Again, it's a simple file, and it should be quite apparent what needs to be added for a new role.</p>","title":"Creating a role:"},{"location":"sandbox/basics/#other-files-you-may-need-to-edit","text":"<pre><code>defaults\n\u2514\u2500\u2500 settings.yml.default\n</code></pre> <p>This file provides the prototype settings file; if your role requires some new settings, add them to this file.  When the sandbox repo is updated, your new settings will be added to the user's current settings file and they will be prompted to review it.</p> <pre><code>templates\n\u2514\u2500\u2500 my-cool-role.j2\n</code></pre> <p>Perhaps you need to create a config file, or a service file, or the like.  Create templates for them here and fill them in at install time.  THere are lots of examples in the existing roles.</p>","title":"Other files you may need to edit:"},{"location":"sandbox/basics/#testing","text":"<p>Warning</p> <p>BE SURE TO TEST YOUR ROLE.</p>  <p>You want to make sure that your role works, so be sure you run it several times. Run it on fresh installs, reinstalls, enlist someone else to run it for you. The point of doing this is to add something to sandbox for others to use; if you don't verify that it works, why are you doing it?</p>","title":"Testing:"},{"location":"sandbox/basics/#creating-the-pull-request","text":"<p>Now it's complete, and tested, and you want it to be added to sandbox for other users to enjoy.</p> <p>First, commit your changes to your fork.</p>  <p>Warning</p> <p>BE SURE YOU DO NOT COMMIT FILES CONTAINING SECRETS LIKE API KEYS OR TOKENS.</p>  <p>This will involve adding the files you changed or added and doing a git commit and git push.</p> <p>This is standard git stuff, and again, with all respect, if you don't know these git basics you probably shouldn't be creating a role right now.</p> <p>Back at github.com, create a pull request against the \"master\" branch of the sandbox repo.</p> <p>You do this by switching to your feature branch in your repo and clicking \"Pull request\" at the top where it says something like: \"This branch is 2 commits ahead of sandbox:master.\"</p> <p>This is a request for the Saltbox team to \"pull\" your changes into their repo.</p> <p>If there are special instructions or details that your role needs, add them to the pull request comments. If needed, create a doc page [which will be its own pull request] for the role.</p>  <p>Warning</p> <p>BE SURE YOU DO NOT COMMIT FILES CONTAINING SECRETS LIKE API KEYS OR TOKENS.</p>  <p>Your pull request will be reviewed eventually, and may generate comments or change requests.</p> <p>You can address those change requests by making further commits to your feature branch; they will automatically be added to this pull request.</p> <p>Eventually, if deemed a good or just reasonable fit, your pull request will be accepted and it will appear in the source sandbox repo.</p>","title":"Creating the Pull Request:"},{"location":"sandbox/settings/","text":"<p>The configuration file for Saltbox Sandbox settings is called settings.yml and is located at <code>/opt/sandbox/settings.yml</code></p> <p>settings.yml</p> <pre><code>---\nexample:  # (1)\n  roles:\n    - podcasts\n    - poetry\nnotifiarr:  # (2)\n  api_key: \"api-key-from-notifiarr.com\"\nunifi:  # (3)\n  port: 8080\n</code></pre> <ol> <li> <p>Example role, provide a list of \"examples's\"     For each listed item an Example instance will be created and the item set to the subdomain.</p> </li> <li> <p>Notifiarr     Add your notifiarr api key here.</p> </li> <li> <p>Unifi</p> </li> </ol>","title":"The Settings File"},{"location":"sandbox/apps/adguardhome/","text":"","title":"AdGuard Home"},{"location":"sandbox/apps/adguardhome/#what-is-it","text":"<p>AdGuard Home is a network-wide, open source software for blocking ads &amp; tracking and for gaining control over all traffic in your home network. After you set it up, it'll cover ALL devices in your home Wi-Fi network, and you won't need any client-side software for that. At the same time, it provides a user-friendly web interface that allows you to easily manage the traffic, even from a mobile device.</p> <p>There are some concerns with the security of running a DNS server remotely so just be aware of this if you choose to run it on a public network.</p>    Details         Project home   Docs  Github:  Docker      <p>Info</p> <p>AdGuard Home is a latency sensitive DNS server, so it's discouraged to use it when your server is far away from you.</p>","title":"What is it?"},{"location":"sandbox/apps/adguardhome/#1-installation","text":"<pre><code>sb install sandbox-adguardhome\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/adguardhome/#2-url","text":"<ul> <li>To access AdGuard Home dashboard, visit <code>https://adguardhome._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/adguardhome/#3-usage","text":"<ul> <li>Make sure you have an application that supports DNS over HTTPS, e.g. Intra for Android or DNSCloak for iOS</li> <li>Connect to AdGuard Home with one of the above applications using <code>https://adguardhome._yourdomain.com/dns-query</code></li> </ul>","title":"3. Usage"},{"location":"sandbox/apps/airdcpp/","text":"","title":"AirDC++"},{"location":"sandbox/apps/airdcpp/#what-is-it","text":"<p>AirDC++ is an easy to use client for Advanced Direct Connect and Direct Connect networks. You are able to join \"hubs\" with other users, and chat, perform searches and browse the share of each user. It allows you to share files with friends and other people.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/airdcpp/#1-installation","text":"<pre><code>sb install sandbox-airdcpp\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/airdcpp/#2-url","text":"<ul> <li>To access AirDC++, visit <code>https://airdcpp._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/airdcpp/#3-setup","text":"<ul> <li> Documentation: AirDC++ Client Docs</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/airsonic/","text":"","title":"Airsonic"},{"location":"sandbox/apps/airsonic/#what-is-it","text":"<p>Airsonic is a free, web-based media streamer, providing ubiquitious access to your music. Use it to share your music with friends, or to listen to your own music while at work. You can stream to multiple players simultaneously, for instance to one player in your kitchen and another in your living room.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/airsonic/#1-installation","text":"<pre><code>sb install sandbox-airsonic\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/airsonic/#2-url","text":"<ul> <li>To access Airsonic, visit <code>https://airsonic._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/airsonic/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/alltube/","text":"","title":"AllTube"},{"location":"sandbox/apps/alltube/#what-is-it","text":"<p>AllTube is an HTML GUI for youtube-dl supporting a wide range of websites.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/alltube/#1-installation","text":"<pre><code>sb install sandbox-alltube\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/alltube/#2-url","text":"<ul> <li>To access AllTube, visit <code>https://alltube._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/alltube/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/alternatrr/","text":"","title":"alternatrr"},{"location":"sandbox/apps/alternatrr/#what-is-it","text":"<p>alternatrr lets you add alternative titles to your sonarr instance by editing the sonarr.db file directly via a simple UI.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/alternatrr/#1-installation","text":"<pre><code>sb install sandbox-alternatrr\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/alternatrr/#2-url","text":"<ul> <li>To access alternatrr, visit <code>https://alternatrr._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/alternatrr/#3-setup","text":"<ul> <li> Documentation </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/alternatrrx/","text":"","title":"alternatrrX"},{"location":"sandbox/apps/alternatrrx/#what-is-it","text":"<p>alternatrrX is an arrX role for alternatrr.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/alternatrrx/#1-installation","text":"<pre><code>sb install sandbox-alternatrrx\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/alternatrrx/#2-url","text":"<ul> <li>To access alternatrrX, visit <code>https://alternatrrX._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/alternatrrx/#3-setup","text":"<ol> <li> <p>Read through the general arrX role instructions.</p> </li> <li> <p>Add your X instance names to the alternatrrX section in sandbox <code>settings.yml</code>: using a list format as below.</p> </li> </ol> <pre><code> alternatrrx:\n   roles:\n     - 1080webdl\n     - 1080remux\n</code></pre> <ul> <li>For app specific instructions refer to the parent role,<ul> <li>alternatrr</li> <li>and the upstream documentation   Documentation </li> </ul> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/apprise/","text":"","title":"Apprise"},{"location":"sandbox/apps/apprise/#what-is-it","text":"<p>Apprise allows you to send a notification to almost all of the most popular notification services available to us today such as: Telegram, Discord, Slack, Amazon SNS, Gotify, etc.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/apprise/#1-installation","text":"<pre><code>sb install sandbox-apprise\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/apprise/#2-setup","text":"<p>As configured, the instance runs on the Docker network accessible to other saltbox network containers at  <code>http://apprise:8000</code>  as well as via the reverse proxy at  <code>https://apprise.domain.tld</code>.</p> <p>The configured username/password are taken from your Saltbox <code>accounts.yml</code> file located in <code>/srv/git/saltbox/accounts.yml</code></p> <ul> <li> Documentation: Apprise Client Docs</li> </ul>","title":"2. Setup"},{"location":"sandbox/apps/archivebox/","text":"","title":"ArchiveBox"},{"location":"sandbox/apps/archivebox/#what-is-it","text":"<p>ArchiveBox is a powerful, self-hosted internet archiving solution to collect, save, and view sites you want to preserve offline.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/archivebox/#1-installation","text":"<pre><code>sb install sandbox-archivebox\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/archivebox/#2-url","text":"<ul> <li>To access ArchiveBox, visit <code>https://archivebox._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/archivebox/#3-setup","text":"<p>Initial setup guide thanks to <code>erisheaded</code> on CB discord.</p> <ol> <li>Run tag:     <pre><code>sb install sandbox-archivebox\n</code></pre></li> <li>Connect to container:    <pre><code>docker exec -it archivebox /bin/bash\n</code></pre></li> <li>NOTE: (This drops you in the /data folder. DO NOT switch to /data/archive directory)</li> <li>Switch to <code>archivebox</code> user for config:    <pre><code>su archivebox\n</code></pre></li> <li>Initialize with setup to create a web admin:    <pre><code>archivebox init \u2014setup\n</code></pre></li> <li>Enter username, email, and password</li> <li>Load URL and test login</li> </ol> <p>By default, your new installation has a publicly accessible web index, snapshots, and archive addition access. You may not want this for a host of security reasons, so it's recommended to review the ArchiveBox Security Overview and tailoring these settings to your preference when setting up.</p>","title":"3. Setup"},{"location":"sandbox/apps/beets/","text":"","title":"Beets"},{"location":"sandbox/apps/beets/#what-is-it","text":"<p>Beets catalogs your collection, automatically improving its metadata as it goes using the MusicBrainz database. Then it provides a bouquet of tools for manipulating and accessing your music.</p> <p>Beets is a music library manager and not, for the most part, a music player. It does include a simple player plugin and an experimental Web-based player, but it generally leaves actual sound-reproduction to specialized tools.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/beets/#1-installation","text":"<pre><code>sb install sandbox-beets\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/beets/#2-url","text":"<ul> <li>To access Beets, visit <code>https://beets._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/beets/#3-setup","text":"<ul> <li>The configured username/password are taken from your Saltbox <code>accounts.yml</code> file located in <code>/srv/git/saltbox/accounts.yml</code></li> <li>When the role is run, a cron job is set to automatically import any music found at <code>/mnt/local/downloads/music</code> every hour.     If a match is under 95% beets will skip the file and it will need manual importing.</li> <li>To run a manual import (which will help correct any matches under 95%) run the following command:  <pre><code>rm /opt/beets/state.pickle &amp;&amp; docker exec -it beets /bin/bash -c 'beet import /downloads'\n</code></pre></li> <li> <p>If you want to change the folder structure you should do so in the config file located at   <code>/opt/beets/config.yaml</code>  This link details the allowed options</p> <p>If you already have imported music you will need to run an import using the following command: <pre><code>docker exec -it beets /bin/bash -c 'beet import /music'\n</code></pre></p> </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/booksonic/","text":"","title":"Booksonic Air"},{"location":"sandbox/apps/booksonic/#what-is-it","text":"<p>Booksonic Air is a platform for accessing the audibooks you own wherever you are. At the moment the platform consists of Booksonic Air - A server for streaming your audiobooks, successor to the original Booksonic server and based on Airsonic. Booksonic App - An DSub based Android app for connection to Booksonic-Air servers.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/booksonic/#1-installation","text":"<pre><code>sb install sandbox-booksonic\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/booksonic/#2-url","text":"<ul> <li>To access Booksonic Air, visit <code>https://booksonic._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/booksonic/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/bookstack/","text":"","title":"BookStack"},{"location":"sandbox/apps/bookstack/#what-is-it","text":"<p>BookStack is a simple, self-hosted, easy-to-use platform for organising and storing information.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/bookstack/#1-installation","text":"<pre><code>sb install sandbox-bookstack\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/bookstack/#2-url","text":"<ul> <li>To access BookStack, visit <code>https://bookstack._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/bookstack/#3-setup","text":"<ul> <li> <p>Log in using the default admin details <code>admin@admin.com</code> with a password of <code>password</code>. You should change these details immediately after logging in for the first time.</p> </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/calibre/","text":"","title":"Calibre"},{"location":"sandbox/apps/calibre/#what-is-it","text":"<p>Calibre is a powerful and easy to use e-book manager. Users say it\u2019s outstanding and a must-have. It\u2019ll allow you to do nearly everything and it takes things a step beyond normal e-book software. It\u2019s also completely free and open source and great for both casual users and computer experts.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/calibre/#1-installation","text":"<pre><code>sb install sandbox-calibre\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/calibre/#2-url","text":"<ul> <li>To access Calibre, visit <code>https://calibre._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/calibre/#3-setup","text":"<ul> <li> <p>The configured username/password are taken from your Saltbox <code>accounts.yml</code> file located in <code>/srv/git/saltbox/accounts.yml</code></p> </li> <li> <p>Calibre is ready for use. If you added your pre-existing Calibre library to /mnt/local/Media/Books then you should see your library is ready to go. If not, then you have a blank library ready for you to fill.</p> </li> </ul>  <p>Info</p> <p>Running Calibre on a headless server is not very fun. If at all possible, run Calibre on your local, home computer. Use rclone to sync the files from home to google drive, and then another sync from google drive to your server so that Calibre-Web can use it.</p> <p>A local database file is required. This means you cannot run either Calibre or Calibre-Web from a mounted teamdrive, and this is the biggest pain for many of us. The easiest solution is to simply have your database and book files all located in /mnt/local/Media/Books.</p> <p>Both Calibre and Calibre-Web expect to find your library in <code>/mnt/unionfs/Media/Books</code>. Note that per standard Saltbox setup, <code>/mnt/local</code> is included inside <code>/mnt/unionfs</code>. However, both dockers also include access to anything in your <code>/mnt</code> directory.</p>","title":"3. Setup"},{"location":"sandbox/apps/calibre/#4-handy-commands-for-managing-your-calibre-docker","text":"<p>You can access advanced features of the Guacamole remote desktop using ctrl+alt+shift enabling you to use remote copy/paste and different languages.</p> <ul> <li> <p>Shell access whilst the container is running:  <code>docker exec -it calibre /bin/bash</code></p> </li> <li> <p>To monitor the logs of the container in realtime:  <code>docker logs -f calibre</code></p> </li> <li> <p>Container version number:  <code>docker inspect -f '{{ index .Config.Labels \"build_version\" }}' calibre</code></p> </li> <li> <p>Image version number:  <code>docker inspect -f '{{ index .Config.Labels \"build_version\" }}' linuxserver/calibre</code></p> </li> <li> <p> Documentation</p> </li> </ul>","title":"4. Handy commands for managing your calibre docker:"},{"location":"sandbox/apps/calibre_web/","text":"","title":"Calibre-Web"},{"location":"sandbox/apps/calibre_web/#what-is-it","text":"<p>Calibre-Web is a web app providing a clean interface for browsing, reading and downloading eBooks using an existing Calibre database.</p> <p>Calibre-Web allows you to add users, and each user can set up a Kindle email address to have ebooks automatically sent to their Kindle reader or Kindle app. Users can also simply download epub, pdf, or whatever files you have. Requires an existing Calibre library database.</p>  <p>Info</p> <p>Calibre and Calibre-web do NOT need to be on the same server. But you do need to have a local copy of the Calibre <code>metadata.db</code> and a path to the books for calibre-web to operate.</p>     Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/calibre_web/#1-installation","text":"<pre><code>sb install sandbox-calibre-web\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/calibre_web/#2-url","text":"<ul> <li>To access Calibre-Web, visit <code>https://calibre-web._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/calibre_web/#3-setup","text":"<ul> <li> <p>Default admin login:   <pre><code>Username: admin\nPassword: admin123\n</code></pre>   Change the default log in details immediately.</p> </li> <li> <p>Unrar is included by default and needs to be set in the Calibre-Web admin page (Basic Configuration:External Binaries) with a path of <code>/usr/bin/unrar</code>.</p> </li> <li> <p>Automatic ebook conversion via Calibre converter is included.  Enable it in the Calibre-Web admin page (Basic Configuration:External Binaries) by setting the Path to Calibre E-Book Converter to <code>/usr/bin/ebook-convert</code>.</p> </li> <li> <p>The kepubify ebook conversion tool (MIT License) to convert epub to kepub is included. In the Calibre-Web admin page (Basic Configuration:External Binaries) set the Path to Kepubify E-Book Converter to <code>/usr/bin/kepubify</code>.</p> </li> </ul> <p>You can access advanced features of the Guacamole remote desktop using ctrl+alt+shift enabling you to use remote copy/paste and different languages.</p> <ul> <li> <p>Shell access whilst the container is running:  <code>docker exec -it calibre-web /bin/bash</code></p> </li> <li> <p>To monitor the logs of the container in realtime:  <code>docker logs -f calibre-web</code></p> </li> <li> <p>Container version number:  <code>docker inspect -f '{{ index .Config.Labels \"build_version\" }}' calibre-web</code></p> </li> <li> <p>Image version number:  <code>docker inspect -f '{{ index .Config.Labels \"build_version\" }}' linuxserver/calibre-web</code></p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/calibre_web/#4-sks-calibre-web-usage-tips","text":"","title":"4. SK's Calibre-Web Usage Tips"},{"location":"sandbox/apps/calibre_web/#smtp-email-server-setup","text":"<p>A useful function of Calibre-Web is sending ebooks by email.  Therefore, you need to set up SMTP e-mail server settings.</p> <p>I am using Google to host the email for mydomain.com.  In my case, after trial and error, I found it most reliable to go into my Google control panel, go to the SMTP settings, and whitelist my server\u2019s IP address without authentication.  Now, I can send email from any Saltbox app that supports it (Ombi, Tautelli, Organizr, and Calibre-Web) with no troubles.</p> <pre><code>Hostname: smtp-relay.gmail.com, Port:  25,  SSL: No\n</code></pre>","title":"SMTP Email Server Setup"},{"location":"sandbox/apps/calibre_web/#kindle-setup","text":"<p>There is a nice benefit to using a Kindle.  When you send a \u201cpersonal document\u201d (book) to your Kindle account, it will automatically download to the specific device tied to the email address you use. Even though it\u2019s called a document, it goes into your regular library and looks just like any book you may have purchased, including the cover.  In addition, that book is available on any other device or app tied to your account, so you can read the same book on your phone, a Kindle Paperwhite, and an iPad.  Amazon\u2019s WhisperSync feature will bookmark your most recent page in the background, so if you switch devices it will ask if you want to update to the most recent page read.</p> <p>If you (or your users) want to have books sent directly to a Kindle from Calibre-Web email, then there are additional one-time setup steps for each user.</p> <ul> <li> <p>Tell Amazon to accept books sent from your website</p> <ul> <li>Go to www.amazon.com</li> <li>On the top navigation bar, go to <code>Account &amp; Lists</code>.  In the dropdown, click on <code>Your Content and Devices</code>.</li> <li>Towards the top of the white section, in the middle, click on <code>Preferences</code></li> <li>Scroll down to Personal Document Settings. Click the title to open up that section of the page.</li> <li>Under <code>Approved Personal Document E-mail List</code>, click the link for <code>\"Add a new approved e-mail address\"</code></li> <li>In the popup, add <code>@yourdomain.com</code> and save.  Done!</li> </ul> <p>Before closing the website, you might want to grab your device email address for the next step.  Under the Send-to-Kindle E-Mail Settings, copy the email address where you want the books sent by default. </p> </li> <li> <p>Add your Kindle email address to your profile on books.yourdomain.com</p> <ul> <li>Once logged in, on the top ride side, click your name to open your profile</li> <li>Add your kindle email address and save</li> <li>Your Kindle email address will be something like name_79@kindle.com.  Every Kindle device and mobile app has its own unique address, however, you can send to any of your devices and it will still be available on all of them.  You can find this email address either in the Settings of the device/app, or copy it from the Devices page</li> </ul> </li> </ul>  <p>Info</p> <p>Kindle has started sending verification emails on every document sent if your Kindle's email is the one they generated for you.  While you are on your settings page, go ahead and make up a new Kindle email address.</p>  <p>Enjoy!</p>","title":"Kindle Setup"},{"location":"sandbox/apps/calibre_web/#5-advanced-method-of-library-storage","text":"<p>Since only the <code>metadata.db</code> file has to be local, you can keep the metadata.db file in <code>/mnt/local/Media/Books</code> as RW and the actual book files in <code>teamdrive:Books</code> as RO and mergerfs them together. Use the latest rclone <code>--vfs-cache-mode=full</code> and related cloud-seeding settings for your teamdrive mount so that it does not get laggy. Have a script that copies the metadata.db file regularly to the local disk, and leave the books in the cloud.</p> <p>If this paragraph does not make sense to you, then please do not try it.</p>","title":"5. Advanced Method of Library Storage"},{"location":"sandbox/apps/coder/","text":"","title":"code-server"},{"location":"sandbox/apps/coder/#what-is-it","text":"<p>code-server . Run VS Code on any machine anywhere and access it in the browser.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/coder/#1-installation","text":"<pre><code>sb install sandbox-coder\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/coder/#2-url","text":"<ul> <li>To access code-server, visit <code>https://coder._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/coder/#3-setup","text":"<ul> <li> VS Code Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/comicstreamer/","text":"","title":"ComicStreamer"},{"location":"sandbox/apps/comicstreamer/#what-is-it","text":"<p>ComicStreamer is a media server app for sharing a library of comic files with client applications. It allows for searching for comics based on a rich set of metadata including fields like series name, title, publisher, story arcs, characters, and creator credits.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/comicstreamer/#1-installation","text":"<pre><code>sb install sandbox-comicstreamer\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/comicstreamer/#2-url","text":"<ul> <li>To access ComicStreamer, visit <code>https://comicstreamer._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/comicstreamer/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/comixed/","text":"","title":"ComiXed"},{"location":"sandbox/apps/comixed/#what-is-it","text":"<p>ComiXed is anapplication for managing digital comics.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/comixed/#1-installation","text":"<pre><code>sb install sandbox-comixed\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/comixed/#2-url","text":"<ul> <li>To access ComiXed, visit <code>https://comixed._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/comixed/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/deemix/","text":"","title":"deemix"},{"location":"sandbox/apps/deemix/#what-is-it","text":"<p>deemix is a barebone deezer downloader library built from the ashes of Deezloader Remix.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/deemix/#1-installation","text":"<pre><code>sb install sandbox-deemix\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/deemix/#2-url","text":"<ul> <li>To access deemix, visit <code>https://deemix._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/deemix/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/delugevpn/","text":"","title":"DelugeVPN"},{"location":"sandbox/apps/delugevpn/#what-is-it","text":"<p>DelugeVPN is a VPN version of Deluge with OpenVPN to ensure a secure and private connection to the Internet, including use of iptables to prevent IP leakage when the tunnel is down.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/delugevpn/#1-installation","text":"<pre><code>sb install sandbox-delugevpn\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/delugevpn/#2-url","text":"<ul> <li>To access DelugeVPN, visit <code>https://delugevpn._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/delugevpn/#3-setup","text":"<p>See the parentDeluge role for app setup.</p> <ul> <li>Edit the DelugeVPN settings in the delugevpn section in community <code>settings.yml</code>: as shown below.</li> </ul> <pre><code> delugevpn:\n   vpn_endpoint: netherlands.ovpn\n   vpn_pass: your_vpn_password\n   vpn_prov: pia\n   vpn_user: your_vpn_username\n   vpn_client: wireguard # 'wireguard' or 'openvpn'\n</code></pre> <p>For Private Internet Access </p> <ul> <li>Add your user name and password</li> <li>Change the vpn_endpoint to your chosen server.  Note that PIA occasionally changes which servers have port forwarding.  The Netherlands server no longer offers port forwarding.  See configuration section for more details.</li> </ul> <p>For other VPN providers </p> <ul> <li>Add your user name and password</li> <li>Change <code>vpn_prov</code> to <code>custom</code></li> <li>Leave <code>vpn_endpoint</code> as <code>netherlands.ovpn</code></li> <li>Follow step 2 below then immediately follow step 3</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/delugevpn/#run-the-delugevpn-role","text":"<pre><code>sb install sandbox-delugevpn\n</code></pre>","title":"Run the DelugeVPN Role"},{"location":"sandbox/apps/delugevpn/#configuring-server-for-custom-vpn-providers-only-for-non-pia","text":"<p>Why you need to do this</p> <p>For custom VPN providers, delugevpn needs an ovpn file to complete the install properly. It can check for a custom file in the <code>/opt/delugevpn/openvpn</code> folder, but this folder does not yet exist. Therefore, we will first use PIA's <code>netherlands.ovpn</code> file, which we will modify later to have our own VPN provider details.</p> <p>The steps above have created some files in <code>/opt/delugevpn/openvpn</code>.</p> <ul> <li><code>ca.rsa.2048.crt</code>  - Leave this</li> <li><code>crl.rsa.2048.pem</code> - Leave this</li> <li><code>credentials.conf</code>  - Leave this. Your VPN username and password are stored here.</li> <li><code>netherlands.ovpn</code>  - Your server details are stored here. We will change this.</li> </ul> <p><pre><code>docker stop delugevpn\ncd /opt/delugevpn/openvpn\nrm netherlands.ovpn\n</code></pre> Now you can upload your own .ovpn file from your VPN provider, renamed as <code>netherlands.ovpn</code>. If your VPN provider has also included a <code>ca.crt</code> file, upload that file as well. Upload one or both files into <code>/opt/delugevpn/openvpn</code>.</p>","title":"Configuring Server for Custom VPN providers (only for non-pia)**"},{"location":"sandbox/apps/delugevpn/#note","text":"<p>Do not rename the original <code>netherlands.ovpn</code> file if you're using Filezilla. delugevpn will automatically use the renamed file instead of <code>netherlands.ovpn</code> and your newly uploaded .ovpn file will still be ignored.</p> <p>Now you can restart the docker <pre><code>docker start delugevpn\n</code></pre></p>","title":"Note"},{"location":"sandbox/apps/delugevpn/#configuration","text":"<p>FOR PIA</p> <ul> <li> <p>vpn_user: Your PIA user name</p> </li> <li> <p>vpn_pass: Your PIA password</p> </li> <li> <p>vpn_prov: pia</p> </li> <li> <p>vpn_endpoint: netherlands.ovpn</p> </li> </ul> <p>Included PIA OpenVPN end point options are.</p>    Endpoint Endpoint Endpoint Endpoint     albania.ovpn egypt.ovpn monaco.ovpn uk_london.ovp   algeria.ovpn finland.ovpn mongolia.ovpn uk_manchester.ovpn   andorra.ovpn france.ovpn montenegro.ovpn uk_southampton.ovpn   argentina.ovpn georgia.ovpn morocco.ovpn ukraine.ovpn   armenia.ovpn greece.ovpn netherlands.ovpn united_arab_emirates.ovpn   au_melbourne.ovpn greenland.ovpn new_zealand.ovpn us_atlanta.ovpn   au_perth.ovpn hong_kong.ovpn nigeria.ovpn us_california.ovpn   au_sydney.ovpn hungary.ovpn norway.ovpn us_chicago.ovpn   austria.ovpn iceland.ovpn panama.ovpn us_denver.ovpn   bahamas.ovpn india.ovpn philippines.ovpn us_east.ovpn   bangladesh.ovpn ireland.ovpn poland.ovpn us_florida.ovpn   belgium.ovpn isle_of_man.ovpn portugal.ovpn us_houston.ovpn   brazil.ovpn israel.ovpn qatar.ovpn us_las_vegas.ovpn   bulgaria.ovpn italy.ovpn romania.ovpn us_new_york.ovpn   ca_montreal.ovpn japan.ovpn saudi_arabia.ovpn us_seattle.ovpn   ca_ontario.ovpn kazakhstan.ovpn serbia.ovpn us_silicon_valley.ovpn   ca_toronto.ovpn latvia.ovpn singapore.ovpn us_texas.ovpn   ca_vancouver.ovpn liechtenstein.ovpn slovakia.ovpn us_washington_dc.ovpn   cambodia.ovpn lithuania.ovpn south_africa.ovpn us_west.ovpn   china.ovpn luxembourg.ovpn spain.ovpn venezuela.ovpn   cyprus.ovpn macao.ovpn sri_lanka.ovpn vietnam.ovpn   czech_republic.ovpn macedonia.ovpn sweden.ovpn    de_berlin.ovpn malta.ovpn switzerland.ovpn    de_frankfurt.ovpn mexico.ovpn taiwan.ovpn    denmark.ovpn moldova.ovpn turkey.ovpn     <p>As of July 4, 2020, the PIA servers that allow port forwarding, and DelugeVPN to work properly, are: CA Toronto, CA Montreal, CA Vancouver, Czech Republic, DE Berlin, DE Frankfurt, France, Israel, Romania, Spain, Switzerland, Sweden.  Check the PIA website for changes if these servers do not work.</p>","title":"Configuration"},{"location":"sandbox/apps/delugevpn/#tips","text":"<ul> <li>If you run into issues check <code>settings.yml</code> modified during pre install setup.</li> <li>If your endpoint has spaces you can use single quotes in the settings.yml ex.)   <code>vpn_endpoint: 'CA Toronto.ovpn'</code></li> <li>After checking/fixing <code>settings.yml</code> execute <code>sudo rm -rf /opt/delugevpn</code></li> <li>WARNING: this will delete all files and folder in /opt/delugevpn, backup first if you need anything)</li> <li>Follow installation steps above again</li> </ul>","title":"Tips"},{"location":"sandbox/apps/delugevpn/#for-app-specific-instructions-refer-to-the-parent-role","text":"<ul> <li>deluge </li> <li>and the upstream documentation   Documentation </li> </ul>","title":"For app specific instructions refer to the parent role"},{"location":"sandbox/apps/dozzle/","text":"","title":"Dozzle"},{"location":"sandbox/apps/dozzle/#what-is-it","text":"<p>Dozzle is a small lightweight application with a web based interface to monitor Docker logs. It doesn\u2019t store any log files. It is for live monitoring of your container logs only.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/dozzle/#1-installation","text":"<pre><code>sb install sandbox-dozzle\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/dozzle/#2-url","text":"<ul> <li>To access Dozzle, visit <code>https://dozzle._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/dozzle/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/embystat/","text":"","title":"EmbyStat"},{"location":"sandbox/apps/embystat/#what-is-it","text":"<p>EmbyStat is a personal web server that can calculate all kinds of statistics from your (local) Emby or Jellyfin server. Just install this on your server and let him calculate all kinds of fun stuff.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/embystat/#1-installation","text":"<pre><code>sb install sandbox-embystat\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/embystat/#2-url","text":"<ul> <li>To access EmbyStat, visit <code>https://embystat._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/embystat/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/epms/","text":"","title":"Extended Personal Media Shows Agent and Scanner"},{"location":"sandbox/apps/epms/#what-is-it","text":"<p>EPMS is very useful for sports or things that do not have a DB to scrape against, creates episode numbers for date-based media and sorts correctly in Plex interface.</p> <p>The Extended Personal Media Shows Agent is a Metadata Agent for personal media files. It works in conjunction with the Extended Personal Media Scanner to scan personal media shows. The meta data agent sets the summary details on the episode. The agent expects the files to follow the naming conventions for personal media that are outlined in the Plex documentation.</p> <p>This scanner is not meant to be full replacement of the Plex Media Scanner. Requests for functionality will be considered but may be limited by what Plex currently allows in the TV Show sections.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/epms/#1-installation","text":"<pre><code>sb install sandbox-epms\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/epms/#2-setup","text":"<ul> <li> Documentation</li> </ul>","title":"2. Setup"},{"location":"sandbox/apps/filebot/","text":"","title":"FileBot"},{"location":"sandbox/apps/filebot/#what-is-it","text":"<p>FileBot is the ultimate tool for organizing and renaming your movies, tv shows or anime, and music well as downloading subtitles and artwork. It's smart and just works.</p> <p>This is a Docker container for FileBot.</p> <p>The GUI of the application is accessed through a modern web browser (no installation or configuration needed on the client side) or via any VNC client.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/filebot/#1-installation","text":"<pre><code>sb install sandbox-filebot\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/filebot/#2-url","text":"<ul> <li>To access FileBot, visit <code>https://filebot._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/filebot/#3-setup","text":"<ul> <li>The configured username/password are taken from your Saltbox <code>accounts.yml</code> file located in <code>/srv/git/saltbox/accounts.yml</code></li> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/filebrowser/","text":"","title":"File Browser"},{"location":"sandbox/apps/filebrowser/#what-is-it","text":"<p>File Browser is is a create-your-own-cloud-kind of software where you can install it on a server, direct it to a path and then access your files through a nice web interface. You have many available features!</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/filebrowser/#1-installation","text":"<pre><code>sb install sandbox-filebrowser\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/filebrowser/#2-url","text":"<ul> <li>To access File Browser, visit <code>https://filebrowser._yourdomain.com_</code></li> </ul>  <p>Info</p> <p>default login  <pre><code>    user: admin\npassword: admin\n</code></pre> Change the default user and password immediately.</p>","title":"2. URL"},{"location":"sandbox/apps/filebrowser/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/filezilla/","text":"","title":"FileZilla"},{"location":"sandbox/apps/filezilla/#what-is-it","text":"<p>FileZilla is a cross-platform graphical FTP, SFTP, and FTPS file management tool with a vast list of features.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/filezilla/#1-installation","text":"<pre><code>sb install sandbox-filezilla\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/filezilla/#2-url","text":"<ul> <li>To access FileZilla, visit <code>https://filezilla._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/filezilla/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/flaresolverr/","text":"","title":"FlareSolverr"},{"location":"sandbox/apps/flaresolverr/#what-is-it","text":"<p>FlareSolverr is a proxy server to bypass Cloudflare protection.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/flaresolverr/#1-installation","text":"<pre><code>sb install sandbox-flaresolverr\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/flaresolverr/#2-setup","text":"","title":"2. Setup"},{"location":"sandbox/apps/flaresolverr/#jackett","text":"<ul> <li>Locate the FlareSolverr API URL field in the main page.</li> <li>Input <code>http://flaresolverr:8191</code> and apply the settings.</li> </ul>","title":"Jackett"},{"location":"sandbox/apps/flaresolverr/#prowlarr","text":"<ul> <li>In the settings, add an Indexer Proxy and select FlareSolverr.</li> <li> <p>Host should be <code>http://flaresolverr:8191</code>.</p> </li> <li> <p> Documentation</p> </li> </ul>","title":"Prowlarr"},{"location":"sandbox/apps/funkwhale/","text":"","title":"Funkwhale"},{"location":"sandbox/apps/funkwhale/#what-is-it","text":"<p>Funkwhale is a modern, self-hosted, free and open-source music server.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/funkwhale/#1-installation","text":"<pre><code>sb install sandbox-funkwhale\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/funkwhale/#2-url","text":"<ul> <li>To access Funkwhale, visit <code>https://funkwhale._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/funkwhale/#3-setup","text":"<p>First create the superuser</p> <ul> <li><code>docker exec -it funkwhale manage createsuperuser</code>     (for ease of access, set it as your Saltbox user and password.)</li> <li>enter the <code>exit</code> command when finished to return to your server's shell.</li> </ul> <p>Now configure these settings via the web GUI</p> <ul> <li>Access Funkwhale, visit <code>https://funkwhale._yourdomain.com_</code> and log in with the user and password you just created.</li> <li>Enter <code>Music-&gt;Add Content-&gt;Create a new Library</code> and fill out the information.</li> <li>Enter your new Library and Details. There will be a sharing link such as:   <code>https://funkwhale.domain.com/federation/music/libraries/da8bd97b-3c3f-4e7b-92cb-6ba45721837b</code></li> <li>Copy out the last portion: <code>da8bd97b-3c3f-4e7b-92cb-6ba45721837b</code></li> </ul> <p>Return to the shell session to import music library</p> <ul> <li><code>docker exec -it funkwhale /usr/bin/python3 /app/api/manage.py import_files da8bd97b-3c3f-4e7b-92cb-6ba45721837b \"/music/Media/Audio/Music/**/**/*.flac\" --in-place --async --recursive</code></li> </ul> <p>The above line explained:</p> <ul> <li><code>docker exec -it funkwhale /usr/bin/python3 /app/api/manage.py import_files</code> tells funkwhale to import music.</li> <li><code>da8bd97b-3c3f-4e7b-92cb-6ba45721837b</code> is your library id</li> <li><code>\"/music/Media/Audio/Music/**/**/*.flac\"</code> is the path to your media.</li> <li><code>--in-place</code> means do not copy the media into Funkwhale and leave it where it is.</li> <li><code>--async</code> means it will import the music first and then pull the metadata`</li> <li><code>--recursive</code> will recursively scan the folders</li> </ul> <p>If everything goes as planned you'll get prompted like this:</p> <pre><code>&gt; Checking imported paths against settings.MUSIC_DIRECTORY_PATH\n&gt; Import summary:\n&gt; - 149828 files found matching this pattern: ['/music/Media/Audio/Music/**/**/*.flac']\n\n&gt; - 0 files already found in database\n&gt; - 149828 new files\n&gt; Selected options: in place\n&gt; Are you sure you want to do this?\n&gt; Type 'yes' to continue, or 'no' to cancel:\n</code></pre> <ul> <li>Answer yes at the prompt and the import will begin.</li> </ul>  <p>Info</p> <p>Useful URLs  Libraries URL: <code>https://funkwhale.domain.com/content/libraries/</code>  Admin Account Edit Page: <code>https://funkwhale.domain.com/api/admin/users/user/1/change/</code> </p>   <p>Info</p> <p>If you want to use subsonic clients then you'll need to set a password here:   <code>https://funkwhale.domain.com/settings</code> (subsonic protocol requires storing password in cleartext, so to avoid compromising your Funkwhale account, we use a different password).</p>  <p>Additional Information:</p> <ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/gitea/","text":"","title":"Gitea"},{"location":"sandbox/apps/gitea/#what-is-it","text":"<p>Gitea is a community managed lightweight code hosting solution written in Go.</p> <p>Gitea is a painless self-hosted Git service. It is similar to GitHub, Bitbucket, and GitLab. Gitea is a fork of Gogs.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/gitea/#1-installation","text":"<pre><code>sb install sandbox-gitea\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/gitea/#2-url","text":"<ul> <li>To access Gitea, visit <code>https://gitea._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/gitea/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/glances_web/","text":"","title":"Glances"},{"location":"sandbox/apps/glances_web/#what-is-it","text":"<p>Glances is a cross-platform monitoring tool which aims to present a large amount of monitoring information through a curses or Web based interface. The information dynamically adapts depending on the size of the user interface.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/glances_web/#1-installation","text":"<pre><code>sb install sandbox-glances-web\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/glances_web/#2-url","text":"<ul> <li>To access Glances, visit <code>https://glances._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/glances_web/#3-setup","text":"<ul> <li>The configured username/password are taken from your Saltbox <code>accounts.yml</code> file located in <code>/srv/git/saltbox/accounts.yml</code></li> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/goaccess/","text":"","title":"GoAccess"},{"location":"sandbox/apps/goaccess/#what-is-it","text":"<p>GoAccess is an open source real-time web log analyzer and interactive viewer that runs in a terminal in *nix systems or through your browser.</p> <p>It provides fast and valuable HTTP statistics for system administrators that require a visual server report on the fly.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/goaccess/#1-installation","text":"<pre><code>sb install sandbox-goaccess\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/goaccess/#2-url","text":"<ul> <li>To access GoAccess, visit <code>https://goaccess._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/goaccess/#3-setup","text":"<ul> <li>The configured username/password are taken from your Saltbox <code>accounts.yml</code> file located in <code>/srv/git/saltbox/accounts.yml</code></li> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/goplaxt/","text":"","title":"Goplaxt"},{"location":"sandbox/apps/goplaxt/#what-is-it","text":"<p>Goplaxt scrobbles Plex plays to Trakt with ease!</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/goplaxt/#1-installation","text":"<pre><code>sb install sandbox-goplaxt\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/goplaxt/#2-url","text":"<ul> <li>To access Goplaxt, visit <code>https://goplaxt._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/goplaxt/#3-setup","text":"<ol> <li> <p>Create an API application through Trakt here. The Redirect URI should be your goplaxt.domain + <code>/authorize</code>, so it reads as: <code>https://goplaxt.domain.com/authorize</code>.</p> </li> <li> <p>Edit the Goplaxt section in community <code>settings.yml</code>: substituting your own <code>ID</code> and <code>secret</code>.</p> <pre><code>goplaxt:\n  trakt_id: IDHERE\n  trakt_secret: SECRETHERE\n</code></pre> </li> <li> <p>Run the role install command</p> <pre><code>sb install sandbox-goplaxt\n</code></pre> </li> <li> <p>Visit the goplaxt site at <code>https://goplaxt.domain.com</code>.      Enter your <code>Plex Username</code> then <code>Authorize</code>, and add the Webhook in <code>Plex Settings</code>.      Make sure under your server <code>Settings &gt; Network</code> that Webhooks is <code>enabled</code>.</p> </li> <li> <p> Documentation</p> </li> </ol>","title":"3. Setup"},{"location":"sandbox/apps/gotify/","text":"","title":"Gotify"},{"location":"sandbox/apps/gotify/#what-is-it","text":"<p>Gotify a simple server for sending and receiving messages.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/gotify/#1-installation","text":"<pre><code>sb install sandbox-gotify\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/gotify/#2-url","text":"<ul> <li>To access Gotify, visit <code>https://gotify._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/gotify/#3-setup","text":"<ul> <li> <p>The configured username/password are taken from your Saltbox <code>accounts.yml</code> file located in <code>/srv/git/saltbox/accounts.yml</code></p> </li> <li> <p> Documentation</p> </li> </ul>  <p>Info</p> <p>Android App  https://github.com/gotify/android  https://f-droid.org/de/packages/com.github.gotify/ </p>","title":"3. Setup"},{"location":"sandbox/apps/grafana/","text":"","title":"Grafana"},{"location":"sandbox/apps/grafana/#what-is-it","text":"<p>Grafana allows you to query, visualize, alert on, and understand your data no matter where it\u2019s stored. With Grafana you can create, explore and share all of your data through beautiful, flexible dashboards.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/grafana/#1-installation","text":"<pre><code>sb install sandbox-grafana\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/grafana/#2-url","text":"<ul> <li>To access Grafana, visit <code>https://grafana._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/grafana/#3-setup","text":"<ul> <li> <p>The configured username/password are taken from your Saltbox <code>accounts.yml</code> file located in <code>/srv/git/saltbox/accounts.yml</code></p> </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/guacamole/","text":"","title":"Guacamole"},{"location":"sandbox/apps/guacamole/#what-is-it","text":"<p>Guacamole is a clientless remote desktop gateway. It supports standard protocols like VNC, RDP, and SSH.</p> <p>We call it clientless because no plugins or client software are required.</p> <p>Thanks to HTML5, once Guacamole is installed on a server, all you need to access your desktops is a web browser.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/guacamole/#1-installation","text":"<pre><code>sb install sandbox-guacamole\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/guacamole/#2-url","text":"<ul> <li>To access Guacamole, visit <code>https://guacamole._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/guacamole/#3-setup","text":"<ul> <li> <p>Log in with user and password <code>guacadmin</code>. Change the default user and password immediately.</p> </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/handbrake/","text":"","title":"HandBrake"},{"location":"sandbox/apps/handbrake/#what-is-it","text":"<p>HandBrake is a tool for converting video from nearly any format to a selection of modern, widely supported codecs.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/handbrake/#1-installation","text":"<pre><code>sb install sandbox-handbrake\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/handbrake/#2-url","text":"<ul> <li>To access HandBrake, visit <code>https://handbrake._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/handbrake/#3-setup","text":"<ol> <li> <p>Edit the HandBrake section in community <code>settings.yml</code>: and enter your desired password. Please note that it MUST be less than eight characters.</p> <pre><code>handbrake:\n  handbrake_pass: saltbox\n</code></pre> </li> <li> <p>Run the role install command</p> <pre><code>sb install sandbox-handbrake\n</code></pre> </li> <li> <p>Access HandBrake <code>https://handbrake._yourdomain.com_</code></p> </li> <li> <p>See the HandBrake documentation for usage:</p> <ul> <li> Documentation</li> </ul> </li> </ol>  <p>Tip</p> <p>This container has an automatic video converter built in, see the container documentation here.</p>","title":"3. Setup"},{"location":"sandbox/apps/healthchecks/","text":"","title":"Healthchecks"},{"location":"sandbox/apps/healthchecks/#what-is-it","text":"<p>Healthchecks is a watchdog for your cron jobs. It's a web server that listens for pings from your cron jobs, plus a web interface.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/healthchecks/#1-installation","text":"<pre><code>sb install sandbox-healthchecks\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/healthchecks/#2-url","text":"<ul> <li>To access Healthchecks, visit <code>https://healthchecks._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/healthchecks/#3-setup","text":"<ul> <li> <p>The configured username/password are taken from your Saltbox <code>accounts.yml</code> file located in <code>/srv/git/saltbox/accounts.yml</code></p> </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/heimdall/","text":"","title":"Heimdall"},{"location":"sandbox/apps/heimdall/#what-is-it","text":"<p>Heimdall is a way to organise all those links to your most used web sites and web applications in a simple way. Simplicity is the key to Heimdall. Why not use it as your browser start page? It even has the ability to include a search bar using either Google, Bing or DuckDuckGo.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/heimdall/#1-installation","text":"<pre><code>sb install sandbox-heimdall\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/heimdall/#2-url","text":"<ul> <li>To access Heimdall, visit <code>https://heimdall._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/heimdall/#3-setup","text":"<ul> <li> <p>The configured username/password are taken from your Saltbox <code>accounts.yml</code> file located in <code>/srv/git/saltbox/accounts.yml</code></p> </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/influxdb/","text":"","title":"InfluxDB"},{"location":"sandbox/apps/influxdb/#what-is-it","text":"<p>InfluxDB is an open source time series database for recording metrics, events, and analytics.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/influxdb/#1-installation","text":"<pre><code>sb install sandbox-influxdb\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/influxdb/#2-setup","text":"<ul> <li> Documentation</li> </ul>","title":"2. Setup"},{"location":"sandbox/apps/jdownloader2/","text":"","title":"JDownloader"},{"location":"sandbox/apps/jdownloader2/#what-is-it","text":"<p>JDownloader is a free download-manager that makes downloading as easy, fast and automated as it should be. It's like your personal internet robot that does all the work for you. He will download whole photo albums, playlists or just about anything else with just one click. Go ahead and try it!</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/jdownloader2/#1-installation","text":"<pre><code>sb install sandbox-jdownloader2\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/jdownloader2/#2-url","text":"<ul> <li>To access JDownloader, visit <code>https://jdownloader2._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/jdownloader2/#3-setup","text":"<ol> <li> <p>The configured password is taken from your Saltbox <code>accounts.yml</code> file located in <code>/srv/git/saltbox/accounts.yml</code></p> </li> <li> <p>Configure your myjdownloader account (Create at https://my.jdownloader.org/ if needed) and name your instance so you can connect via web or browser extensions. Use clipboard for two step copy and paste if needed. Note that some settings are only accessible via <code>jdownloader2.yourdomain.com</code>. Premium accounts such as mega.nz can be added via web interface.</p> </li> <li> <p>Use manual import from sonarr / radarr and navigate to <code>/mnt/local/downloads/myjdownloader/output/</code> to import your files, note they must be already added as wanted media for import to recognise and identify your downloaded media.</p> </li> <li> <p>See https://my.jdownloader.org/ for browser extensions and phone apps as desired.</p> </li> <li> <p> Documentation</p> </li> </ol>","title":"3. Setup"},{"location":"sandbox/apps/jirafeau/","text":"","title":"Jirafeau"},{"location":"sandbox/apps/jirafeau/#what-is-it","text":"<p>Jirafeau  is a web site permitting to upload a file in a simple way and give an unique link to it. Jirafeau is a \"one-click-filesharing\": Select your file, upload, share a link. That's it.</p> <p>See jirafeau.net for a demo.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/jirafeau/#1-installation","text":"<pre><code>sb install sandbox-jirafeau\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/jirafeau/#2-url","text":"<ul> <li>To access Jirafeau, visit <code>https://jirafeau._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/jirafeau/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/kavita/","text":"","title":"Kavita"},{"location":"sandbox/apps/kavita/#what-is-it","text":"<p>Kavita is a fast, feature rich, cross platform reading server. Built with a focus for manga, and the goal of being a full solution for all your reading needs. Setup your own server and share your reading collection with your friends and family!</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/kavita/#1-installation","text":"<pre><code>sb install sandbox-kavita\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/kavita/#2-url","text":"<ul> <li>To access Kavita, visit <code>https://kavita._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/kavita/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/kcptun_client/","text":"","title":"kcptun client"},{"location":"sandbox/apps/kcptun_client/#what-is-it","text":"<p>APPNAME is a Stable &amp; Secure Tunnel based on KCP with N:M multiplexing and FEC.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/kcptun_client/#1-installation","text":"<pre><code>sb install sandbox-kcptun-client\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/kcptun_client/#2-setup","text":"<ul> <li> Documentation</li> </ul>","title":"2. Setup"},{"location":"sandbox/apps/kcptun_server/","text":"","title":"kcptun server"},{"location":"sandbox/apps/kcptun_server/#what-is-it","text":"<p>APPNAME is a Stable &amp; Secure Tunnel based on KCP with N:M multiplexing and FEC.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/kcptun_server/#1-installation","text":"<pre><code>sb install sandbox-kcptun-server\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/kcptun_server/#2-setup","text":"<ul> <li> Documentation</li> </ul>","title":"2. Setup"},{"location":"sandbox/apps/kitana/","text":"","title":"Kitana"},{"location":"sandbox/apps/kitana/#what-is-it","text":"<p>Kitana is a responsive Plex plugin web frontend.</p> <p>Running one instance of Kitana can serve infinite amounts of servers and plugins - you can even expose your Kitana instance to your friends, so they can manage their plugins as well, so they don't have to run their own Kitana instance.</p> <p>Kitana was built for Sub-Zero originally, but handles other plugins just as well.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/kitana/#1-installation","text":"<pre><code>sb install sandbox-kitana\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/kitana/#2-url","text":"<ul> <li>To access Kitana, visit <code>https://kitana._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/kitana/#3-setup","text":"<ul> <li> <p>pen your browser and visit your Kitana instance <code>https://kitana._yourdomain.com_</code></p> </li> <li> <p>authenticate against Plex.TV</p> </li> <li> <p>select your server (non-owned may not work; local connections are preferred)</p> </li> <li> <p>profit</p> </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/komga/","text":"","title":"Komga"},{"location":"sandbox/apps/komga/#what-is-it","text":"<p>Komga is a free and open source comics/mangas server.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/komga/#1-installation","text":"<pre><code>sb install sandbox-komga\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/komga/#2-url","text":"<ul> <li>To access Komga, visit <code>https://komga._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/komga/#3-setup","text":"<ul> <li> <p>On first opening you will be asked to create a user account.    Choose an email and password, then click on Create User Account.</p> </li> <li> <p>Komga expects comics to be stored in <code>/mnt/unionfs/Media/Comics</code>.</p> </li> <li> <p><code>/mnt</code> is accessible to the container as well.</p> </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/lazylibrarian/","text":"","title":"LazyLibrarian"},{"location":"sandbox/apps/lazylibrarian/#what-is-it","text":"<p>LazyLibrarian is a program to follow authors and grab metadata for all your digital reading needs.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/lazylibrarian/#1-installation","text":"<pre><code>sb install sandbox-lazylibrarian\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/lazylibrarian/#2-url","text":"<ul> <li>To access LazyLibrarian, visit <code>https://lazylibrarian._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/lazylibrarian/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/logarr/","text":"","title":"Logarr ALPHA"},{"location":"sandbox/apps/logarr/#what-is-it","text":"<p>Logarr ALPHA is a Self-hosted, single-page, log consolidation tool written in PHP.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/logarr/#1-installation","text":"<pre><code>sb install sandbox-logarr\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/logarr/#2-url","text":"<ul> <li>To access Logarr ALPHA, visit <code>https://logarr._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/logarr/#3-setup","text":"<ul> <li> <p>See documentation for configuration and instructions for adding more logs to your instance.</p> </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/medusa/","text":"","title":"Medusa"},{"location":"sandbox/apps/medusa/#what-is-it","text":"<p>Medusa is an automatic Video Library Manager for TV Shows. It watches for new episodes of your favorite shows, and when they are posted it does its magic.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/medusa/#1-installation","text":"<pre><code>sb install sandbox-medusa\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/medusa/#2-url","text":"<ul> <li>To access Medusa, visit <code>https://medusa._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/medusa/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/mkvtoolnix/","text":"","title":"MKVToolNix"},{"location":"sandbox/apps/mkvtoolnix/#what-is-it","text":"<p>MKVToolNix is a set of tools to create, alter and inspect Matroska files.</p> <p>You can use MKVToolNix to create, split, edit, mux, demux, merge, extract or inspect Matroska files. The program will also work with other video formats (AVI, MPEG, MP4, MPEG, Ogg/OGM, RealVideo, MPEG1/2, h264/AVC, Dirac, VC1) including some video codecs (such as VP9 video codec support - reading from IVF/Matroska/WebM files, extract to IVF files). Audio formats (AAC, FLAC, MP2, MP3, (E)AC3, DTS/DTS-HD, Vorbis, RealAudio) and also most subtitle formats (SRT, PGS/SUP, VobSub, ASS, SSA, etc.).</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/mkvtoolnix/#1-installation","text":"<pre><code>sb install sandbox-mkvtoolnix\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/mkvtoolnix/#2-url","text":"<ul> <li>To access MKVToolNix, visit <code>https://mkvtoolnix._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/mkvtoolnix/#3-setup","text":"<ul> <li> Documentation: MKVToolNix Client Docs</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/monitorr/","text":"","title":"Monitorr"},{"location":"sandbox/apps/monitorr/#what-is-it","text":"<p>Monitorr is a self-hosted PHP web app that monitors the status of local and remote network services, websites, and applications.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/monitorr/#1-installation","text":"<pre><code>sb install sandbox-monitorr\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/monitorr/#2-url","text":"<ul> <li>To access Monitorr, visit <code>https://monitorr._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/monitorr/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/moviematch/","text":"","title":"MovieMatch"},{"location":"sandbox/apps/moviematch/#what-is-it","text":"<p>MovieMatch is an app that helps you and your friends pick a movie to watch from a Plex server.</p> <p>MovieMatch connects to your Plex server and gets a list of movies (from any libraries marked as a movie library).</p> <p>As many people as you want connect to your MovieMatch server and get a list of shuffled movies. Swipe right to +1, swipe left to -1.</p> <p>If two (or more) people swipe right on the same movie, it'll show up in everyone's matches. The movies that the most people swiped right on will show up first.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/moviematch/#1-installation","text":"<pre><code>sb install sandbox-moviematch\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/moviematch/#2-url","text":"<ul> <li>To access MovieMatch, visit <code>https://moviematch._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/moviematch/#3-setup","text":"","title":"3. Setup"},{"location":"sandbox/apps/moviematch/#via-ui","text":"<ul> <li>If you prefer to set up MovieMatch using a web interface, just start MovieMatch and you will be presented with a configuration screen.    The configuration will be saved in the working directory.</li> </ul>","title":"Via UI"},{"location":"sandbox/apps/moviematch/#via-yaml","text":"<ul> <li>MovieMatch can be configured with a simple YAML document, which allows connecting to multiple Plex servers.    Here's a simple example:</li> </ul> <pre><code>  host: 0.0.0.0\n  port: 8000\n  servers:\n    - url: https://plex.example.com\n      token: abcdef12346\n</code></pre> <p>MovieMatch will read the config from <code>/opt/moviematch/config.yaml</code> by default.</p> <ul> <li> Documentation</li> </ul>","title":"Via YAML"},{"location":"sandbox/apps/mylar3/","text":"","title":"Mylar3"},{"location":"sandbox/apps/mylar3/#what-is-it","text":"<p>Mylar3 is an automated Comic Book downloader (cbr/cbz) for use with SABnzbd, NZBGet and torrents. Also provides an OPDS server distribution.</p> <p>Mylar allows you to create a watchlist of series that it monitors for various things (new issues, updated information, etc). It will grab, sort, and rename downloaded issues. It will also allow you to monitor weekly pull-lists for items belonging to said watchlisted series to download, as well as being able to monitor and maintain story-arcs.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/mylar3/#1-installation","text":"<pre><code>sb install sandbox-ROLENAME\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/mylar3/#2-url","text":"<ul> <li>To access Mylar3, visit <code>https://ROLENAME._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/mylar3/#3-setup","text":"<ol> <li> <p>It's highly unlikely your mylar install is up to date.    Press the Update link on the dialog in the bottom right hand corner. Mylar3 will update and then restart.</p> </li> <li> <p>Enable some authentication. Add a <code>username</code> and <code>password</code> and set your preferred <code>login method</code>.</p> </li> <li> <p>Make sure <code>Launch Browser on startup</code> is disabled.</p> </li> <li> <p>You'll need a ComicVine API Key for Mylar to be useful. Create an account, and your key will be at the top of this page.</p> </li> <li> <p>Set the Comic Location path to <code>/comics</code>. It will already be mounted.</p> </li> <li> <p>Uncheck <code>enforce permissions</code></p> </li> <li> <p>Optional: Enable <code>Series-Annual Integration</code></p> </li> <li> <p>Save and then restart the app</p> </li> </ol>  <p>Note</p> <p>If you enable to OPDS server, DO NOT ENABLE <code>OPDS Fetch MetaInfo</code>. It queries the file system.</p>","title":"3. Setup"},{"location":"sandbox/apps/mylar3/#download-settings","text":"<p>(These instructions are for NZBGet. Adapt for other Download Apps)</p>","title":"Download settings"},{"location":"sandbox/apps/mylar3/#configure-nzbget","text":"<ol> <li> <p>Log into <code>https://nzbget._youdomain_.com</code></p> </li> <li> <p>Go to <code>Settings &gt; Categories</code></p> </li> <li> <p>Scroll to bottom, click <code>Add Another Category</code></p> </li> <li> <p>Name it <code>mylar</code></p> </li> </ol>","title":"Configure NZBGet"},{"location":"sandbox/apps/mylar3/#configure-mylar","text":"<ol> <li> <p>Set Usenet client to NZBGet</p> </li> <li> <p>Fill in the server stuff like it would be in sonarr / radarr / etc</p> </li> <li> <p>Set values:</p> </li> <li> <p>Host: <code>nzbget</code></p> </li> <li> <p>Port: <code>6789</code></p> </li> <li> <p>Username:  <code>Your NZBGet Username</code></p> </li> <li> <p>Password:  <code>Your NZBGet Password</code></p> </li> <li> <p>Category: <code>mylar</code></p> </li> <li> <p>Use SSL: <code>No</code></p> </li> <li> <p>NZBGet Download Directory: Leave Blank</p> </li> <li> <p>Enable Completed Download Handling: <code>X</code></p> </li> </ol>","title":"Configure Mylar"},{"location":"sandbox/apps/mylar3/#search-providers","text":"<ol> <li> <p>Click Add Indexer (<code>+</code>).</p> </li> <li> <p>Select \"Newznab\".</p> </li> <li> <p>Add the following:</p> <ol> <li> <p>Use Newznab: <code>X</code></p> </li> <li> <p>NewzNab Name: <code>NZBHydra2</code></p> </li> <li> <p>NewzNab Host: <code>http://nzbhydra2:5076</code></p> </li> <li> <p>Verify SSL: <code>Disabled</code></p> </li> <li> <p>API Key: <code>Your NZBHydra2 API Key</code></p> </li> <li> <p>Enabled: <code>X</code></p> </li> </ol> </li> </ol>","title":"Search Providers"},{"location":"sandbox/apps/mylar3/#quality-and-post-processing","text":"<ol> <li> <p>Enable Failed Download Handling: <code>X</code></p> </li> <li> <p>Enable Automatic-Retry for Failed Downloads: <code>X</code></p> </li> <li> <p>Enable Post-Processing: <code>X</code></p> </li> <li> <p>When Post-Processing <code>move</code> the files</p> </li> </ol>","title":"Quality and Post Processing"},{"location":"sandbox/apps/mylar3/#advanced-settings","text":"<p>These settings are up to the user</p> <ol> <li> <p>Rename Files: <code>X</code></p> </li> <li> <p>Folder Format: <code>$Series ($Year)</code> (My recommendation)</p> </li> <li> <p>File Format: <code>$Series $Annual $Issue ($Year)</code> (My recommendation)</p> </li> </ol>","title":"Advanced Settings"},{"location":"sandbox/apps/mylar3/#see-the-mylar-wiki-for-more-information","text":"<ul> <li> Documentation</li> </ul>","title":"See the Mylar Wiki for more information"},{"location":"sandbox/apps/nabarr/","text":"","title":"Nabarr"},{"location":"sandbox/apps/nabarr/#what-is-it","text":"<p>Nabarr monitors Newznab/Torznab RSS feeds to find new media to add to Sonarr and or Radarr.</p>    Details         Nabarr   Docs  Github:  Docker:","title":"What is it?"},{"location":"sandbox/apps/nabarr/#1-installation","text":"<pre><code>sb install sandbox-nabarr\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/nabarr/#2-setup","text":"<ul> <li> Documentation: Nabarr Docs</li> </ul>","title":"2. Setup"},{"location":"sandbox/apps/navidrome/","text":"","title":"Navidrome"},{"location":"sandbox/apps/navidrome/#what-is-it","text":"<p>Navidrome allows you to enjoy your music collection from anywhere, by making it available through a modern Web UI and through a wide range of third-party compatible mobile apps, for both iOS and Android devices.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/navidrome/#1-installation","text":"<pre><code>sb install sandbox-navidrome\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/navidrome/#2-url","text":"<ul> <li>To access Navidrome, visit <code>https://navidrome._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/navidrome/#3-setup","text":"<ul> <li> <p>After installing Navidrome in your platform, you need to create your first user. This will be your admin user, a super user that can manage all aspects of Navidrome, including the ability to manage other users. Just browse to Navidrome\u2019s homepage at<code>https://navidrome._yourdomain.com_</code> and you will be greeted with a screen like this: </p> <p></p> <p>Just fill out the username and password you want to use, confirm the password and click on the \u201cCreate Admin\u201d button.</p> <p>That\u2019s it! You should now be able to browse and listen to all your music.</p>  <p>Note<p>It usually take a couple of minutes for your music to start appearing in Navidrome\u2019s UI.   You can check the logs to see what is the scan progress. If you have a large library this may take some time.</p> </p>  </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/nextcloud/","text":"","title":"Nextcloud"},{"location":"sandbox/apps/nextcloud/#what-is-it","text":"<p>Nextcloud is safe home for all your data. Access &amp; share your files, calendars, contacts, mail &amp; more from any device, on your terms.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/nextcloud/#1-installation","text":"<pre><code>sb install sandbox-nextcloud\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/nextcloud/#2-url","text":"<ul> <li>To access Nextcloud, visit <code>https://nextcloud._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/nextcloud/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/notifiarr/","text":"","title":"Notifiarr Client"},{"location":"sandbox/apps/notifiarr/#what-is-it","text":"<p>Notifiarr Client is the unified client for Notifiarr.com. The client enables content requests from Media Bot in your Discord Server. It also provides reports for Plex usage and system health. Other features can be configured on the Notifiarr website.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/notifiarr/#1-installation","text":"<pre><code>sb install sandbox-notifiarr\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/notifiarr/#2-url","text":"<ul> <li>The Notifiarr url will only display the app status <code>https://notifiarr._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/notifiarr/#3-setup","text":"<p>You will need a notifiar account api key to use notifiarr. You can get one by signing up for a free account.</p> <p>After logging in, you should be redirected to your profile screen.</p> <ul> <li>Click on Generate API Key (This needs to be done)</li> <li>Select your Country</li> <li>Select your Timezone</li> <li>Change your Time Format to your liking</li> <li>Select your Site Theme</li> <li>Select your Notification Language</li> <li>Don't forget to Save your changes</li> </ul> <p>Add your API key to the Sandbox settings file</p> <p>Now run the installer</p> <p><pre><code>sb install sandbox-notifiarr\n</code></pre> Now go to the Notifiarr website and configure your integrations and discord server. Refer to the Notifiarr documentation for more information.</p> <p>The role will attempt to configure sonarr, radarr, plex, and tautulli. Other apps can be edited in the config file which can be found at <code>\"/opt/notifiarr/notifiarr.conf\"</code> in a standard install. From time to time new options will be added and an example config file can be found here.</p> <p>A quickstart guide can be found on the Trash Guides website.</p> <ul> <li> Documentation: Notifiarr Client Docs</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/ombi/","text":"","title":"Ombi"},{"location":"sandbox/apps/ombi/#what-is-it","text":"<p>Ombi is a self-hosted web application that automatically gives your shared Plex or Emby users the ability to request content by themselves!</p> <p>Ombi can be linked to multiple TV Show and Movie DVR tools to create a seamless end-to-end experience for your users.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/ombi/#1-installation","text":"<pre><code>sb install sandbox-ombi\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/ombi/#2-url","text":"<ul> <li>To access Ombi, visit <code>https://ombi._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/ombi/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/ombix/","text":"","title":"OmbiX"},{"location":"sandbox/apps/ombix/#what-is-it","text":"<p>OmbiX is an arrX role for Ombi.</p> <p>Ombi is a self-hosted web application that automatically gives your shared Plex or Emby users the ability to request content by themselves!</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/ombix/#1-installation","text":"<pre><code>sb install sandbox-ombix\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/ombix/#2-url","text":"<ul> <li>To access OmbiX, visit <code>https://OmbiX._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/ombix/#3-setup","text":"<ol> <li> <p>Read through the general arrX role instructions.</p> </li> <li> <p>Add your X instance names to the OmbiX section in community <code>settings.yml</code>: using a list format as below.</p> </li> </ol> <pre><code> ombix:\n   roles:\n     - 4k\n     - anime\n</code></pre> <ul> <li>For app specific instructions refer to the parent role,<ul> <li>Ombi</li> <li>and the upstream documentation   Documentation </li> </ul> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/ouroboros/","text":"","title":"Ouroboros"},{"location":"sandbox/apps/ouroboros/#what-is-it","text":"<p>Ouroboros will automatically update your running Docker containers to the latest available image.</p> <p>A python-based alternative to watchtower</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/ouroboros/#1-installation","text":"<pre><code>sb install sandbox-ouroboros\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/ouroboros/#2-setup","text":"<ul> <li> Documentation</li> </ul>","title":"2. Setup"},{"location":"sandbox/apps/plex-meta-manager/","text":"","title":"Plex Meta Manager"},{"location":"sandbox/apps/plex-meta-manager/#what-is-it","text":"<p>Plex Meta Manager can update many metadata fields for movies, shows, collections, seasons, and episodes and can act as a backup if your plex DB goes down. It can even update metadata the plex UI can't like Season Names. If the time is put into the metadata configuration file you can have a way to recreate your library and all its metadata changes with the click of a button.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/plex-meta-manager/#1-installation","text":"<p>You will need to create a config file prior to running the tag:</p> <p><code>/opt/plex-meta-manager/config/config.yml</code></p> <p>There is a Docker-based walkthrough on the PMM wiki here that you can use to learn how to create these files.  Once you've created those files, move them into <code>/opt/plex-meta-manager/config/</code> and then run the tag.</p> <pre><code>sb install sandbox-plex-meta-manager\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/plex-meta-manager/#2-setup","text":"<ul> <li> Documentation</li> </ul>","title":"2. Setup"},{"location":"sandbox/apps/qbit_manage/","text":"","title":"qBit Management"},{"location":"sandbox/apps/qbit_manage/#what-is-it","text":"<p>qBit Management is a program used to manage your qBittorrent instance.</p>    Details         qBit Management   Docs  Github:  Docker:     <p>Functions include:- </p> <ul> <li> <p>Tag torrents based on tracker and then set seed goals/limit upload speed by tag.</p> </li> <li> <p>Update categories based on save directory.</p> </li> <li> <p>Remove unregistered torrents (delete data &amp; torrent if it is not being cross-seeded, otherwise it will just remove the torrent).</p> </li> <li> <p>Automatically add cross-seed torrents in paused state.  Note: cross-seed now allows for torrent injections directly to qBit, making this feature obsolete.</p> </li> <li> <p>Recheck paused torrents sorted by lowest size and resume if completed.</p> </li> <li> <p>Remove orphaned files from your root directory that are not referenced by qBittorrent.</p> </li> <li> <p>Tag any torrents that have no hard links and allows optional cleanup to delete these torrents and contents based on maximum ratio and/or time seeded.</p> </li> <li> <p>RecycleBin function to move files into a RecycleBin folder instead of deleting the data directly when deleting a torrent.</p> </li> <li> <p>Built-in scheduler to run the script every x minutes. (Can use --run command to run without the scheduler).</p> </li> <li> <p>Webhook notifications with Notifiarr and Apprise API integration.</p> </li> </ul>","title":"What is it?"},{"location":"sandbox/apps/qbit_manage/#1-installation","text":"<p>Before installing qBit Management, you should have a qBittorrent instance running on your local machine.</p> <p><pre><code>sb install cm-qbit_manage\n</code></pre> After installation has finished, stop the qbit_manage docker container and edit the config file that will have been created at <code>/opt/qbit_manage/config.yml</code></p> <p><pre><code>docker stop qbit_manage\n</code></pre> Minimally you will need to change the following items in order to connect with your qBittorrent instance:-</p> <p><pre><code>    qbt:\n      host: \"qbittorrent:8080\"\n      user: \"qbittorrent_username\"\n      pass: \"qbittorrent_password\"\n\n    directory:\n      cross_seed: \"/your/path/here/\"\n      root_dir: \"/mnt/unionfs/downloads/torrents/qbittorrent/completed/\"\n      remote_dir: \"/mnt/unionfs/torrents/your/path/here/\"\n</code></pre> An indepth explanation of the config file settings can be found here.</p> <p>The config file is full of examples that more than likely will not work for you, sections you aren't using can be safely commented out or left blank. An up to date example configuration file can be found here when you wish to add newer features or restore a self mangled section. YAML spacing matters.</p> <p>After making adjustments to the config file, you can start the docker container again.</p> <p><pre><code>docker start qbit_manage\n</code></pre> Either tail the log ( <code>tail -f \"/opt/qbit_manage/activity.log\"</code> ) or open the log file after a few minutes to check for any errors or behaviour that may have been unexpected. The container has been deliberately set to DRY RUN MODE initially so you can see what the script will do without actually moving deleting, tagging, or categorising anything.. Once you are happy your life's work will not be destroyed and any errors have been resolved you can edit the qbit_manage variables in the sandbox settings.yml file and then run the role again. Set <code>qbt_dry_run: false</code> to run in live mode. This will delete and move files according to your settings.</p> <p>Apply the changes to the sandbox settings file with:</p> <pre><code>sb install cm-qbit_manage\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/qbit_manage/#3-setup","text":"<p>The following variables are available to set in the sandbox settings.yml file. An explanation of these settings can be found here.</p> <pre><code>qbit_manage:\n  qbt_run: \"false\" # Default is \"false\"\n  qbt_schedule: \"30\" # Default is \"30\"\n  qbt_config: \"config.yml\" # Default is \"config.yml\"\n  qbt_logfile: \"activity.log\" # Default is \"activity.log\"\n  qbt_cross_seed: \"false\" # Default is \"false\"\n  qbt_recheck: \"false\" # Default is \"false\"\n  qbt_cat_update: \"false\" # Default is \"false\"\n  qbt_tag_update: \"false\" # Default is \"false\"\n  qbt_rem_unregistered: \"false\" # Default is \"false\"\n  qbt_rem_orphaned: \"false\" # Default is \"false\"\n  qbt_tag_nohardlinks: \"false\" # Default is \"false\"\n  qbt_skip_recycle: \"false\" # Default is \"false\"\n  qbt_dry_run: \"true\" # Default is \"false\"\n  qbt_log_level: \"INFO\" # Default is \"INFO\"\n  qbt_divider: \"=\" # Default is \"=\"\n  qbt_width: \"100\" # Default is \"100\"\n</code></pre> <ul> <li> Documentation: qBit Management Docs</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/requestrr/","text":"","title":"Requestrr"},{"location":"sandbox/apps/requestrr/#what-is-it","text":"<p>Requestrr is a chatbot used to simplify using services like Sonarr/Radarr/Ombi via the use of chat. Current platform is Discord only, but the bot was built around the ideology of quick adaptation for new features as well as new platforms.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/requestrr/#1-installation","text":"<pre><code>sb install sandbox-requestrr\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/requestrr/#2-url","text":"<ul> <li>To access Requestrr, visit <code>https://requestrr._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/requestrr/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/requestrrx/","text":"","title":"RequestrrX"},{"location":"sandbox/apps/requestrrx/#what-is-it","text":"<p>RequestrrX is an arrX role for Requestrr.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/requestrrx/#1-installation","text":"<pre><code>sb install sandbox-requestrrx\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/requestrrx/#2-url","text":"<ul> <li>To access RequestrrX, visit <code>https://requestrrx._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/requestrrx/#3-setup","text":"<ol> <li> <p>Read through the general arrX role instructions.</p> </li> <li> <p>Add your X instance names to the RequestrrX section in community <code>settings.yml</code>: using a list format as below.</p> <pre><code>    requestrrx:\n      roles:\n        - 1080\n        - 4k\n</code></pre> </li> <li> <p>Run the Saltbox installer to generate your X instances of requestrr.</p> <pre><code>    sb install cm-requestrrx\n</code></pre> </li> <li> <p>For app specific instructions refer to the parent role,</p> <ul> <li>requestrr</li> <li>and the requestrr upstream documentation   Documentation </li> </ul> </li> </ol>","title":"3. Setup"},{"location":"sandbox/apps/resilio_sync/","text":"","title":"Resilio Sync"},{"location":"sandbox/apps/resilio_sync/#not-integrated-make-sandbox-request-if-needed","text":"","title":"NOT INTEGRATED - MAKE SANDBOX REQUEST IF NEEDED"},{"location":"sandbox/apps/resilio_sync/#what-is-it","text":"<p>Resilio Sync  uses peer-to-peer technology to provide fast, private file sharing for teams and individuals. By skipping the cloud, transfers can be significantly faster because files take the shortest path between devices. Sync does not store your information on servers in the cloud, avoiding cloud privacy concerns.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/resilio_sync/#1-installation","text":"<pre><code>sb install cm-resilio-sync\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/resilio_sync/#2-url","text":"<ul> <li>To access Resilio Sync, visit <code>https://resilio-sync._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/resilio_sync/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/rflood/","text":"","title":"rFlood"},{"location":"sandbox/apps/rflood/#what-is-it","text":"<p>rFlood docker image with rTorrent and the Flood UI, also optional WireGuard VPN support.</p>","title":"What is it?"},{"location":"sandbox/apps/rflood/#project-information","text":"<ul> <li> rFlood </li> <li> Docs</li> <li> Github rTorrent:</li> <li> Github Flood:</li> <li> Docker: </li> </ul>","title":"Project Information"},{"location":"sandbox/apps/rflood/#1-installation","text":"<pre><code>sb install sandbox-rflood\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/rflood/#2-url","text":"<ul> <li>To access rFlood, visit <code>https://rflood._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/rflood/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/rfloodx/","text":"","title":"rFloodX"},{"location":"sandbox/apps/rfloodx/#what-is-it","text":"<p>rFloodX is an arrX role for rFlood.</p>","title":"What is it?"},{"location":"sandbox/apps/rfloodx/#project-information","text":"<ul> <li> rFlood </li> <li> Docs</li> <li> Github rTorrent:</li> <li> Github Flood:</li> <li> Docker: </li> </ul>","title":"Project Information"},{"location":"sandbox/apps/rfloodx/#1-installation","text":"<pre><code>sb install sandbox-rfloodx\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/rfloodx/#2-url","text":"<ul> <li>To access rFloodX, visit <code>https://rfloodx._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/rfloodx/#3-setup","text":"<ol> <li> <p>Read through the general arrX role instructions.</p> </li> <li> <p>Add your X instance names to the rFloodX section in community <code>settings.yml</code>: using a list format as below.</p> <pre><code>    rfloodx:\n      roles:\n        - linuxisos\n        - anime\n</code></pre> </li> <li> <p>Run the Saltbox installer to generate your X instances of rflood.</p> <pre><code>    sb install cm-rfloodx\n</code></pre> </li> <li> <p>For app specific instructions refer to the parent role,</p> <ul> <li>rflood</li> <li>and the rflood upstream documentation   Documentation </li> </ul> </li> </ol>","title":"3. Setup"},{"location":"sandbox/apps/speedtest/","text":"","title":"Speedtest"},{"location":"sandbox/apps/speedtest/#what-is-it","text":"<p>Speedtest  is a very lightweight Speedtest implemented in Javascript, using XMLHttpRequest and Web Workers.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/speedtest/#1-installation","text":"<pre><code>sb install sandbox-speedtest\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/speedtest/#2-url","text":"<ul> <li>To access Speedtest, visit <code>https://speedtest._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/speedtest/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/sshwifty/","text":"","title":"Sshwifty"},{"location":"sandbox/apps/sshwifty/#what-is-it","text":"<p>Sshwifty is an SSH and Telnet connector made for the Web. It can be deployed on your computer or server to provide SSH and Telnet access interface for any compatible (standard) web browser.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/sshwifty/#1-installation","text":"<pre><code>sb install sandbox-sshwifty\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/sshwifty/#2-url","text":"<ul> <li>To access Sshwifty, visit <code>https://sshwifty._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/sshwifty/#3-setup","text":"<ul> <li> <p>The pre-configured password is taken from your Saltbox <code>accounts.yml</code> file located in <code>/srv/git/saltbox/accounts.yml</code></p> </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/stash/","text":"","title":"Stash"},{"location":"sandbox/apps/stash/#what-is-it","text":"<p>Stash is a locally hosted web-based app written in Go which organizes and serves your porn.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/stash/#1-installation","text":"<pre><code>sb install sandbox-stash\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/stash/#2-url","text":"<ul> <li>To access Stash, visit <code>https://stash._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/stash/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/telegraf/","text":"","title":"Telegraf"},{"location":"sandbox/apps/telegraf/#what-is-it","text":"<p>Telegraf is a plugin-driven server agent for collecting and sending metrics and events from databases, systems, and IoT sensors.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/telegraf/#1-installation","text":"<pre><code>sb install sandbox-telegraf\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/telegraf/#2-setup","text":"<ul> <li> Documentation</li> </ul>","title":"2. Setup"},{"location":"sandbox/apps/thelounge/","text":"","title":"The Lounge"},{"location":"sandbox/apps/thelounge/#what-is-it","text":"<p>The Lounge is a self hosted web IRC client. In private mode, The Lounge acts like a bouncer and a client combined, in order to offer an experience similar to other modern chat applications outside the IRC world. Users can then access and resume their session without being disconnected from their channels.</p>    Details         The Lounge   Docs  Github:  Docker:","title":"What is it?"},{"location":"sandbox/apps/thelounge/#1-installation","text":"<pre><code>sb install cm-thelounge\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/thelounge/#2-url","text":"<ul> <li>To access The Lounge, visit <code>https://thelounge._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/thelounge/#3-setup","text":"<ul> <li>When the application first runs, it will populate its /config</li> <li>Stop the container</li> <li>Now from the host, edit /config/config.js, wherever you've mapped it</li> <li>In most cases you want the value public: false to allow named users only</li> <li>Setting the two prefetch values to true improves usability, but uses more storage</li> <li>Once you have the configuration you want, save it and start the container again</li> <li>For each user, run the command       <pre><code>  docker exec -it thelounge s6-setuidgid abc thelounge add &lt;user&gt;\n</code></pre><ul> <li>You will be prompted to enter a password that will not be echoed.</li> <li>Saving logs to disk is the default, this consumes more space but allows scrollback.</li> </ul> </li> <li>To log in to the application, browse to <code>https://thelounge._yourdomain.com_</code></li> <li>You should now be prompted for a username and password on the webinterface.</li> <li>Once logged in, you can add an IRC network. Some defaults are preset for Freenode.</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/thelounge/#znc","text":"<p>To connect to znc, you need to have a znc server running. A guide to using The Lounge with ZNC can be found here</p> <ul> <li>In this image we have a ZNC network defined.</li> </ul> <p></p> <ul> <li>To add this network to The Lounge, give it a Name, it does not have to match the ZNC network settings.</li> <li>For the Server, use <code>znc</code> and set the port to <code>6502</code></li> <li>For the Password, enter your <code>ZNC user password</code></li> <li>Uncheck `Use secure connection (TLS)</li> <li>In the User Preferences section enter your Nick - I would recommend the same Nick as that set in ZNC.</li> <li>For the user name enter the <code>&lt;ZNC username&gt;/&lt;ZNC_Network_Name&gt;</code>.</li> <li>For Real Name, enter your desired <code>&lt;real_name&gt;</code> it does not need to match ZNC</li> <li>Save the network, and it should connect to ZNC.</li> </ul> <p></p> <ul> <li> Documentation: The Lounge Docs</li> </ul>","title":"ZNC"},{"location":"sandbox/apps/transmission/","text":"","title":"Transmission"},{"location":"sandbox/apps/transmission/#what-is-it","text":"<p>Transmission is a fast, easy, and free BitTorrent client.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/transmission/#1-installation","text":"<pre><code>sb install sandbox-transmission\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/transmission/#2-url","text":"<ul> <li>To access Transmission, visit <code>https://transmission._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/transmission/#3-setup","text":"<ul> <li> <p>Suggested desktop client is Transmission Remote GUI. It is to be set up with ssl enabled on port 443</p> </li> <li> <p><code>/watch</code> is hard-coded in the software and not editable from the settings.json, see related issue. To get around this the folder is mounted to <code>/mnt/local/downloads/torrents/transmission{{ rolename }}/watch</code></p> </li> <li> <p>Do not change the published ports if you want to be connectable.</p> </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/transmissionx/","text":"","title":"TransmissionX"},{"location":"sandbox/apps/transmissionx/#what-is-it","text":"<p>TransmissionX is an arrX role for Transmission.</p> <p>Transmission is a fast, easy, and free BitTorrent client.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/transmissionx/#1-installation","text":"<pre><code>sb install sandbox-transmissionx\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/transmissionx/#2-url","text":"<ul> <li>To access TransmissionX, visit <code>https://transmissionx._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/transmissionx/#3-setup","text":"<ol> <li> <p>Read through the general arrX role instructions.</p> </li> <li> <p>Add your X instance names to the TransmissionX section in community <code>settings.yml</code>: using a list format as below.</p> <pre><code>    transmissionx:\n      roles:\n        - reality\n        - games\n</code></pre> </li> <li> <p>Run the Saltbox installer to generate your X instances of transmission.</p> <pre><code>    sb install sandbox-transmissionx\n</code></pre> </li> <li> <p>For app specific instructions refer to the parent role,</p> <ul> <li>transmission</li> <li>and the transmission upstream documentation   Documentation </li> </ul> </li> </ol>","title":"3. Setup"},{"location":"sandbox/apps/unmanic/","text":"","title":"Unmanic"},{"location":"sandbox/apps/unmanic/#what-is-it","text":"<p>Unmanic is a simple tool for optimising your file library. You can use it to convert your files into a single, uniform format, manage file movements based on timestamps, or execute custom commands against a file based on its file size.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/unmanic/#1-installation","text":"<pre><code>sb install sandbox-unmanic\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/unmanic/#2-url","text":"<ul> <li>To access Unmanic, visit <code>https://unmanic._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/unmanic/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/unpackerr/","text":"","title":"Unpackerr"},{"location":"sandbox/apps/unpackerr/#what-is-it","text":"<p>Unpackerr checks for completed downloads and extracts them so Lidarr, Radarr, Readarr, Sonarr may import them. There are a handful of options out there for extracting and deleting files after your client downloads them.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/unpackerr/#1-installation","text":"<pre><code>sb install sandbox-unpackerr\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/unpackerr/#2-setup","text":"<ul> <li> Documentation</li> </ul>","title":"2. Setup"},{"location":"sandbox/apps/uptime_kuma/","text":"","title":"Uptime Kuma"},{"location":"sandbox/apps/uptime_kuma/#what-is-it","text":"<p>Uptime Kuma is a self-hosted monitoring tool like \"Uptime Robot\".</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/uptime_kuma/#1-installation","text":"<pre><code>sb install sandbox-uptime-kuma\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/uptime_kuma/#2-url","text":"<ul> <li>To access Uptime Kuma, visit <code>https://uptime._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/uptime_kuma/#3-setup","text":"<ul> <li> Documentation</li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/varken/","text":"","title":"Varken"},{"location":"sandbox/apps/varken/#what-is-it","text":"<p>Varken is Dutch for PIG. PIG is an Acronym for Plex/InfluxDB/Grafana</p> <p>Varken is a standalone application to aggregate data from the Plex ecosystem into InfluxDB using Grafana for a frontend</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/varken/#1-installation","text":"<pre><code>sb install sandbox-varken\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/varken/#2-url","text":"<ul> <li>To access the Varken dashboard, visit <code>https://grafana._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/varken/#3-setup","text":"<ol> <li> <p>Run the Saltbox varken role to install varken/influxdb/telegraf/grafana:</p> <pre><code>    sb install sandbox-varken\n</code></pre> </li> <li> <p>Add your Maxmind API key to varken.ini:</p> <pre><code>    nano /opt/varken/varken.ini\n</code></pre> </li> <li> <p>Restart Varken:</p> <pre><code>    docker restart varken\n</code></pre> </li> <li> <p>Visit grafana <code>https://grafana._yourdomain.com_</code> </p> <ul> <li>The configured username/password are taken from your Saltbox <code>accounts.yml</code> file located in <code>/srv/git/saltbox/accounts.yml</code></li> </ul> </li> <li> <p>Add data source InfluxDB named InfluxDB:</p> <ol> <li> <p>HTTP: URL = http://influxdb:8086</p> </li> <li> <p>InfluxDB Details: Database = varken</p> </li> <li> <p>Save &amp; Test</p> </li> </ol> </li> <li> <p>Add data source InfluxDB named Telegraf:</p> <ol> <li> <p>HTTP: URL = http://influxdb:8086</p> </li> <li> <p>InfluxDB Details: Database = telegraf</p> </li> <li> <p>Save &amp; Test</p> </li> </ol> </li> <li> <p>Grafana Example from Organizrr Discord  (imported via <code>Dashboards &gt; Manage &gt; Import</code>) :</p> <p>from: GilbN -- Plex dashboard for Grafana   @Grafana-Group for anyone using Varken Thought I'd share the dashboard I made. (with the help of Rox and Tron)   You will need to add the piechart and worldmap plugins for the dashboard to work. Use the variables to set the   different data sources.</p> <p>To Install PieChart/WorldMap: </p> <pre><code>    cd /opt/grafana/plugins &amp;&amp; git clone https://github.com/grafana/piechart-panel.git &amp;&amp; git clone\n  https://github.com/grafana/worldmap-panel.git &amp;&amp; docker restart grafana\n</code></pre> <p></p> </li> <li> <p>Grafana Examples from Varken Discord:</p> <ul> <li> <p>Varken Official Supported Dashboards: </p> </li> <li> <p>Online Users Table Example (Tautulli):</p> </li> <li> <p>World Map w/ geoIP</p> </li> </ul> <p> </p> <ul> <li> <p>Device Type Pie Chart:</p> </li> <li> <p>Basic Panel Structure</p> </li> </ul> <p></p> </li> <li> <p>For app specific instructions refer to the grafana role,</p> <ul> <li> <p>grafana</p> </li> <li> <p>and the upstream documentation   Documentation</p> </li> </ul> </li> </ol>","title":"3. Setup"},{"location":"sandbox/apps/vaultwarden/","text":"","title":"vaultwarden"},{"location":"sandbox/apps/vaultwarden/#what-is-it","text":"<p>vaultwarden is an alternative implementation of the Bitwarden server API written in Rust and compatible with upstream Bitwarden clients*, perfect for self-hosted deployment where running the official resource-heavy service might not be ideal.</p>  <p>Note</p> <p>\ud83d\udce2 This project was known as Bitwarden_RS and has been renamed to separate itself from the official Bitwarden server in the hopes of avoiding confusion and trademark/branding issues.</p>     Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/vaultwarden/#1-installation","text":"<pre><code>sb install cm-vaultwarden\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/vaultwarden/#2-url","text":"<ul> <li>To access vaultwarden, visit <code>https://vaultwarden._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/vaultwarden/#3-setup","text":"<ol> <li> <p>Visit the vaultwarden site at <code>https://vaultwarden._yourdomain.com_</code></p> </li> <li> <p>Sign up with any email address and password.</p> </li> <li> <p>To access the Admin Panel go to <code>https://vaultwarden._yourdomain.com_admin</code></p> </li> <li> <p>You will need to enter an authentication key which you can find in <code>/opt/vaultwarden/env</code>. Look for <code>ADMIN_TOKEN=</code>.</p> </li> <li> <p> Documentation</p> </li> </ol>","title":"3. Setup"},{"location":"sandbox/apps/watchtower/","text":"","title":"Watchtower"},{"location":"sandbox/apps/watchtower/#what-is-it","text":"<p>Watchtower is a process for automating Docker container base image updates.</p> <p>With watchtower you can update the running version of your containerized app simply by pushing a new image to the Docker Hub or your own image registry. Watchtower will pull down your new image, gracefully shut down your existing container and restart it with the same options that were used when it was deployed initially.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/watchtower/#1-installation","text":"<pre><code>sb install sandbox-watchtower\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/watchtower/#2-setup","text":"<ul> <li> Documentation</li> </ul>","title":"2. Setup"},{"location":"sandbox/apps/wordpress/","text":"","title":"WordPress"},{"location":"sandbox/apps/wordpress/#what-is-it","text":"<p>WordPress  is open source software you can use to create a beautiful website, blog, or app.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/wordpress/#1-installation","text":"<pre><code>sb install sandbox-wordpress\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/wordpress/#2-url","text":"<ul> <li>To access WordPress , visit <code>https://wordpress._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/wordpress/#3-setup","text":"<ul> <li> <p>Visit the wordpress site at <code>https://wordpress._yourdomain.com_</code> and the setup screen will appear.</p> </li> <li> <p>No default user is configured until you run through the setup screen, so you should ideally run through setup as soon as wordpress is deployed to secure the site.</p> </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/wrapperr/","text":"","title":"Wrapperr"},{"location":"sandbox/apps/wrapperr/#what-is-it","text":"<p>Wrapperr is a website-based platform and API for collecting user stats within a set timeframe using Tautulli. The data is displayed as a statistics-summary, sort of like Spotify Wrapped. Yes, you need Tautulli to have been running beforehand and currently for this to work.</p>    Details        -  Wrapperr   Docs  Github:  Docker:","title":"What is it?"},{"location":"sandbox/apps/wrapperr/#1-installation","text":"<pre><code>sb install cm-wrapperr\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/wrapperr/#2-url","text":"<ul> <li>To access Wrapperr, visit <code>https://wrapperr._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/wrapperr/#3-setup","text":"<ul> <li> <p>The very first thing you should do after installing Wrapperr is visit <code>https://wrapperr._yourdomain.com_</code> and configure an admin username/password.  Do this NOW.</p> </li> <li> <p> Documentation: Wrapperr Docs</p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/xteve/","text":"","title":"xTeVe"},{"location":"sandbox/apps/xteve/#what-is-it","text":"<p>xTeVe is a M3U proxy server for Plex, Emby and any client and provider which supports the .TS and .M3U8 (HLS) streaming formats.</p> <p>xTeVe emulates a SiliconDust HDHomeRun OTA tuner, which allows it to expose IPTV style channels to software, which would not normally support it. This Docker image includes the following packages and features:</p> <ul> <li> <p>xTeVe v2.1 (Linux) x86 64 bit</p> </li> <li> <p>Latest Guide2go (Linux) x86 64 bit (Schedules Direct XMLTV grabber)</p> </li> <li> <p>Zap2XML Support (Perl based zap2it / TVguide.com XMLTV grabber)</p> </li> <li> <p>Bash, Perl &amp; crond Support</p> </li> <li> <p>VLC &amp; ffmpeg Support</p> </li> <li> <p>Automated XMLTV Guide Lineups &amp; Cron\u2019s</p> </li> </ul>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/xteve/#1-installation","text":"<pre><code>sb install sandbox-xteve\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/xteve/#2-url","text":"<ul> <li>To access xTeVe, visit <code>https://ROLENAME._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/xteve/#3-setup","text":"<ul> <li> <p>Access xTeVe web GUI, visit <code>https://ROLENAME._yourdomain.com_</code></p> </li> <li> <p>Run through the Configuration Wizard.</p> </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/yacht/","text":"","title":"Yacht"},{"location":"sandbox/apps/yacht/#what-is-it","text":"<p>Yacht is a web interface for managing docker containers with an emphasis on templating to provide one-click deployments of dockerized applications. Think of it like a decentralized app store for servers that anyone can make packages for.</p>    Details         Project home   Docs  Github:  Docker","title":"What is it?"},{"location":"sandbox/apps/yacht/#1-installation","text":"<pre><code>sb install sandbox-yacht\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/yacht/#2-url","text":"<ul> <li>To access Yacht, visit <code>https://yacht._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/yacht/#3-setup","text":"<ul> <li> <p>Check out the getting started guide if this is the first time you've used Yacht.</p> </li> <li> <p> Documentation</p> </li> </ul>","title":"3. Setup"},{"location":"sandbox/apps/znc/","text":"","title":"ZNC"},{"location":"sandbox/apps/znc/#what-is-it","text":"<p>ZNC is an an advanced IRC bouncer that is left connected so an IRC client can disconnect/reconnect without losing the chat session.</p> <p>It can detach the client from the actual IRC server, and also from selected channels. Multiple clients from different locations can connect to a single ZNC account simultaneously and therefore appear under the same nickname on IRC.</p>    Details         ZNC   Docs  Github:  Docker:","title":"What is it?"},{"location":"sandbox/apps/znc/#1-installation","text":"<pre><code>sb install cm-znc\n</code></pre>","title":"1. Installation"},{"location":"sandbox/apps/znc/#2-url","text":"<ul> <li>To access ZNC, visit <code>https://znc._yourdomain.com_</code></li> </ul>","title":"2. URL"},{"location":"sandbox/apps/znc/#3-setup","text":"<ul> <li> Documentation: ZNC Docs</li> </ul>","title":"3. Setup"}]})